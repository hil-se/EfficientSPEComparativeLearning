Issue,Storypoint
"Support profiling mapR 2.1.2   
nan",3
"delete analysis by right click on sub node of report node is not synchronous with editor of report if editor is opening
delete analysis by right click on sub node of report node should update report editor with same time.    1.create a report by right click on the analysis node.  2.keep report editor is opening and expand the sub node of report node try to find analysis node.  3.right click on the analysis node and select delete analysis action.  4.pop up a choose dialog ask you whether want to delete the analysis forever and choose yes.    expect:  the report editor should be updated. The analysis which be deleted just now should not exist on the analysis list.    result:  the analysis will exist yet.  ",5
"""Hide"" action should also hide data in the data sample table in the match analysis editor
When clicking on the ""hide groups less than x items"", the data in the data table should be filtered out accordingly.   Just like in the component",5
"Do not open the DQ repository view when saving the editor
we can follow the following 4 steps to do the refactoring:  1. refactoring DQRepositoryNodes  2. action/editor/page/handler, recursiveFind()  3. command line  4. sub nodes under connection        details:  1.1 profiling node  		analysis node  		report node    1.2 library node  		indicator node  		pattern node  		rule node  		source file node  		jrxml node  		exchange node: need not to refactoring    the above Nodes need to refactor, remove the property ModelElement and refactor the related method  {code}      private Analysis analysis;        public Analysis getAnalysis() {          return this.analysis;      }        public void updateAnalysis(Analysis ana) {          this.analysis = ana;      }  {code}  remove the property analysis and the method updateAnalysis()  refactor the method getAnalysis(), get the analysis from the Node  {code}      public Analysis getAnalysis() {          return ((TDQAnalysisItem)this.getObject().getProperty().getItem()).getAnalysis();      }  {code}  other node just like this  		  1.3 folder node and connection node need not to refactoring            2.1 action  		OpenItemEditorAction : using RepositoryNode as the parameter of this class, refactoring the related codes to adapt to this change  		RunAnalysisAction: keep using the Item, add comments here, remove the deprecated method    2.2 editor/page/handler  		AbstractItemEditorInput : using RepositoryNode as the parameter, all the Editor and pages need to adapt to this change  		  org.talend.dataprofiler.core.ui.wizard.analysis.AbstractAnalysisWizard.openEditor(Item item): get the Node from the Item first and then pass the Node to the EditorInput    2.5 recursiveFind()		  		need to remvoe most recursiveFind()	method, but still need to keep several recursiveFind()	method, because some time still need to find the node according to the ModelElement or other type object  		  these refactoring need to deal with as a whole, this part will cost more time than first part        ReportWriter line 74:  ...  AnalysisRepNode recursiveFindAnalysis = RepositoryNodeHelper.recursiveFindAnalysis(ana);  ...  if (recursiveFindAnalysis != null && recursiveFindAnalysis.getProject().isMainProject()) {  ...  find another method to check the project is main project or reference project      create the RepositoryNode first when use wizard to create Item, then use this node to open the editor      for the 3 and 4 step, we can do them later  		  ",7
"Match analysis editor cosmetic changes
See pic.",2
"Create cheat sheet for new Match Analysis.
nan",5
"Eclipse help view for the Match rule wizard.
The Match rule creation wizard is accessible from the Repository. So contextual help should be availalble using the F1 key, and should also be available with a Help button  at the bottom of the wizard (eclipse already provide this feature, it just needs to be activated).",8
"TOP should do same things as TDQ to open the dialog which can download all of jar files when stdio is opening 
TOP should do same things as TDQ to open the dialog which can download all of jar files when stdio is opening.  The image of dialog has been attached.  ",13
"Support hive profiling for MapR 2.1.3
nan",5
"Hadoop components for DQ support HDP 2.0.0
The DI Hadoop components now support HDP 2.0.0. So the DQ Hadoop components might need to keep pace.",8
"update the content when check mysql database user privileges
nan",5
"Update tmatch group ""refresh"" button label
Update tMatchGroup refresh button in the configuration wizard.  Refresh name is not intuitive.  Could be better with ""Chart"" or ""Visualize""  ",2
"If you change the basic data set for the matching analysis the whole screen should be reset
nan",5
"Reduce memory usage during TDQ item export
I have 44 analyses and 7 reports in my project and I clicked at the export wizard button.    The wizard is open after 10 seconds of dependency calculation. and the memory usage is shown in the attached picture. ",2
"Create version 5.4.1 in Babili and populate it
nan",2
"After change the analyzed file connection path columns in analysis will be removed even the news are same as the originals
analyze a file connection  keep the analysis editor open, and if change the file path and retrieve the new schema(some columns are same as the originals)  and do NOT update the editor    for column analysis  columns still in editor, but actually all columns are removed   for match analysis  columns in match analysis editor do not change(originals)  click ""select data"" to open the column selection dialog, you can see only the same columns are checked    This issue need to implement a new feature of reload file connection.",13
"Cannot edit a synonym
Open addons/data/synonym/idx_city_exonyms/all_4_countries  Search ""strasbourg""  Edit the entry to remove ""Est"" as a synonym.   Save.  It yields to an error and nothing is saved.     See pic",3
"Technical - Refine commit of  TDQ-8068  Support hive profiling for MapR 3.0
For commit : http://talendforge.org/trac/top/changeset/111240#file0  - Add a comment to explain the logic for if/else.",1
"Export babili translations into trunk of SVN
nan",2
"handle org.talend.dqdemos
nan",3
"when create datamart with user which doesn't have enough privileges, can get only one error.
1. create a report  2. set datamart information in report editor(mysql/oracle),  make sure      (1)user just have access privileges.     (2) datamart tables/views doesn't exist.  3. then click ""check"", try to create datamart.    Expected Result:  get many error for what privileges we need to add    Actual Result:  just get an error , refer to doc attached.",5
"tRecordMatching : bug with lookup
There is a bug with the tRecordMatching and it's lookup. In the ""End"" part of the code, the lookup is flushed and it's caused big issue when you use the component :  - after an iterate link  - in a Data Service (ESB)    Workaround : edit the code surrounded in the screenshot",5
"Hive profiling cannot finish on mapR3.0 embedded mode in Win 8
From TDQ-8068  tested on build Talend-Studio-r111555-V5.4.1EP  while run analysis with embeded mode with hive in MapR 3.0.1  the process is always running and will never stop  no error log",8
"Sampling algorithm to run Analysis on a sample of data which is not necessary the first 1000 or first 5000 rows.
It would be nice to have some smart Sampling algorithm which can return a smaller dataset than the entire dataset while we are doing our PROFILE analysis and Matchgroup set up.    The idea is to have a significant sample, random and not only filter on the x first rows of our data sets.    ",8
"in demo project the first analysis--GenderAna can not genereate ETL job  correctly about the pattern(Email Address)
1. create a new project.  2. on the welcome page,click ""Demos"", on the pop up dialog select dq demo, and import it.  3. change the msyql configuration to your correct one.  4. run the fist analysis--enderAna.  5. focus on ""Result page"", right click on the pattern --> Email Address -->Generate Job, on the pop up dialog select the first one option.    Expected Result:  generate a job correctly.    Actual Result:  job can generated but the dialog still show.    note: just create a new connection, and column analysis with pattern, the issue won't show.    {code}  java.lang.NullPointerException    org.talend.designer.core.ui.editor.nodes.Node.checkSchema(Node.java:3410)    org.talend.designer.core.ui.editor.nodes.Node.checkNode(Node.java:3685)    org.talend.designer.core.ui.editor.nodes.Node.checkAndRefreshNode(Node.java:3676)    org.talend.designer.core.ui.editor.cmd.QueryGuessCommand.execute(QueryGuessCommand.java:165)    org.talend.datacleansing.core.ui.actions.IndicatorJobAction.setParameters(IndicatorJobAction.java:144)    org.talend.datacleansing.core.ui.actions.pattern.PatternIndicatorJobAction.setParameters(PatternIndicatorJobAction.java:93)    org.talend.datacleansing.core.ui.actions.pattern.PatternValidRowsJobAction.setParameters(PatternValidRowsJobAction.java:50)    org.talend.datacleansing.core.ui.jobs.template.AJobAction.addTemplateNodes(AJobAction.java:295)    org.talend.datacleansing.core.ui.jobs.template.AJobAction.doRun(AJobAction.java:153)    org.talend.repository.ui.actions.AContextualAction$2.run(AContextualAction.java:611)    org.talend.repository.RepositoryWorkUnit.executeRun(RepositoryWorkUnit.java:93)    org.talend.core.repository.model.AbstractRepositoryFactory.executeRepositoryWorkUnit(AbstractRepositoryFactory.java:237)    org.talend.repository.localprovider.model.LocalRepositoryFactory.executeRepositoryWorkUnit(LocalRepositoryFactory.java:3197)    org.talend.core.repository.model.ProxyRepositoryFactory.executeRepositoryWorkUnit(ProxyRepositoryFactory.java:1979)    org.talend.repository.ui.actions.AContextualAction.run(AContextualAction.java:617)    org.talend.datacleansing.core.ui.actions.IndicatorJobAction.run(IndicatorJobAction.java:327)    org.talend.datacleansing.core.ui.actions.ui.pattern.PatternJobSelectWizard.performFinish(PatternJobSelectWizard.java:66)    org.eclipse.jface.wizard.WizardDialog.finishPressed(WizardDialog.java:811)    org.eclipse.jface.wizard.WizardDialog.buttonPressed(WizardDialog.java:430)    org.eclipse.jface.dialogs.Dialog$2.widgetSelected(Dialog.java:624)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.jface.window.Window.runEventLoop(Window.java:825)    org.eclipse.jface.window.Window.open(Window.java:801)    org.talend.datacleansing.core.ui.service.DatabaseJobService.createJobActon(DatabaseJobService.java:97)    org.talend.datacleansing.core.ui.service.DatabaseJobService.executeJob(DatabaseJobService.java:77)    org.talend.dataprofiler.core.ui.editor.preview.model.ChartTableFactory$1.widgetSelected(ChartTableFactory.java:152)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.rcp.intro.Application.start(Application.java:145)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    java.lang.reflect.Method.invoke(Method.java:597)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)    {code}",8
"tRecordMatching import rules from dq Repository, some parameters can not set correctly.
1. create rule manually or export from match analysis,     --make sure rules have a key item select ""Matching Function"" select ""Custom"" and set class name.  2. create a job add tRecordMatching  3. on the Component tab of tRecordMatching, click ""import rules from Repository""  4. on the pop up dialog select the rules.    Expected Result:  parameters set correctly, job can run well.    Actual Result:  ""Matching Function"" set ""Exact"",   ""Custom Matcher""  lose ""double quote"", and add jar name, in fact, have jar name job can not run.",5
"Component that generates duplicates
Create a component that generates duplicate data from an input flow. This component would be mostly used in combination with a tRowGenerator.     Settings:  - percentage of duplicates to generate (will tell how many rows to generate from a given row - will be less than one).   This means that when a row comes in, we must decide whether to generate or not a duplicate row (In order to do this, we could use a sampling algo).   - fields that are subject to changes (choose which columns may have changes)  - for each chosen field, choose how to modify them.     - this could be exact duplicated value    - approximate duplicated value     - replacement value (use a synonym from an index file)    - delete value (set to null or blank)  - min and max percentage of fields to be modified  ",8
"Drag a UDI to current folder will throw 2 error
in DQ Repository,  drag a UDI to current folder will get 2 error  {code}  Problems occurred when invoking code from plug-in: ""org.eclipse.ui.navigator"".  --------------------------------------------------------------------------------------------------------------------------------------  org.eclipse.core.runtime.AssertionFailedException: assertion failed: Cannot move '/TOP_DEFAULT_PRJ/TDQ_Libraries/Indicators/User Defined Indicators/Copy_of_Row_Count_0.1.properties'. Destination should not be under source's hierarchy.    org.eclipse.core.runtime.Assert.isTrue(Assert.java:110)    org.eclipse.core.internal.resources.Resource.assertMoveRequirements(Resource.java:195)    org.eclipse.core.internal.resources.Resource.move(Resource.java:1585)    org.eclipse.core.internal.resources.Resource.move(Resource.java:1565)    org.talend.commons.utils.workbench.resources.ResourceUtils.moveResource(Unknown Source)    org.talend.core.repository.utils.XmiResourceManager.moveResource(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.moveResource(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.moveObject(Unknown Source)    org.talend.core.repository.model.ProxyRepositoryFactory.moveObject(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD$2$1.run(Unknown Source)    org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1975)    org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1957)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD$2.run(Unknown Source)    org.talend.repository.RepositoryWorkUnit.executeRun(Unknown Source)    org.talend.core.repository.model.AbstractRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.core.repository.model.ProxyRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveObject(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveOthersNode(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveRepositoryNodes(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.handleDrop(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.RepositoryNodeDorpAdapterAssistant.handleDrop(Unknown Source)    org.eclipse.ui.navigator.CommonDropAdapter$1.run(CommonDropAdapter.java:194)    org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)    org.eclipse.ui.navigator.CommonDropAdapter.performDrop(CommonDropAdapter.java:184)    org.eclipse.jface.viewers.ViewerDropAdapter.drop(ViewerDropAdapter.java:276)    org.eclipse.ui.part.PluginDropAdapter.drop(PluginDropAdapter.java:69)    org.eclipse.swt.dnd.DNDListener.handleEvent(DNDListener.java:90)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1077)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1062)    org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:774)    org.eclipse.swt.dnd.DropTarget.Drop(DropTarget.java:456)    org.eclipse.swt.dnd.DropTarget.Drop_64(DropTarget.java:392)    org.eclipse.swt.dnd.DropTarget$3.method6(DropTarget.java:260)    org.eclipse.swt.internal.ole.win32.COMObject.callback6(COMObject.java:119)    org.eclipse.swt.internal.ole.win32.COM.DoDragDrop(Native Method)    org.eclipse.swt.dnd.DragSource.drag(DragSource.java:363)    org.eclipse.swt.dnd.DragSource.access$0(DragSource.java:289)    org.eclipse.swt.dnd.DragSource$1.handleEvent(DragSource.java:172)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)    java.lang.reflect.Method.invoke(Unknown Source)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)    org.eclipse.equinox.launcher.Main.main(Main.java:1383)    {code}  {code}  assertion failed: Cannot move '/TOP_DEFAULT_PRJ/TDQ_Libraries/Indicators/User Defined Indicators/Copy_of_Row_Count_0.1.properties'. Destination should not be under source's hierarchy.  --------------------------------------------------------------------------------------------------------------------------------------  org.eclipse.core.runtime.AssertionFailedException: assertion failed: Cannot move '/TOP_DEFAULT_PRJ/TDQ_Libraries/Indicators/User Defined Indicators/Copy_of_Row_Count_0.1.properties'. Destination should not be under source's hierarchy.    org.eclipse.core.runtime.Assert.isTrue(Assert.java:110)    org.eclipse.core.internal.resources.Resource.assertMoveRequirements(Resource.java:195)    org.eclipse.core.internal.resources.Resource.move(Resource.java:1585)    org.eclipse.core.internal.resources.Resource.move(Resource.java:1565)    org.talend.commons.utils.workbench.resources.ResourceUtils.moveResource(Unknown Source)    org.talend.core.repository.utils.XmiResourceManager.moveResource(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.moveResource(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.moveObject(Unknown Source)    org.talend.core.repository.model.ProxyRepositoryFactory.moveObject(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD$2$1.run(Unknown Source)    org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1975)    org.eclipse.core.internal.resources.Workspace.run(Workspace.java:1957)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD$2.run(Unknown Source)    org.talend.repository.RepositoryWorkUnit.executeRun(Unknown Source)    org.talend.core.repository.model.AbstractRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.repository.localprovider.model.LocalRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.core.repository.model.ProxyRepositoryFactory.executeRepositoryWorkUnit(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveObject(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveOthersNode(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.moveRepositoryNodes(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.LocalRepositoryObjectCRUD.handleDrop(Unknown Source)    org.talend.dataprofiler.core.ui.views.resources.RepositoryNodeDorpAdapterAssistant.handleDrop(Unknown Source)    org.eclipse.ui.navigator.CommonDropAdapter$1.run(CommonDropAdapter.java:194)    org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)    org.eclipse.ui.navigator.CommonDropAdapter.performDrop(CommonDropAdapter.java:184)    org.eclipse.jface.viewers.ViewerDropAdapter.drop(ViewerDropAdapter.java:276)    org.eclipse.ui.part.PluginDropAdapter.drop(PluginDropAdapter.java:69)    org.eclipse.swt.dnd.DNDListener.handleEvent(DNDListener.java:90)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1077)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1062)    org.eclipse.swt.widgets.Widget.notifyListeners(Widget.java:774)    org.eclipse.swt.dnd.DropTarget.Drop(DropTarget.java:456)    org.eclipse.swt.dnd.DropTarget.Drop_64(DropTarget.java:392)    org.eclipse.swt.dnd.DropTarget$3.method6(DropTarget.java:260)    org.eclipse.swt.internal.ole.win32.COMObject.callback6(COMObject.java:119)    org.eclipse.swt.internal.ole.win32.COM.DoDragDrop(Native Method)    org.eclipse.swt.dnd.DragSource.drag(DragSource.java:363)    org.eclipse.swt.dnd.DragSource.access$0(DragSource.java:289)    org.eclipse.swt.dnd.DragSource$1.handleEvent(DragSource.java:172)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)    java.lang.reflect.Method.invoke(Unknown Source)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)    org.eclipse.equinox.launcher.Main.main(Main.java:1383)    {code}",5
"Job  about tGenkey and tGenkeyHadoop can not run well when select ""remove[diacritical marks and lower/upper case]"" for pre-algorithm
1. create a job with input+tGenkey/tGenkeyHadoop+output  2. add one column for tGenkey/tGenkeyHadoop at Algorithm part.  3. set pre-algorithm with ""remove diacritical marks and upper/lower case"" or ""remove diacritical marks ""  4. run job.    Expected Result:  job can run well.    Actual Result:  job run failed.    note: ok on 5.3.1, no 5.3.2 build now so doesn't test,    {code}  Exception in thread ""main"" java.lang.NoClassDefFoundError: org/talend/utils/string/AsciiUtils    org.talend.windowkey.AlgoBox.removeDiacriticalMarks(AlgoBox.java:325)    org.talend.windowkey.AlgoBox.removeDMAndUpperCase(AlgoBox.java:367)    test2a.job_tgenkey_0_1.job_tGenkey.tOracleInput_1Process(job_tGenkey.java:1098)    test2a.job_tgenkey_0_1.job_tGenkey.runJobInTOS(job_tGenkey.java:1501)    test2a.job_tgenkey_0_1.job_tGenkey.main(job_tGenkey.java:1366)  Caused by: java.lang.ClassNotFoundException: org.talend.utils.string.AsciiUtils    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:424)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:357)  	... 5 more  {code}",3
"when set an unexist folder for the tDqReportRun, can't generate report doc file but show success in the log
create a tDqReportRun job, set an unexist folder for it, run this job    Except Result:  can't generate report doc file, show failed in the log    Actual Result:  can't generate report doc file, but show success in the log",8
"on the ""cheat sheet selection dialog"" (get by Help-->cheat sheets...)doesn't contains match anaysis under ""Talend->Analysis"" 
1. click Help-->cheat sheets...  2. check the pop up dialog, under ""Talend-Cheat sheets""-->analysis,    Actual Result  no match analysis here    Expected Result:  on the cheat sheet tab list have match analysis, may be we should also show here.",5
"Cannot select table from a file connection in the match analysis wizard
# create a file connection  # Open the match analysis wizard with the ""new analysis"" menu and click ""next""  # select the ""metadata"" table in the file connection and click ""finish""    This gives the following exception and no data appear in the analysis editor.     java.lang.ClassCastException: org.talend.core.repository.model.repositoryObject.MetadataTableRepositoryObject cannot be cast to org.talend.core.model.metadata.MetadataColumnRepositoryObject  at org.talend.dataprofiler.core.ui.editor.analysis.MatchMasterDetailsPage.translateNodeIntoModelElement(MatchMasterDetailsPage.java:1083)  at org.talend.dataprofiler.core.ui.editor.analysis.MatchMasterDetailsPage.translateSelectedNodeIntoModelElement(MatchMasterDetailsPage.java:1063)  at org.talend.dataprofiler.core.ui.editor.analysis.MatchMasterDetailsPage.refreshColumnAndData(MatchMasterDetailsPage.java:842)  at org.talend.dataprofiler.core.ui.editor.analysis.MatchMasterDetailsPage.setSelectedNodes(MatchMasterDetailsPage.java:838)  at org.talend.dataprofiler.core.ui.wizard.analysis.column.MatchWizard.updateAnalysisBySelectedNode(MatchWizard.java:92)  at org.talend.dataprofiler.core.ui.wizard.analysis.column.MatchWizard.openEditor(MatchWizard.java:79)  at org.talend.dataprofiler.core.ui.wizard.AbstractWizard.performFinish(AbstractWizard.java:67)  at org.eclipse.jface.wizard.WizardDialog.finishPressed(WizardDialog.java:811)  at org.eclipse.jface.wizard.WizardDialog.buttonPressed(WizardDialog.java:430)  at org.eclipse.jface.dialogs.Dialog$2.widgetSelected(Dialog.java:624)  at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1258)  at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3540)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3161)  at org.eclipse.jface.window.Window.runEventLoop(Window.java:825)  at org.eclipse.jface.window.Window.open(Window.java:801)  at org.talend.dataprofiler.core.ui.action.actions.CreateNewAnalysisAction.run(CreateNewAnalysisAction.java:112)  at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)  at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584)  at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501)  at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411)  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1258)  at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:3540)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3161)  at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)  at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)  at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)  at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)  at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)  at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)  at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)  at org.talend.rcp.intro.Application.start(Application.java:145)  at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:601)  at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)  at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)  at org.eclipse.equinox.launcher.Main.run(Main.java:1407)  at org.eclipse.equinox.launcher.Main.main(Main.java:1383)    ",3
"incomplete matching distances in match analysis editor
See attached screen capture",5
"improve the dialog message
when do empty recyle bin",1
"Update component configuration file for TDI-28502
Now we have supported hiding columns(either custom or non-custom type) in column list controller by *FILTER* attribute.    So if you want to hide T_GEN_KEY column of tGenKeyHadoop you can modify it's configuration file like below:  {code:xml}  ...  <PARAMETER NAME=""ALGO"" FIELD=""TABLE"" SHOW=""true"" NUM_ROW=""16"" NB_LINES=""3"">      <ITEMS>          <ITEM NAME=""PRECOLUMN"" FIELD=""COLUMN_LIST"" FILTER=""CUSTOM_COLUMNS:T_GEN_KEY""/>          ...      </ITEMS>  </PARAMETER>  ...  {code}    or simplly:    {code:xml}  ...  <PARAMETER NAME=""ALGO"" FIELD=""TABLE"" SHOW=""true"" NUM_ROW=""16"" NB_LINES=""3"">      <ITEMS>          <ITEM NAME=""PRECOLUMN"" FIELD=""COLUMN_LIST"" FILTER=""CUSTOM_COLUMNS:*""/>          ...      </ITEMS>  </PARAMETER>  ...  {code}    If you want to hide more than one column; for instance, you want to hide all custom columns of tMatchGroupHadoop  you can modify it's configuration file like below:  {code:xml}  ...  <PARAMETER FIELD=""TABLE"" NAME=""JOIN_KEY"" NB_LINES=""3"" NUM_ROW=""12"" REQUIRED=""true"" SHOW=""true"">      <ITEMS>          <ITEM FIELD=""COLUMN_LIST"" NAME=""INPUT_COLUMN"" FILTER=""CUSTOM_COLUMNS:GID,GRP_SIZE,MASTER,SCORE,MATCHING_DISTANCES"" />          ...      </ITEMS>  </PARAMETER>  ...  <PARAMETER FIELD=""TABLE"" NAME=""BLOCKING_DEFINITION"" NB_LINES=""2"" NUM_ROW=""22"" REQUIRED=""false"">      <ITEMS>          <ITEM FIELD=""COLUMN_LIST"" NAME=""INPUT_COLUMN"" FILTER=""CUSTOM_COLUMNS:GID,GRP_SIZE,MASTER,SCORE,MATCHING_DISTANCES"" />      </ITEMS>  </PARAMETER>  ...  {code}    or simplly:    {code:xml}  ...  <PARAMETER FIELD=""TABLE"" NAME=""JOIN_KEY"" NB_LINES=""3"" NUM_ROW=""12"" REQUIRED=""true"" SHOW=""true"">      <ITEMS>          <ITEM FIELD=""COLUMN_LIST"" NAME=""INPUT_COLUMN"" FILTER=""CUSTOM_COLUMNS:*"" />          ...      </ITEMS>  </PARAMETER>  ...  <PARAMETER FIELD=""TABLE"" NAME=""BLOCKING_DEFINITION"" NB_LINES=""2"" NUM_ROW=""22"" REQUIRED=""false"">      <ITEMS>          <ITEM FIELD=""COLUMN_LIST"" NAME=""INPUT_COLUMN"" FILTER=""CUSTOM_COLUMNS:*"" />      </ITEMS>  </PARAMETER>  ...  {code}",2
"Export babili translations into 5.3 branch of GIT
nan",2
"import exported jrxml file get many errors--but can imported
1. in one project, import build-in jrxml.  2. export them.  3. delete all the jrxml  4. import the exported one.    Expected Result:  should import no errors.    Actual Result:  get many errors in error log, but can import it.    org.talend.dataprofiler.core.ui.imex.model.FileSystemImportWriter  - the ModelElemnt of property is null!    ",1
"keep the same decimal precision on chart and table for benford indicator
1.create a column analysis with benford indicator.  2.run this analysis,turn to result page,the decimal precision on chart is not same as on table.  3.generate a report form this analysis. the decimal precision on chart is not same as on table too.  ",8
"View Database Structure can not show table and view for hive connection (test by CDH4)
1. create a cdh4 standalone connection.  2. preview one table, works.  3. turn to data explorer, right click on the connection-->View Database Structure   4. result: database structure tab open, but no tables show,refer to pic attached. get warning.  5. restart studio, redo step3.    Expected Result:  can show tables well.    Actual Result:  can not show tables, after restart step 5 will get error,  ",8
"Catalog overview analysis with hive(HDP1.2 embedded) connection filter table is invalid
Catalog overview analysis with hive(HDP1.2 embedded) connection filter table is invalid",8
"The popup message is not correct when renaming a opened Jrxml
1, use the Jrxml in some report  2, open the jrxml file  3, select "" rename"" on the right-click menu  4, the popup message is: ""!!! RenameJrxmlFileAction.jrxmlFileOpening!!!""    Should be some meaningful message.",3
"when reload table list on the hdp connection, get error
org.talend.cwm.compare.exception.ReloadCompareException: java.lang.NullPointerException  at org.talend.cwm.compare.factory.comparisonlevel.CatalogSchemaComparisonLevel.reloadElementOfPackage(CatalogSchemaComparisonLevel.java:313)  at org.talend.cwm.compare.factory.comparisonlevel.CatalogSchemaComparisonLevel.getSavedReloadObject(CatalogSchemaComparisonLevel.java:183)  at org.talend.cwm.compare.factory.comparisonlevel.CatalogSchemaComparisonLevel.compareWithReloadObject(CatalogSchemaComparisonLevel.java:148)  at org.talend.cwm.compare.factory.comparisonlevel.AbstractComparisonLevel.reloadCurrentLevelElement(AbstractComparisonLevel.java:186)  at org.talend.cwm.compare.ui.actions.ReloadDatabaseAction$1$1.run(ReloadDatabaseAction.java:159)  at org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)  at org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134)  at org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660)  at org.eclipse.jface.operation.ModalContext$ModalContextThread.block(ModalContext.java:173)  at org.eclipse.jface.operation.ModalContext.run(ModalContext.java:388)  at org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)  at org.talend.dataprofiler.core.ui.progress.ProgressUI.popProgressDialog(ProgressUI.java:54)  at org.talend.dataprofiler.core.ui.progress.ProgressUI.popProgressDialog(ProgressUI.java:38)  at org.talend.cwm.compare.ui.actions.ReloadDatabaseAction.run(ReloadDatabaseAction.java:186)  at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)  at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584)  at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501)  at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411)  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)  at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)  at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)  at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)  at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)  at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)  at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)  at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)  at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)  at org.talend.rcp.intro.Application.start(Application.java:141)  at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)  at java.lang.reflect.Method.invoke(Unknown Source)  at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)  at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)  at org.eclipse.equinox.launcher.Main.run(Main.java:1407)  at org.eclipse.equinox.launcher.Main.main(Main.java:1383)  Caused by: java.lang.NullPointerException  at java.util.Hashtable.put(Unknown Source)  at java.util.Properties.setProperty(Unknown Source)  at java.lang.System.setProperty(Unknown Source)  at org.talend.core.model.metadata.builder.database.JavaSqlFactory.doHivePreSetup(JavaSqlFactory.java:410)  at org.talend.metadata.managment.connection.manager.HiveConnectionManager.createHiveEmbeddedConnection(HiveConnectionManager.java:174)  at org.talend.metadata.managment.connection.manager.HiveConnectionManager.createConnection(HiveConnectionManager.java:70)  at org.talend.core.model.metadata.builder.util.MetadataConnectionUtils.checkConnection(MetadataConnectionUtils.java:129)  at org.talend.core.model.metadata.builder.util.MetadataConnectionUtils.checkConnection(MetadataConnectionUtils.java:285)  at org.talend.core.model.metadata.builder.database.DqRepositoryViewService.loadTables(DqRepositoryViewService.java:333)  at org.talend.core.model.metadata.builder.database.DqRepositoryViewService.loadTables(DqRepositoryViewService.java:323)  at org.talend.core.model.metadata.builder.database.DqRepositoryViewService.getTables(DqRepositoryViewService.java:192)  at org.talend.cwm.compare.factory.comparisonlevel.CatalogSchemaComparisonLevel.reloadElementOfPackage(CatalogSchemaComparisonLevel.java:292)  ... 43 more  ",8
"get different result with summary statistics indicators when analyze DB2
1.create a DB2 connection(192.168.30.75)  2.create an analysis with this connection  3.select column Talend->TEST1->ID,select summary statistics indicators.  4.run this anaysis with sql then java engine.   turn to result page.Inter Quartile Range and Low Quartile indicator have different result.",5
"create new pattern from pattern test view get a NullPointerException
NullPointerException as below:    java.lang.NullPointerException    org.talend.dataprofiler.core.pattern.actions.CreatePatternAction.run(CreatePatternAction.java:98)    org.talend.dataprofiler.core.ui.views.PatternTestView$6.widgetSelected(PatternTestView.java:358)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.rcp.intro.Application.start(Application.java:141)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)    java.lang.reflect.Method.invoke(Method.java:597)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)  ",1
"the icon on force delete dialog is not correct for sql rules
1. create a table rule analysis, add a sql rule  2. delete sql rule to Recycle Bin.  3. try to empty Recycle bin, get a force delete dialog.    Expected Result:  should show the icon for sql rule correctly.    Actual Result:  the icon is not correct for sql rule.",3
"No warning icon shows for the corresponding data in the '%Match' column of 'Analysis Result' page.
nan",5
"""Average Length "" can not show correct result in evolution report.
1. create a column analysis, add text indicator.  2. create report about the analysis.  3. generate report with Evolution template.      Actual Result:  in report, ""Average Length"" result is not correct.    Expected Result:  should show result correctly.  ",1
"improve force delete a analysis and the java udi its used
test on Talend-Studio-r113457-V5.3.2 and trunk    1. create a java udi  2. create a analysis with java engine, and run it  3. delete analysis and udi  4. empty recycle bin  5. in the dialog,select force delete, and finish, get error  java.lang.NullPointerException  at org.talend.dataprofiler.core.ui.action.actions.DQDeleteAction.logicDeleteDependeny(DQDeleteAction.java:550)  at org.talend.dataprofiler.core.ui.action.actions.DQDeleteAction.physicalDeleteDependencies(DQDeleteAction.java:531)  at org.talend.dataprofiler.core.ui.action.actions.DQDeleteAction.physicalDelete(DQDeleteAction.java:405)  at org.talend.dataprofiler.core.ui.action.actions.DQDeleteAction.run(DQDeleteAction.java:244)  at org.talend.dataprofiler.core.ui.action.actions.DQEmptyRecycleBinAction.run(DQEmptyRecycleBinAction.java:67)  at org.eclipse.jface.action.Action.runWithEvent(Action.java:498)  at org.eclipse.jface.action.ActionContributionItem.handleWidgetSelection(ActionContributionItem.java:584)  at org.eclipse.jface.action.ActionContributionItem.access$2(ActionContributionItem.java:501)  at org.eclipse.jface.action.ActionContributionItem$5.handleEvent(ActionContributionItem.java:411)  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)  at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)  at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)  at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)  at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)  at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)  at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)  at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)  at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)  at org.talend.rcp.intro.Application.start(Application.java:150)  at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)  at java.lang.reflect.Method.invoke(Unknown Source)  at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)  at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)  at org.eclipse.equinox.launcher.Main.run(Main.java:1407)  at org.eclipse.equinox.launcher.Main.main(Main.java:1383)      issue2: when the analysis and its udi all in the recycle bin, and no other items use them, should do empty recycle bin directly without confirm dialog  ",5
"Create Junit for r113086
1, create junit for the added public method in EObjectHelper;  2, modify the junit of the modified method in DQDeleteHelper.",3
"cmdline project can not found the jar which manually added to  lid/java
1. log on studio, create db2 connection(no jars in studio, so should manually added to lib/java)  2. create report about the connection.  3. exit the project.  4. log on a cmdline project (commandline.bat and Talend-Studio-win-x86_64.exe in same folder, so the jar already exist)  5. import the report created on step 2.  6. try to execute Report, get error.    {code}  !STACK 0  java.lang.ClassNotFoundException: com.ibm.db2.jcc.DB2Driver    org.eclipse.osgi.internal.loader.BundleLoader.findClassInternal(BundleLoader.java:506)    org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:422)    org.eclipse.osgi.internal.loader.BundleLoader.findClass(BundleLoader.java:410)    org.eclipse.osgi.internal.baseadaptor.DefaultClassLoader.loadClass(DefaultClassLoader.java:107)    java.lang.ClassLoader.loadClass(ClassLoader.java:356)    java.lang.Class.forName0(Native Method)    java.lang.Class.forName(Class.java:186)    org.talend.cwm.db.connection.ConnectionUtils.getClassDriver(ConnectionUtils.java:580)    org.talend.cwm.db.connection.ConnectionUtils.createConnection(ConnectionUtils.java:173)    org.talend.cwm.db.connection.ConnectionUtils.checkConnection(ConnectionUtils.java:224)    org.talend.cwm.db.connection.ConnectionUtils.isConnectionAvailable(ConnectionUtils.java:354)    org.talend.dataquality.reporting.engine.ReportDocGenerator.validateReport(ReportDocGenerator.java:309)    org.talend.dataquality.reporting.engine.ReportDocGenerator.generate(ReportDocGenerator.java:185)    org.talend.dataprofiler.core.tdq.action.LocalReportDocGenerator.generate(LocalReportDocGenerator.java:130)    org.talend.datacleansing.core.service.TDQReportService.executeReport(TDQReportService.java:71)    org.talend.commandline.command.CommandProcessor.executeReport(CommandProcessor.java:556)    org.talend.commandline.command.ExtensionCommandSwitch.caseExecuteReportCommand(ExtensionCommandSwitch.java:79)    org.talend.commandline.client.command.extension.AbstractExtensionCommandSwitch.doSwitch(AbstractExtensionCommandSwitch.java:35)    org.talend.commandline.command.CommandProcessorSwitch.caseExtensionCommand(CommandProcessorSwitch.java:161)    org.talend.commandline.client.util.CommandAbstractSwitch.doSwitch(CommandAbstractSwitch.java:70)    org.talend.commandline.command.CommandConsumer.executeCommand(CommandConsumer.java:57)    org.talend.commandline.command.CommandConsumer.execute(CommandConsumer.java:35)    org.talend.commandline.mode.ServerCommandLine$CommmandConsumerRunnable.run(ServerCommandLine.java:139)    java.lang.Thread.run(Thread.java:722)    !ENTRY org.talend.platform.logging 4 0 2014-01-21 15:47:00.773  !MESSAGE 2014-01-21 15:47:00,772 ERROR org.talend.dataquality.reporting.engine.ReportDocGenerator  - Run analysis error: abc_1 : Driver not found: com.ibm.db2.jcc.DB2Driver      !ENTRY org.talend.platform.logging 1 0 2014-01-21 15:47:00.858  !MESSAGE 2014-01-21 15:47:00,858 INFO  org.talend.datacleansing.core.service.TDQReportService  - Generated successfully, the report document is store in null      !ENTRY org.talend.platform.logging 1 0 2014-01-21 15:49:03.297  !MESSAGE 2014-01-21 15:49:03,296 INFO  org.talend.dataprofiler.datamart.utils.DatamartUtils  - The structure of talend_dq113525 EXIST, do you want to handle the connection?      !ENTRY org.talend.platform.logging 4 0 2014-01-21 15:49:03.330  !MESSAGE 2014-01-21 15:49:03,325 ERROR org.talend.cwm.db.connection.ConnectionUtils  - com.ibm.db2.jcc.DB2Driver  {code}",8
"report about content compare analysis can not generate when set internationalization  as French
1. set internationalization as French(works well on set English).  2. create a report about content compare analysis.  3. try to generate report with ""Basic"" template      Expected Result:  report generate work well.    Actual Result:  can not get generate report, get errors.",5
"The  'Could not connect to your database alias; the exact message was:..' error message poped up after previewing the tables about informix connection.
nan",8
"Data Profiling - Column Analysis fails with Netezza
From Ticket:    When I try to run a column analysis containing a pattern low frequency indicator on a Netezza table, I get the following error: ""Fail to run the analysis: Address_Columns_Analysis. Error message: At least one analysis execution failed, Check the error logs for more details."" I have attached the error log.    It appears the query for the indicator Pattern Low Frequency Table is unable to be created. However, when I look at the indicator definition under the settings, I see the following SQL template for the Default Database: ""SELECT <%=__COLUMN_NAMES__%>, COUNT(*) c FROM <%=__TABLE_NAME__%> t <%=__WHERE_CLAUSE__%> GROUP BY <%=__COLUMN_NAMES__%> ORDER BY c ASC"" When I replace the expression templates with my table values, I am able to execute it in a separate query editor.    We are able to connect to Netezza using Data Integration and the correct driver has been placed under the lib/java folder as well as added  as an Extra Class path under Windows -> Preferences -> Talend -> Data Explorer -> JDBC Drivers.    We need to be able to execute analysis with Pattern Frequency Stats as well as the other system indicators on Netezza tables    Attaching provided workspace log as well.",3
"Add CDH5 Support in Profiling
nan",2
"change the match rule editor icon in the export/import item dialog
see attachment image",2
"password displays
When I right-click in analysis results and click ""Generate Job"" and select ""generate an ELT job to get only invalid rows"", the input component in the generated job displays my password (instead of *********) in the component settings area.",5
"Validate that DQ (M/R) components can run on CDH5
Main components to check are:  - tMatchgroup  - tStandardizeRow  - tGenKey    No need to validate standard tGenKeyHadoop and tMatchGroupHadoop components. They're going to be deprecated. ",8
"Add support for HDP 2.1 
Profiling + Data Preview +  M/R Components",13
"Add support for Pivotal HD 2.0
We must support Pivotal -HD 1.1- *2.0*  (Profiling + preview + components)",13
"Check that DQ M/R components can run with Pivotal HD
Confirm that the DQ M/R components can run with Pivotal HD 2.0  (Don't check tXXHadoop components)",5
"Add support of Kerberos when doing Hive profiling
nan",8
"Investigate profiling with Apache Stinger
The purpose of this research task is to evaluate the Hive profiler on http://hortonworks.com/labs/stinger/  The HDP 2.0 sandbox does not have Stinger activated by default, but HW offers a ""technical preview"" which does not seem hard to install: http://public-repo-1.hortonworks.com/HDP-LABS/Projects/Stinger/StingerTechnicalPreviewInstall.pdf    This work item does not require any commit but you may need to patch the studio or run from the dev environment in order to be able to connect to Hive.   ",20
"DQ Reports generate report of wrong person 
When 2 different persons are generating reports from different time zones, both will get the same reports.    Ex.  One person is generating DQ reports in New York (Eastern Time), and another is generating reports from San Francisco (Pacific Time).  If both happen to be generating the same report using tDqReportRun from different integration jobs.  Then the person in SanFrancisco (later time zone) will start receiving reports of the person in the Eastern Time zone.",13
"fixed junit fail
We maybe break some junit when do feature or fixed some bug.  Fixed them on this task, and improve those junit make them only care about what will be input and what will be output or get.  About how we get those result we should ignore it so that our junit will not easy to be broken.  Note that we should explain what change is make this break when we commite some code to fix one junit.",1
"Run job which contains tMatchgrouphadoop will failed
nan",8
"Branding update
Update branding images in studio and DQ portal.  Review other required changes see PMUP-149",3
"Special characters in analysis name did not show correctly in repository
nan",5
"Unable to execute regular expression functions against Teradata
I am using the Talend Open Studio for Data Quality 5.4.1.r111943 on a Windows XP laptop connecting to a Teradata database (version 13.10.04.14).    When attempting to execute any of the regular expressions against a column in a Teradata table, I receive the following error message:    java.lang.NullPointerException                  at com.teradata.jdbc.TeraStatement.parseCreateProcedure(TeraStatement.java:197)                  at com.teradata.jdbc.jdbc_3.ifjdbc_4.TeraLocalStatement.parseCreateProcedure(TeraLocalStatement.java:569)                  at com.teradata.jdbc.jdbc_3.ifjdbc_4.TeraLocalStatement.executeQuery(TeraLocalStatement.java:81)                  at com.teradata.jdbc.jdbc_3.ifjdbc_4.TeraLocalStatement.executeQuery(TeraLocalStatement.java:110)                  at org.talend.dataprofiler.core.ui.views.PatternTestView.testRegularText(Unknown Source)                  at org.talend.dataprofiler.core.ui.views.PatternTestView.access$0(Unknown Source)                  at org.talend.dataprofiler.core.ui.views.PatternTestView$8.widgetSelected(Unknown Source)                  at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)                  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)                  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)                  at org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)                  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)                  at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)                  at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)                  at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)                  at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)                  at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)                  at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)                  at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)                  at org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)                  at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)                  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)                  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)                  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)                  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)                  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)                  at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)                  at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)                  at java.lang.reflect.Method.invoke(Unknown Source)                  at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)                  at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)                  at org.eclipse.equinox.launcher.Main.run(Main.java:1407)  ",5
"some problem about report
1. ColumnSet basic report of html type in DQPortal, can't show the result in the table, but in pdf file, it is ok. see: cs_basic_html.png and cs_basic_pdf.png  2. in the evolution report, the first point of the line is ahead of the time in the x axis, the time should ahead of the point. see: column_evolution.png, column_set_evolution.png, overview_evolution.png, dqrule_evolution.png",3
"Refactor & Junit for Hive handlers
Now, this hierarchy is wrong.   {code:java}  public class HiveYarnHandler extends HortonWorksHandler {  {code}    Refactoring the code with appropriate Junits coverage.",3
"TLoqateAddressRow stalls no way to determine what the problem is
TLoqateAddressRow stalls no way to determine what the problem is  is there a way to tell the component to send any address/record to a file or reject and move on  to the next record.    Several times I ran different size batches and it just stalls no way to determine what the problem is.",8
"Threshold violation alert job on a DQ rule has incorrect wording in email message
nan",8
"Customer would like option to use Oracle with service name in DQ Reports
Customer would like to have the option to select ""Oracle with Service Name"" and only Oracle with SID is currently available for DQ reports.    The ""Database connection settings"" folder in the report editor must be adapted to this requirement.  Same thing for the Reporting preference page.     There are two things to do:   # add the different ways to connect to Oracle   # allow the user to edit directly the URL (like we can edit it in the new connection wizard)    For 5.5, we'll only add the service name option and we won't modify the URL behavior.   The other features will be done in 5.6.",2
"The ""Report generation failed"" dialog pops up When run basic report about column content comparison analysis.
1.Start studio.  2.Create one column content comparison analysis.  3.Create  basic report with create analysis of last step.  4.Run report.    Expected result:  The report generated successfully and no error shows.  Actual result:  The report cannot be run successfully. See attachment error.jpg and column content comparison.txt  ",5
"Improve Datamart settings
Customer would like to have the option to select ""Oracle with Service Name"" and only Oracle with SID is currently available for DQ reports.    The ""Database connection settings"" folder in the report editor must be adapted to this requirement.  Same thing for the Reporting preference page.     There are two things to do:   # add the different ways to connect to Oracle   # allow the user to edit directly the URL (like we can edit it in the new connection wizard)    notes:  - the url field is editable for all databases (not only oracle)  - when the url is edited, the values of the server, database, schema and port should be retrieved into the ""server"", ""database"", ""schema"" and ""port"" fields.  - display a warning if the URL is invalid (syntactically)  - like in the connection wizard, the fields are editable, only the label in front of the fields are greyed out (in order to show that they are not required to be filled in - they are filled in automatically)",13
"Removing DB selection in Match Analysis causes ""Progress Information"" window to loop
I have created a match analysis in the profiler.  I decided to change the data source, so I removed the check mark for the existing DB and when I did that, the ""Progress Information"" window keeps popping up (see attachment).  It seems to be in a loop.",8
"Null result for Range (in summary indicators) when the first data is null and in java mode
1, prepare the data in the table: make the first data of the column is: null, the following data can have values.  2, create a summary analysis to analyze this column , and select java mode to run it.  3, the result of the range is : null , which should not be(in sql mode ,the value is not null)    FOr mysql, and DB2, (maybe also other dbs),all have this problem.  this is caused only when the first data is null in table.     the related code is: MinValueIndicatorImpl line 100. (which should add judgement before just turn it to double)",1
"Report format distortion on business rule basic report
Report format distortion when viewed through the DQPortal - The labels get cut off, headers disappear in the business rule basic.    And when I export the report, I found:    1, export as PDF and RTF, it shows correct  2, export as XLS, it shows liked the this issue  3, export as JPG, failed on all kinds of reports, it shows blank dialog, in log, there has such excepiton:      12 Mar 2014 11:44:47,464 ERROR it.eng.spagobi.utilities.engines.AbstractEngineStartServlet.handleException:70 - Service execution failed  it.eng.spagobi.utilities.engines.SpagoBIEngineException: An error occurred while executing report. Check log file for more information          at it.eng.spagobi.engines.jasperreport.services.JasperReportEngineStartAction.doService(JasperReportEngineStartAction.java:111)          at it.eng.spagobi.utilities.engines.AbstractEngineStartServlet.doService(AbstractEngineStartServlet.java:53)          at it.eng.spagobi.utilities.service.AbstractBaseServlet.service(AbstractBaseServlet.java:54)          at javax.servlet.http.HttpServlet.service(HttpServlet.java:717)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:290)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)          at it.eng.spagobi.utilities.filters.SpagoBIAccessFilter.doFilter(SpagoBIAccessFilter.java:200)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:235)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:206)          at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:233)          at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:191)          at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:127)          at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:102)          at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:109)          at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:293)          at org.apache.coyote.http11.Http11Processor.process(Http11Processor.java:859)          at org.apache.coyote.http11.Http11Protocol$Http11ConnectionHandler.process(Http11Protocol.java:602)          at org.apache.tomcat.util.net.JIoEndpoint$Worker.run(JIoEndpoint.java:489)          at java.lang.Thread.run(Thread.java:636)  Caused by: it.eng.spagobi.engines.jasperreport.JasperReportEngineRuntimeException: Impossible to run report          at it.eng.spagobi.engines.jasperreport.JasperReportEngineInstance.runReport(JasperReportEngineInstance.java:124)          at it.eng.spagobi.engines.jasperreport.services.JasperReportEngineStartAction.doService(JasperReportEngineStartAction.java:101)          ... 18 more  Caused by: it.eng.spagobi.engines.jasperreport.JasperReportEngineRuntimeException: Impossible to run report          at it.eng.spagobi.engines.jasperreport.JasperReportEngineInstance.runReport(JasperReportEngineInstance.java:257)          at it.eng.spagobi.engines.jasperreport.JasperReportEngineInstance.runReport(JasperReportEngineInstance.java:122)          ... 19 more  Caused by: java.lang.RuntimeException: Error while producing jpg image of the report          at it.eng.spagobi.engines.jasperreport.exporters.JRJpegExporter.exportReport(JRJpegExporter.java:84)          at it.eng.spagobi.engines.jasperreport.JasperReportEngineInstance.runReport(JasperReportEngineInstance.java:251)          ... 20 more  Caused by: java.lang.IncompatibleClassChangeError: Found class com.sun.image.codec.jpeg.JPEGImageEncoder, but interface was expected          at it.eng.spagobi.engines.jasperreport.exporters.JRJpegExporter.exportReport(JRJpegExporter.java:74)          ... 21 more  ",5
"No response when open the basic report with column content comparison anlysis in the Dq portal
1.Start studio and create mysql database.  2.Create one column content comparison analysis.  3.Create basic report with created column content comparison.  4.Login Dq portal with tdq_user and password: tdq.  5.Select ""Redundancy Basic"" in the ""Redundancy Report"" under ""Reporting"" menu.  6.Click search icon of ""Report"".  7.Select column_content and click ""confirm"" button in the popped dialog.  8.Select ""Execute Document"" icon.  Expected result:  The report should be shown.  Actual result:  No response after clicking ""Execute Document"" icon.   (Report name: column_content    datamart: see attachment datamart.jpg  analysis configuration: column configuration.jpg  Log file of dq portal:catalina.2014-03-14.log and SpagoBIJasperReports.log)  ",5
"Unified Address Validation API
expected input: 1 address field  expected output: 1 address field (corrected) + 1 status field (string) + 1 accuracy code (returned by the vendor? or defined by Talend?) + optional list of enrichment fields (1 string in key/value format)    The initialization of the API requires some parameters:   # the address correction vendor (Enum)   # the parameters required by the vendor (key, values)     # default country (when we cannot parse the country of the input address)   # list of enrichment fields (list of fields that the vendor can provide such as location coordinates, administrative area, ...). This list is a closed list (we need to map it to the actual list of each vendor)      Wrapping existing vendors:  https://help.talend.com/display/TalendComponentsReferenceGuide54EN/tGoogleAddressRow  https://help.talend.com/display/TalendComponentsReferenceGuide54EN/tLoqateAddressRow  https://help.talend.com/display/TalendComponentsReferenceGuide54EN/tMelissaDataAddress  https://help.talend.com/display/TalendComponentsReferenceGuide54EN/tQASAddressRow      Note: This API will be used by all new components and by iPaaS.      *To be defined further*",13
"tGoogle* to provide a way to apply a license
h1. Requirement    The tGoogle* components are limited in the number of calls per day accepted by Google. A customer has purchased a licence to make more calls per day, they need to be able to apply the license in the component somehow.    Ideally we would include a facility to supply a licence (in the component, or elsewhere in the Studio)    h1. Background    See also http://www.talendforge.org/forum/viewtopic.php?id=33027  ",8
"Create a component tReservoirSampling
nan",2
"Create version 5.4.2 in Babili and populate it
nan",2
"tMatchGroup component in map/reduce job is creating different GID than standard job
I have created a map/reduce job using tMatchGroup.  The GID that is created has a different format than the GID from a standard job.    GID from map/reduce job - d79469c1-c9fe-4de3-ac7c-e3190e3f5d6e  GID from standard job - 1    I think these should be consistent and definitely prefer the GID from the standard job.    TODO:   Add a version to the component.   if the component has no version defined (after an import action), then we output a numeric GID (for backward compatibility).   if the component is just dragged&dropped on a new job, then the version is, let's say, 2.  And the output GID is of string type.    this means, nothing to change in the UI part.  ",8
"Align the tMatchGroup (M/R) features with those of the tMatchGroupHadoop
The tMatchGroupHadoop has an option to do matching with multiple passes.   This feature must exist in the tMatchGroup component.   ",20
"when generate ""Alert threshold Violation"" job, will get inform dialog, but both ""yes"" and ""no"" works for the job.
1. create a report, set datamart with mysql or oracle.  2. right click on the report-->Generate jobs->Alert threshold Violation    the job generated and will pop up a dialog(refer to pic),   no matter click ""yes' or ""no""  job can run well, so what's the difference, can we remove it  ",3
"Add support to  Cloud connector for address validation as one component.
Component name: tCloudAddressRow      # Develop the Loqate Address Provider to be included in the Address Verification API     # Develop a tLoqateCloudAddressRow component that uploads data to the cloud and retrieves the corrected data.    h1. Technical reference documentation  https://www.everythinglocation.com/api-references/    We develop first the transactional processing: https://www.everythinglocation.com/api-rest-transactional/    Before launching the address correction requests, we may check the status of the server with ""https://devsaas1/rest/version/?lqtkey=[APIKEY]"".    See also https://help.talend.com/display/TalendComponentsReferenceGuide54EN/tLoqateAddressRow      The component category is the same as the existing address components (Data Quality/Address ?)    We'll design one component for all Address providers.  The first version of the component focuses only on the available fields provided by the Adddress API.  The fields define  the output schema.     *Notes*:  - Automatically Define an output schema that contains all the columns available in the API.  - only use the ""synchronous"" calls of the API. (will use async calls in a later version)  - like tLoqateRow, define an input mapping in the properties    - like in tLoqateRow, do define an output mapping. But auto fill this mapping with all the fields available in the API (they are the same as the output schema).  The user is able to rename fields or remove fields in the output schema.   - dropdown list option in the component to choose the provider between : Loqate, Melissadata (Google only for developers)  - the output schema is currently given by the list of fields from the API (address1, address2, country, ....).     *Output code*: use vendor code for accuracy code, status code, geocoding code       *Advanced settings*:  - keep the same loqate advanced settings as in the tLoqateRow (check whether the other providers work the same way).   ",20
"Enable Cloudera Impala profiling
Cloudera Impala:  http://www.cloudera.com/content/cloudera/en/products-and-services/cdh/impala.html    Installation:  http://www.cloudera.com/content/cloudera-content/cloudera-docs/Impala/latest/Installing-and-Using-Impala/Installing-and-Using-Impala.html    SQL reference:  http://www.cloudera.com/content/cloudera-content/cloudera-docs/Impala/latest/Installing-and-Using-Impala/ciiu_langref.html    JDBC connection:   http://www.cloudera.com/content/cloudera-content/cloudera-docs/Impala/latest/Installing-and-Using-Impala/ciiu_impala_jdbc.html?scroll=impala_jdbc    Security:  We must at least support  http://www.cloudera.com/content/cloudera-content/cloudera-docs/Impala/latest/Installing-and-Using-Impala/ciiu_kerberos.html    Relation with Hive:  http://is.gd/wIcQmh",5
"Incremental display of results in the profiler
Currently, when we run an analysis, we display the results only after all indicators are computed.   Now, we must display the results in the charts as soon as they are computed.   With the SQL engine, each indicator is computed independently. Therefore we can display the results of each indicator in the charts as soon as they arrive.     Question:  - some charts require several indicators (simple statistics chart for instance). Can we build the chart dynamically? That is add bars to the chart as each indicator result comes.   - if not we need to group indicators together. Therefore, only complete charts would appear: The simple stat chart would appear as soon as all simple stat indicators are computed and the frequency table chart would be computed independently as soon as the frequency indicator is computed.     Notes:  - The user can switch between the settings page and the results page. Therefore, the chart must be incrementally displayed both in the setting page (when the focus is the setting page) and in the results page (when the focus is the results page).     - this feature only applies to SQL engine (with Java engine, there is a loop on all rows and all indicators are computed at the same time, so we can't display one indicator before the other).     - in column set analysis with SQL engine, there is only one chart with simple statistics => nothing to do (moreover, all indicators are computed together too)    - nothing to do for match analysis, all correlation analyses    - overview analysis: we won't display the results dynamically in the table.    - table display: can we dynamically display the results in a table (simple statistics for instance)?    - chart display: can we dynamically display the results in a chart (simple statistics for instance)?    - could display each bar dynamically (if possible) for     -- functional dependency    -- Business rule    -- redundancy analysis    - no need to refresh charts when we run a report (no direct synchronization exists between report execution and analysis execution)    - if there is a focus on the editor and we execute the analysis from the menu (in dq repository or in toolbar), we need to dynamically refresh the charts.    - the ""refresh"" button in the analysis editor keeps the same behavior as before: it only display the charts, there is no computation of the indicators.     *Suggestion*: display the chart with empty values at the beginning (while queries are running), then add values into the chart when they are computed. ",20
"Improve the memory management of the java engine computation engine 
See PMDQ-168  All analyses should be able to profile several GB of data without crashing or without stopping the computation (as is currently the case)",20
"Integrate the t-swoosh algorithm in the match analysis editor
nan",20
"Support MelissaData Cloud Address web service in the tCloudAddressRow component
See tCloudAddressRow specification.    For documentation purpose:   http://www.melissadata.com/address-verification/index.htm  http://www.melissadata.com/address-verification/countries.htm    ",5
"Deprecate tFuzzyJoin and tBlockedFuzzyJoin
These two components are efficiently replaced by the tRecordMatching component.   Hide them from the palette. Just keep them for backward compatibility. ",1
"reload database list about  for ""General JDBC connection about hsql Server mode"" lead to all structure lose
1. crate a General JDbc connection about hsql serve mode    server start by->java -cp ../lib/hsqldb.jar org.hsqldb.server.Server  --database.0 file:bbb --dbname.0 ww    hsql version: hsqldb-2.3.2       2. db connection show well.  3. try to ""reload database list"",    Expected Result:  should show structure well.  make sure all reload function work well.    Actual Result:  structure lose.    note: this issue show on 5.4.2-r115399, r115399-5.6.0  on 5.3.3-115069 no this issue, no more new build, dev please check this.",8
"Create missing fragments
org.talend.designer.tdqmatching.nl    Check again whether there are other missing fragments in DQ projects too. ",5
"drill down function for analysis about context dbconnection can not get correct data at certain operations
1. create a context mysql connection, make sure it has two context group,      and one group is about server 1(default context), another is about server2.      server1 and server2 has a same catalog and under the catalog have a same table(T1), but Row count in two server is different.    2. connection get tables from server1  3. create a column analysis about T1, add ""Row Count"" indicator  4. run get correct result,  drill down also is ok  5. switch context to server2  6. run analysis get ""Row Count"" from server2,        but drill down for ""Row Count"" still get from server1.      do ""Reload table list"" will solver the drill down issue on step 6.    note:  if the two context group are from same server but different catalog name, drill down in step 6 is ok.  ",2
"The tdqReportRun job can't be to run  successfully after running on remote server.
nan",5
"Create a tBatchAddressRowCloud component
We first need to enrich the Address API to support batch file processing.     The process has several steps:   # read data from input stream and prepare files (we may need several files during a stream) to be sent to the address provider.   # send the file(s) to the address provider and get the results.   # output the results in the output flow of the component     The input stream may be splitted in several files (for instance, if there is a limit to the number of rows to submit to the address provider). So, there may be the need for a size parameter in the component.   Each file can be sent independently. This means we don't need to wait for the response to the first file in order to start requesting the an address correction on the second file.   We can even think to process data in parallel: when a Talend flow is parallelized in the job editor, several files of input data must be created. Each of the file must be sent as soon as ready to the Rest API.   We must also be able to deactivate the parallel execution when the provider does not support several requests at the same time.     Once the API works and Junit are created, we can develop the tBatchAddressRowCloud component.     h1. Handle Loqate first    This component receives address records and call the loqate batch API:  https://www.everythinglocation.com/api-rest-batch/  See also https://www.everythinglocation.com/batch/list.php    This component sends a file (formatted as expected by Loqate) to the web service, retrieves the corrected addresses and output them in an output flow.   ",3
"Make TOS DQ compatible with Apache license
Attached the list of libraries to remove.   The third party library download feature must install all the required libraries when needed.     Compatibility list: http://apache.org/legal/resolved.html#category-a",5
"Upgrade Loqate component with latest library
The API had a major Schema change in 2013.   We need to upgrade the component with the latest API.     Download latest Loqate repository and check that everything works fine.  ",5
"Export babili translations into git (for 5.4.3)
nan",2
"Integrate the t-swoosh algorithm in the tMatchGroup component
{color:green}-->Request{color}    - Add a radio button in the tMatchGroup wizard to select between T-Swoosh and Simple VSR algorithms (on the same rows as the ""limit"" field)      --> when select ""VSR"", show the  ""key definition""  table with 5 columns;      --> when select ""T-swoosh"", show 2 tables: 1)  ""key definition""  table with 8 columns, 2) Default Surviviorship Rules table with 3 columns. ( the 2nd table is locate under the 1st table)   - When running the job, need to check which algorithm is selected, and use it in tMatchGroup.    - (Reuse as much as possible the composite classes of the analysis editor)   - (Reuse the same EMF model in the component as in the match rule of dq repository view)  - Make sure the import/export match rules work with these new parameters (and that we did not break the old behavior)    {color:green}-->Analyze/Design:{color}    1) UI part:  - Need to add 2 swoosh's tables in ConfigureMatchRuleDialog, the current ""Key definition"" table is different with the table in the Match analysis, and the swoosh's table maybe also can not reuse the table in the match analysis  - MatchRuleUIService is working for the tMatchGroup only, and the match analysis uses another set of table viewers.   - The chart and the preview data table no need to change    2) Model part:  - The match analysis uses: RecordMatchingIndicator, the tMatchGroup uses:  - The T-swoosh need: SurvivorShipAlgorithmParams for AnalysisMatchRecordGrouping,   - The tmatchgroup operate the match rules in its main.javajet, this means: if can not move it out to a java class( or reuse current ones), need to add the logic for swoosh in javajet too. It is better to consider how to make add different algorithm easier in future for tMatchGroup.     3) ""Chart"" part:  - The ""Chart"" button on the ConfigureMatchRuleDialog now has 2 different logics: VSR and T-swoosh. The execution behind it is different. Need to check how many percent of the code from the match analysis can be reused.     4) execute algorithm part:  - The match analysis uses : BlockAndMatchManager to execute ( in it, separate the algorithm, to use AnalysisMatchRecordGrouping or AnalysisSwooshMatchRecordGrouping). Currently the tMatchGroup overwrite ""AbstractRecordGrouping"" in its tMatchGroupIn_main.javajet, try to reuse the same logic for the match analysis. (If difficult, at least try to reuse AnalysisMatchRecordGrouping or AnalysisSwooshMatchRecordGrouping)   - In tMatchGroupIn_main.javajet, too many match related logics, check if them can be replaced by related java classes in record.linkage.     {color:green}  --> Implement:{color}  1) UI part:   - Firstly, modify the Configuration dialog:        --> add the algorithm choose button,       --> add 2 tables for swoosh: key definition, default survivorship rule (Can not reuse the table viewer : SurvivorShipTableViewer, because the component is different)            need to check for each columns in the table ( value, how to initial swoosh algorithm with them in javajet)       --> make the new tables action correct for add/remove row.      --> when select swoosh : hide the VSR related table, show 2 swoosh related table; when select VSR, hide swoosh's tables, show VSR's table.    2) Model part:     The component use the plugin: org.talend.designer.tdqmatching, so need to modify this plugin, to add the support for swoosh.    3) Chart on the config dialog:     need make ""chart"" button work correctly for each algorithm: for swoosh algorithm:     4) run job part: ",20
"Add support to Experian QAS in the tAddressRowCloud component
We need to add QAS support in the tAddressRowCloud component.   http://www.qas.com/address-verification.htm#tab_3",13
"Deprecate tMachGroupHadoop and tGenKeyHadoop
Hide these components from the default palette (move them in a hidden category)    change tMachGroupHadoop and tGenKeyHadoop to a hidden category ""Technical""        ",1
"Check that indicators can run in parallel
Column analysis can already create several connections to the database and run several queries in parallel.  Here, we must list the databases that don't support parallel queries.    And we must see list the analysis types that can't use parallel execution. ",8
"Update indicators and regexes in Talend Exchange
nan",5
"Activate Exchange indicators and regexes and rules for 6.0
Upgrade interesting extensions in Talend Exchange.",3
"english and french message for Delete inform dialog are different
1. create a dbconnection and a column analysis.  2. delete the dbconnection, then empty the Recycle Bin, check the inform dialog message    Expected Result:  it should be same    Actual Result:  not same  ",1
"Alter threshold violation can not run well when datamart is oracle and report use context parameters.
1. create a report file. in report editor  set db type: oracle with sid.  2. in the context tab, add host,port,sid, schema,user, password, and set values for each parameters,(my schema and uer is same)  3. make sure report use the context value.  4. generate report file. succssfully.  5. right click on the report to generate a ""Alter threshold violation"" job.    Expected Result:  job can run well, after set parameters for tSendMail    Actual Result  job can not run.    NOTE: if datamart use mysql, it is ok.  if datamart use oracle, but doesn't use context, it is also work well.",8
"Unify address results codes 
Different providers use different result codes for accuracy codes.  We must define our own codes and then map the codes from the providers to our codes.  That means that the user can then easily change the provider and the rest of the job (after the address component) will remain the same.   Suppose the user wants to filter some addresses given their accuracy code, with unified codes, no change is required after changing a provider.   ",13
"Create version 5.4.3 in Babili and populate it
nan",2
"add Oracle OCI support and db version in the tdqportal installer
 - add a new database type ""Oracle OCI"" in the database list of the tdqportal installer   - add a new combo ""Db Version"" in the wizard of the tdqportal installer      -Addition to the screenshots: add a browse button on the right of the database type in the second page of the wizard so that the user will provide the driver for his connection.-  -We must not provide the JDBC drivers.-  ",2
"Semantic Studio
Add semantic-aware features to the studio.     See related features: https://jira.talendforge.org/issues/?filter=18839",13
"Improve date pattern recognition and enrich the current date pattern indicator
Use these regular expression to find the appropriate data pattern.   First, a more generic pattern (a pattern that would match all date patterns) should be used to determine whether the data is in a possible date format.  Then in a second step, the more precise date pattern must be applied in order to determine the date format. ",8
"Create version 5.5.1 in Babili and populate it
nan",2
"Create version 5.5.2 in Babili and populate it
nan",2
"Profiler : Allow variables, like context variables - Part I 
Allow variables, like context variables, to be valid fields in analysis and report input fields, like date range on where clauses.    Today to run a profile over a date start/stop and then change the range requires hard coding and then changing that hardcoded value.    Concerned analysis fields:  - data filter  - number of connections per analysis    Concerned report fields:  - output folder  - output filename  - execution date range (start / end)  - logo file path    Enable context usage of contexts in TOS DQ (only use built-in contexts => no need to display the context node in dq repository view)?  is Context view reusable?     Adapt the analysis editor to display the context and allow the user to switch between contexts just as in the report editor. Add a separate section ""Context group"" in the analysis editor AND move the current context of the report editor into a new section too.",20
"try to create mysql datamart by studio, get download jar dialog pop up which not related mysql
open a report, set parameter in the report editor which datamart doesn't exist  click ""check""   get download jar dialog pop up, but the jar is not related with mysql.    NOTE:  if can not reproduce, restart studio, then re-click ""check""",8
"improvement about report
detail information refer to sub-task",8
"Add multiple pass option in standard tMachGroup
The standard version of the tMatchGroup must be aligned with its MR counterpart: we must enable the multiple-pass option.  https://wiki.talend.com/display/talenddataqualityteam/Differences+between+matching+components",3
"tCloudAddressRow improvements
- Change ""Input Address"" label to ""Mapping""   - For the ""output script"" in advanced settings, remove ""(English)"" from the label ""Latin(English)"".  Choices should be Latin/Native",8
"Add Google as a provider in tCloudAddressRow
Use the Places API from Google.  See more details in TDQ-8741",8
"some problems of datamart
nan",13
"remove plugin org.talend.dataprofiler.libraries
after  https://jira.talendforge.org/browse/TDQ-8837 ,there isn't anywhere to use 'org.talend.dataprofiler.libraries'.",1
"dqportal can not support mysql high version driver.
1. install dqportal with Talend-DQPortal-20140707_1931-V5.6.0SNAP.zip, choose mysql datamart type  2. after install finished, copy mysql-connector-java-5.1.30-bin.jar to tomcatpath/lib  3. start dqpotal.  4. try to show detail report content    Expected Result:  show report content well.    Actual Result:  can show the report list, but can not show report content.    note: if on step 2 use mysql-connector-java-5.0.8-bin.jar, it is works.    No problem when installing with the installer. ",5
"in preference page, edit status for datamart parameters should be correct(should same with report editor).
1. open preference page, go to datamart settings page   2. datamart select mysql or oracle,  3. check the ""Url"" filed status,   it is not gray, in report editor, it is gray by default.    4. when focus on ""Url' text field, ""Host"",""Port"", ""Db Name""  status no change, in report editor it turns gray.    Expected Result:   edit status should same behaviour with report editor    Actual Result:  it is not same behaviour",1
"tLaunchDQReports should not show in job Palette by default.
1. In Di perspective, open a job.  2. check the job Palette, tLaunchDQReports under ""Deprecated""    Expected Result:  the component should not show by default    Actual Result:  show the component    NOTE: on 551, we don't show it",1
"Profiler hangs after clicking on Select Data in Matching profile
I have previously created a matching profile that is using a hive table as input.  I opened the matching profile and I do not have my hive vm up.  When I click on the Select Data button, the little circle comes up and the studio shows ""Not Responding"".  I've let it sit there for about 10 minutes and it never comes back.  I have to restart the studio.  There should be a time out after a certain amount of time and this should be configurable.",5
"Create version 5.5.2 in Babili and populate it
nan",2
"Create version 5.6.0M2 in Babili and populate it
nan",2
"Export babili translations into git on 5.5 branch
nan",2
"Export babili translations into git on master branch
nan",2
"Input fields improvements in the tCloudAddressRow component
Two things to do in this feature:  # the input fields can be propagated to the output (for instance, the input schema could contain information about the customer account, etc).  # the input address mapping should be the same as for the other providers (internally, we must concatenate the different fields in order to pass a single address to the Google api)",8
"when db server is stopped, some operations can not get correct inform dialog.
1. create a match analysis about mysql dbconnection, select matching key  2. stop the mysql server , so can not connect to it.    issue 1:   try to run the match analysis, get error refer to ""match_ analsis_now.jpg""  but o 551 refer to ""match_analyis_551.jpg""    issue 2:  try to click ""refresh data"" on match analysis editor, get a dialog not any information.(ok on 551)    issue 3:  try to reload database list, try to do database compare, also on the dialog no correct information(also on 551)    ",3
"create a TUJ for TDQ-9172
This TUJ contians all case of description on TDQ-9172.",5
"Add download of required / optional packages in the TOS_DQ same as the enterprise product.
Add download of required / optional packages in the TOS_DQ same as the enterprise product.",8
"improve for the match analysis editor after integrating the t-swoosh algorithm
issue1:  change ""MDM T-Swoosh Algorithm"" to ""T-Swoosh Algorithm""    issue2:  when select ""MDM T-Swoosh Algorithm"", and select ""store on disk"" in the ""Analysis parameter""  then run analysis, get NPE  java.lang.NullPointerException  at org.talend.dataquality.record.linkage.grouping.swoosh.DQMFBRecordMerger.merge(DQMFBRecordMerger.java:63)  at org.talend.dataquality.matchmerge.mfb.MFB.execute(MFB.java:137)  at org.talend.dataquality.record.linkage.grouping.TSwooshGrouping.swooshMatch(TSwooshGrouping.java:120)  at org.talend.dataquality.record.linkage.grouping.AbstractRecordGrouping.end(AbstractRecordGrouping.java:394)  at org.talend.dq.analysis.ExecuteMatchRuleHandler.executeWithStoreOnDisk(ExecuteMatchRuleHandler.java:148)        issue3:  improve the table column width more longer in the ""Default Surviorship Rules""    issue4:  in the ""Match and Survivor"" section,   in the ""Match Rule 1"" tab, add a new item,   select string type column as ""Input column"",  select ""Largest (for numbers)"" as ""Function"",    click ""chart"" button, popup a error dialog to show user is better  java.lang.NumberFormatException  at java.math.BigDecimal.<init>(Unknown Source)  at java.math.BigDecimal.<init>(Unknown Source)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.parseNumberValue(MFBRecordMerger.java:208)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.createMergeValue(MFBRecordMerger.java:121)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.merge(MFBRecordMerger.java:62)    change the ""Confidence Weight"" to 0  click ""chart"" button, popup a error dialog to show user is better  java.lang.IllegalArgumentException: All attribute matcher weights are 0. This is an invalid setting!  at org.talend.dataquality.record.linkage.record.AbstractRecordMatcher.normalize(AbstractRecordMatcher.java:186)  at org.talend.dataquality.record.linkage.record.AbstractRecordMatcher.setAttributeWeights(AbstractRecordMatcher.java:167)    issue4:  change the text field ""Max buffer size"" show its border    issue5:  when i select hide chart from the preference page, the chart in the match analysis doesn't follow this",20
"""Phone Number Statistics"" indicator can not get result show.
1. create a column analysis. add two columns (one int, one varchar)  2. set java engine, add ""Phone Number Statistics""   3. run the analysis.    Expected Result:  analysis run success. and show result pic correctly.    Actual Result:  on top can show result for varchar type but can not for int type  on tdq can not show any result.    {code}  java.lang.reflect.InvocationTargetException    org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:477)    org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)    org.eclipse.jface.dialogs.ProgressMonitorDialog.run(ProgressMonitorDialog.java:507)    org.talend.dataprofiler.core.ui.progress.ProgressUI.popProgressDialog(ProgressUI.java:54)    org.talend.dataprofiler.core.ui.utils.pagination.PaginationInfo.renderContents(PaginationInfo.java:67)    org.talend.dataprofiler.core.ui.utils.pagination.UIPagination.refresh(UIPagination.java:121)    org.talend.dataprofiler.core.ui.utils.pagination.UIPagination.init(UIPagination.java:103)    org.talend.dataprofiler.core.ui.editor.analysis.ColumnMasterDetailsPage.createPreviewCharts(ColumnMasterDetailsPage.java:423)    org.talend.dataprofiler.core.ui.editor.analysis.ColumnMasterDetailsPage.refresh(ColumnMasterDetailsPage.java:448)    org.talend.dataprofiler.core.ui.editor.analysis.ColumnAnalysisResultPage.refresh(ColumnAnalysisResultPage.java:180)    org.talend.dataprofiler.core.ui.editor.analysis.AbstractAnalysisResultPage.fireRuningItemChanged(AbstractAnalysisResultPage.java:204)    org.talend.dataprofiler.core.ui.action.actions.RunAnalysisAction$1$2.run(RunAnalysisAction.java:252)    org.eclipse.ui.internal.UILockListener.doPendingWork(UILockListener.java:164)    org.eclipse.ui.internal.UISynchronizer$3.run(UISynchronizer.java:158)    org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)    org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:134)    org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4041)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3660)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.rcp.intro.Application.start(Application.java:155)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)  Caused by: java.lang.ClassCastException: org.jfree.chart.plot.PiePlot cannot be cast to org.jfree.chart.plot.CategoryPlot    org.jfree.chart.JFreeChart.getCategoryPlot(JFreeChart.java:830)    org.talend.dataprofiler.core.ui.utils.AnalysisUtils.createDynamicModel(AnalysisUtils.java:267)    org.talend.dataprofiler.core.ui.editor.analysis.MasterPaginationInfo.createChart(MasterPaginationInfo.java:159)    org.talend.dataprofiler.core.ui.editor.analysis.MasterPaginationInfo.render(MasterPaginationInfo.java:113)    org.talend.dataprofiler.core.ui.utils.pagination.PaginationInfo$1.run(PaginationInfo.java:59)    org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)  	... 37 more    {code}",3
"Create version 5.6.0M3 in Babili and populate it
nan",2
"Support new hadoop distributions
nan",8
"rename dbconneciton when match analysis editor open, get error.
1. create a dbconnection.  2. create a match analysis.  3. when match analysis editor open, rename dbconnection.    THIS issue also show on 551 build.    Expected Result:  should rename correctly.    Actual Result:  get error in error log and a dialog pop up.    {code}  java.lang.NullPointerException    org.talend.dataprofiler.core.ui.editor.analysis.AbstractAnalysisMetadataPage.reloadDataproviderAndFillConnCombo(Unknown Source)    org.talend.dataprofiler.core.ui.editor.analysis.AnalysisEditor$3.handle(Unknown Source)    org.talend.dataprofiler.core.ui.events.EventManager.publish(Unknown Source)    org.talend.dataprofiler.core.ui.utils.WorkbenchUtils.nodifyDependedAnalysis(Unknown Source)    org.talend.dataprofiler.core.ui.editor.connection.ConnectionEditor.doSave(Unknown Source)    org.eclipse.ui.internal.SaveableHelper$2.run(SaveableHelper.java:151)    org.eclipse.ui.internal.SaveableHelper$5.run(SaveableHelper.java:277)    org.eclipse.jface.operation.ModalContext.runInCurrentThread(ModalContext.java:464)    org.eclipse.jface.operation.ModalContext.run(ModalContext.java:372)    org.eclipse.jface.window.ApplicationWindow$1.run(ApplicationWindow.java:759)    org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)    org.eclipse.jface.window.ApplicationWindow.run(ApplicationWindow.java:756)    org.eclipse.ui.internal.WorkbenchWindow.run(WorkbenchWindow.java:2600)    org.eclipse.ui.internal.SaveableHelper.runProgressMonitorOperation(SaveableHelper.java:285)    org.eclipse.ui.internal.SaveableHelper.runProgressMonitorOperation(SaveableHelper.java:264)    org.eclipse.ui.internal.SaveableHelper.savePart(SaveableHelper.java:156)    org.eclipse.ui.internal.EditorManager.savePart(EditorManager.java:1369)    org.eclipse.ui.internal.WorkbenchPage.savePart(WorkbenchPage.java:3334)    org.eclipse.ui.internal.WorkbenchPage.saveEditor(WorkbenchPage.java:3347)    org.eclipse.ui.internal.SaveAction.run(SaveAction.java:76)    org.eclipse.jface.action.Action.runWithEvent(Action.java:498)    org.eclipse.jface.commands.ActionHandler.execute(ActionHandler.java:119)    org.eclipse.core.commands.Command.executeWithChecks(Command.java:476)    org.eclipse.core.commands.ParameterizedCommand.executeWithChecks(ParameterizedCommand.java:508)    org.eclipse.ui.internal.handlers.HandlerService.executeCommand(HandlerService.java:169)    org.eclipse.ui.internal.keys.WorkbenchKeyboard.executeCommand(WorkbenchKeyboard.java:468)    org.eclipse.ui.internal.keys.WorkbenchKeyboard.press(WorkbenchKeyboard.java:786)    org.eclipse.ui.internal.keys.WorkbenchKeyboard.processKeyEvent(WorkbenchKeyboard.java:885)    org.eclipse.ui.internal.keys.WorkbenchKeyboard.filterKeySequenceBindings(WorkbenchKeyboard.java:567)    org.eclipse.ui.internal.keys.WorkbenchKeyboard.access$3(WorkbenchKeyboard.java:508)    org.eclipse.ui.internal.keys.WorkbenchKeyboard$KeyDownFilter.handleEvent(WorkbenchKeyboard.java:123)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Display.filterEvent(Display.java:1253)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1052)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1077)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1062)    org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1103)    org.eclipse.swt.widgets.Text.sendKeyEvent(Text.java:1427)    org.eclipse.swt.widgets.Widget.sendKeyEvent(Widget.java:1099)    org.eclipse.swt.widgets.Widget.wmChar(Widget.java:1508)    org.eclipse.swt.widgets.Control.WM_CHAR(Control.java:4268)    org.eclipse.swt.widgets.Text.WM_CHAR(Text.java:2175)    org.eclipse.swt.widgets.Control.windowProc(Control.java:4160)    org.eclipse.swt.widgets.Text.windowProc(Text.java:2170)    org.eclipse.swt.widgets.Display.windowProc(Display.java:4873)    org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)    org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:2459)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3655)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)    {code}  ",5
"Always compute the group quality in tMatchGroup (mr and standard)
The group quality is not correctly computed when doing multiple passes. The chosen way to fix this issue is to always compute the group quality column.       no select ""separate"" option on the 1st tMatchGroup ,select ""separate"" on the 2nd tMatchgroup. the result of GRP_QUALITY is incorrect.it doesn't consider the 1st tMatchGroup. ",8
"Export babili translations into git on master branch
nan",2
"Let the installer add semantic indexes to ElasticSearch
How to setup the semantic repositories:  # Use ElasticSearch provided in the unified platform (default installation with the installer)      The main task is to provide the indexes into the ES server provided by TAC.   And test that everything works fine.  TAC will upgrade ES that is used in TAC. We need to sync with them. ",3
"Business rule anaysis do a redundant row count query for each Sql rule.
1. create a Business rule analysis  2. add more than one sql rule   3. run it, after finished check the error log, for each rule we have a query like-->SELECT COUNT(*) from tableName.     in fact we have a row count indicator to execute this.  refer to  log attached.    also show on 551",5
"Error occurred when finish editing connection using by a job 
nan",3
"Set the default value of ""hide groups less than"" to 2 instead of 1
Set this value to 2 instead of 1 in the match wizard and in the match analysis editor.  Most of the time, users only  care about duplicates. ",3
"issue for dynamic show result of analysis
issue1 (about Dq Rule analysis).   table rule analysis, add one table, 6 rules and set ""Number of connections per analysis""=2. ""Business Rules per page""=5 (set in preference)  but I get the 6 rules at same time      issue2 (about Column analysis).   when we focus on ""Analysis Results"" page, run analysis with benford law indicator, the blue pot will lose after run finished, the can not back anymore.    issue3 (about Column analysis).   when create a new analysis, before run it, both  table chart and pic chart all is empty,what about re-run analysis?   after click run  (1). Summary indicator will set value in table chart NAN,pic chart empty,  Simple/Text indicator only pic chart empty, then show result from empty then dynamic show it, table chart refresh from the current existing status.    (2). for [pattern]Frequency indicator, soundex indicator, benford law indicator both table chart and pic chart only do refresh--not from empty then dynamic show it.    issue4 (about Column analysis).  during running, benford law indicator bar chart will small and at the bottom show redundant words",8
"Fix the out of memory issue when running match analysis
Implement RecordIterator for database resultset and file delimited, use iterator instead of java collection when running the analysis in both VSR and swoosh algorithm.    SKype discussion:  {quote}  [5:47:09 PM] Sebastiao Correia: oh, I see that VSR has also the same issue  [5:47:29 PM] Sebastiao Correia: maybe, we don't need Franois  [5:48:03 PM] : yes, when I test on my computer, vsr have the same issue with t-swoosh  [5:49:54 PM] Mingli Zhao:   There are two kind of tests till now (with Liu's help)  1. Set memory limit in studio launch configuration (-Xmx 1024),  there will be out of memory issue, after analyzed with MAT, Liu summarized the place where the problem is on JIRA. this issue happens both on VSR and T-Swoosh    2. NOT setting the memory limit in studio launch configuration, it will be ""GC overhead limit exceeded"" like I wrote on JIRA. In this case the MAT cannot profile the file which is about 6 GM size .  [5:50:28 PM] Sebastiao Correia: ok  [5:50:43 PM] Sebastiao Correia: the error does not seem related to the algorithms here  [5:50:56 PM] : yes, there a point need to be attention, my computer is windows it maybe different with linux(mzhao's computer)  [5:51:14 PM] Sebastiao Correia: it rather seems to appear when we read the result set of a database connection  [5:51:52 PM] : for test 1:   handleRow(oneRow);  [5:52:06 PM] : will have problem:  [5:52:09 PM] Sebastiao Correia: ah yes  [5:52:16 PM] Sebastiao Correia: it will store all rows in memory  [5:52:24 PM] Sebastiao Correia: in dataFromTable  [5:52:30 PM] :     protected void handleRow(Object[] oneRow) throws Exception {          if (storeOnDisk) {              storeOnDiskHandler.handleRow(oneRow);          } else {              dataFromTable.add(oneRow);          }      }  [5:52:31 PM] : yes  [5:52:38 PM] : store in a List  [5:54:30 PM] Mingli Zhao: yes, that's the current way we compute it.  [5:55:05 PM] Mingli Zhao: maybe we can improve it by handle row by row without store it when run the analysis.  [5:55:37 PM] Mingli Zhao: but we have to consider the case when ""block key"" is set.  [5:56:11 PM] Sebastiao Correia: yes, I think it can be improved  [5:56:48 PM] Sebastiao Correia: the component had been improved a lot some time ago in order to avoid storing everything in memory  [5:56:58 PM] Sebastiao Correia: I think we should at least do the same  [5:57:17 PM] Sebastiao Correia: If I remember well, Yin had worked on the component optimization  [5:58:44 PM] (YinYueyan.talendbj): :P the last component optimization was different with this case  [6:01:08 PM] (YinYueyan.talendbj): agree with zhao's suggestion  [6:01:30 PM] Mingli Zhao: (note that if we want to handle it row by row, we need to refactoring the way blocking key computation done, from BlockingKeyHandler.run())  [6:02:05 PM] (YinYueyan.talendbj): oh, if one block is very big...  [6:02:17 PM] Mingli Zhao: we can see now  the data is set once by ""setInputData(List<Object[]> inputData)"" in BlockingKeyHandler  [6:02:36 PM] Mingli Zhao: we can handle row by row here maybe  [6:02:50 PM] (YinYueyan.talendbj): ;) maybe, we can try  [6:03:20 PM] Mingli Zhao: then we don't need the list property dataFromTable then in SQLExecutor.  [6:04:16 PM] Sebastiao Correia: Franois used an iterator in the t-swoosh algorithm  [6:04:39 PM] Sebastiao Correia: I don't know if we can also use an iterator here...  [6:04:53 PM] Sebastiao Correia: but we should avoid to have all data in a list for sure  [6:05:29 PM] Mingli Zhao: Yes, in MFB:   execute(Iterator<Record> sourceRecords)  [6:08:48 PM] Sebastiao Correia: maybe that is too big a refactor now  [6:09:30 PM] Mingli Zhao: yes, i think so.  [6:09:36 PM] Sebastiao Correia: I advise to work on a branch for this issue and only push on 5.6 if we are really sure not to introduce regressions  [6:11:34 PM] Sebastiao Correia: I suggest to try and find a possible solution first.  Then we can decide whether we have the time to implement it.  [6:12:37 PM] Mingli Zhao: ok, this is for the memory issue of 1st test.  [6:12:43 PM] Mingli Zhao: about 2nd:  [6:12:50 PM] Mingli Zhao: we need to find the root cause still  [6:13:24 PM] Sebastiao Correia: I think the cause is the same  [6:13:45 PM] Mingli Zhao: actually the ""Iterator"" itself requires the data store in memory first, no?  [6:14:44 PM] Sebastiao Correia:  ""GC overhead limit exceeded""  may happen when the garbage collector is trying to free memory too often.  [6:15:15 PM] Sebastiao Correia: in our case, because the memory is full or almost full because of the list, the GC will try to free other objects  [6:15:31 PM] Sebastiao Correia: at one point, it cannot free the memory, hence this exception  [6:16:06 PM] Sebastiao Correia: in the first case, we run out of memory immediately because the GC has not even the time to try and free the memory  [6:16:19 PM] Sebastiao Correia: [12:13:46 PM] Mingli Zhao: actually the ""Iterator"" itself requires the data store in memory first, no?  [6:16:24 PM] Sebastiao Correia: not necessarily  [6:16:46 PM] Sebastiao Correia: when you iterate over a sql.ResultSet,  not all rows are loaded.  [6:16:57 PM] Sebastiao Correia: they are loaded in a lazily manner  [6:17:46 PM] Sebastiao Correia: here, if I understand, we have all the rows in memory. Am I right?   Or do we have only one block of rows in memory?  [6:18:04 PM] Sebastiao Correia: (by block, I mean a block created by the blocking key)  [6:18:17 PM] Mingli Zhao: all rows in memory  [6:18:52 PM] Sebastiao Correia: ok, this needs to be changed somehow  [6:20:05 PM] Sebastiao Correia: when we use the store on disk option, do we have this memory issue?  [6:20:50 PM] Mingli Zhao: i didn't test this case but i think it will be.  [6:21:11 PM] Mingli Zhao: because the MFB algorithm accept a iterator  [6:21:30 PM] Mingli Zhao: currently I use the List as the collection where iterator iterates .  [6:21:50 PM] Mingli Zhao: how can we construct a java.util.Iterator in order to pass this param to MFB algorithm (not use java collection)?  [6:23:10 PM] Mingli Zhao: http://docs.oracle.com/javase/1.5.0/docs/api/java/util/Iterator.html  [6:23:30 PM] Mingli Zhao: it works only in the java collections framework probably  [6:24:40 PM] Sebastiao Correia: RecordIterator ?  [6:25:20 PM] Sebastiao Correia: Franois implemented his own iterator  [6:25:30 PM] Sebastiao Correia: I don't know whether we could reuse it  [6:26:02 PM] Sebastiao Correia: otherwise, we are now expert in MapDB ;-)  that could be a way to solve it  [6:26:25 PM] Sebastiao Correia: but, I recommend you to first look at what did Franois  [6:27:38 PM] Mingli Zhao: in RecordIterator , there is a list as well: List<RecordGenerator> rcdGenerators  [6:29:20 PM] Mingli Zhao: ok, maybe I got a idea now to wapper the jdbc resultset into RecordIterator ....  [6:29:42 PM] Mingli Zhao: when iterator iterates a row, we call resultSet.next()...  [6:30:12 PM] Sebastiao Correia: yes, that could be a solution  [6:30:33 PM] Sebastiao Correia: finally, don't hesitate to contact Franois about this.  [6:30:33 PM] Mingli Zhao: this requires the interator strictly ""bound"" to the data source we profiling  [6:31:05 PM] Sebastiao Correia: yes, I think this should be ok with MFB.  [6:31:17 PM] Sebastiao Correia: I'm wondering whether we can simply do the same for VSR...  [6:32:16 PM] Mingli Zhao: it could be  [6:33:16 PM] Mingli Zhao: ok, let me summarize the discussion tomorrow on JIRA for this performance issue.  [6:33:26 PM] Mingli Zhao: but we may have no enough time to accomplish it in M4.  [6:33:49 PM] Sebastiao Correia: ok  [6:34:16 PM] Sebastiao Correia: don't start big changes now.  Let's see if we can first find a good solution    {quote}",5
"items not be divide into groups correctly
nan",5
"ERROR org.talend.core.model.metadata.DBConnectionFillerImpl
java.sql.SQLException: Invalid argument: unknown column name  REMARKS    org.talend.commons.utils.database.AS400ResultSet.getString(Unknown Source)    org.talend.core.model.metadata.DBConnectionFillerImpl.fillTables(Unknown Source)    org.talend.core.model.metadata.MetadataFillFactory.fillTables(Unknown Source)    org.talend.core.model.metadata.builder.database.DqRepositoryViewService.loadTables(Unknown Source)    org.talend.core.model.metadata.builder.database.DqRepositoryViewService.getTables(Unknown Source)    org.talend.core.model.metadata.builder.database.DqRepositoryViewService.getTables(Unknown Source)    org.talend.dq.nodes.DBTableFolderRepNode.createRepositoryNodeTableFolderNode(Unknown Source)    org.talend.dq.nodes.DBTableFolderRepNode.getChildren(Unknown Source)    org.talend.dataprofiler.core.ui.views.provider.ResourceViewContentProvider.getRepositoryNodeChildren(Unknown Source)    org.talend.dataprofiler.core.ui.views.provider.ResourceViewContentProvider.getChildren(Unknown Source)    org.eclipse.ui.internal.navigator.extensions.SafeDelegateTreeContentProvider.getChildren(SafeDelegateTreeContentProvider.java:96)    org.eclipse.ui.internal.navigator.extensions.SafeDelegateTreeContentProvider.getChildren(SafeDelegateTreeContentProvider.java:275)    org.eclipse.ui.internal.navigator.extensions.SafeDelegateTreeContentProvider.getChildren(SafeDelegateTreeContentProvider.java:94)    org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider$1.run(NavigatorContentServiceContentProvider.java:150)    org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)    org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.internalGetChildren(NavigatorContentServiceContentProvider.java:137)    org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.getChildren(NavigatorContentServiceContentProvider.java:123)    org.eclipse.jface.viewers.AbstractTreeViewer.getRawChildren(AbstractTreeViewer.java:1348)    org.eclipse.jface.viewers.TreeViewer.getRawChildren(TreeViewer.java:391)    org.eclipse.jface.viewers.StructuredViewer.getFilteredChildren(StructuredViewer.java:896)    org.eclipse.jface.viewers.AbstractTreeViewer.getSortedChildren(AbstractTreeViewer.java:601)    org.eclipse.jface.viewers.AbstractTreeViewer$1.run(AbstractTreeViewer.java:799)    org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)    org.eclipse.jface.viewers.AbstractTreeViewer.createChildren(AbstractTreeViewer.java:778)    org.eclipse.jface.viewers.TreeViewer.createChildren(TreeViewer.java:644)    org.eclipse.jface.viewers.AbstractTreeViewer.createChildren(AbstractTreeViewer.java:749)    org.eclipse.jface.viewers.AbstractTreeViewer.handleTreeExpand(AbstractTreeViewer.java:1444)    org.eclipse.jface.viewers.TreeViewer.handleTreeExpand(TreeViewer.java:952)    org.eclipse.jface.viewers.AbstractTreeViewer$4.treeExpanded(AbstractTreeViewer.java:1455)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:132)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1077)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1062)    org.eclipse.swt.widgets.Tree.wmNotifyChild(Tree.java:7408)    org.eclipse.swt.widgets.Control.wmNotify(Control.java:5096)    org.eclipse.swt.widgets.Composite.wmNotify(Composite.java:1887)    org.eclipse.swt.widgets.Control.WM_NOTIFY(Control.java:4726)    org.eclipse.swt.widgets.Control.windowProc(Control.java:4215)    org.eclipse.swt.widgets.Display.windowProc(Display.java:4873)    org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)    org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:2362)    org.eclipse.swt.widgets.Tree.callWindowProc(Tree.java:1536)    org.eclipse.swt.widgets.Control.windowProc(Control.java:4251)    org.eclipse.swt.widgets.Tree.windowProc(Tree.java:5844)    org.eclipse.swt.widgets.Display.windowProc(Display.java:4873)    org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)    org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:2459)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3655)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)    java.lang.reflect.Method.invoke(Unknown Source)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)  ",3
"report can not run when use oracle 12 as datamart( except report with column analysis)
1. create a report, add some analysis,  2. set report as oracle 12 datamart(sid or service name)  3. try to run report.    Actual Result:  report generate failed  note: only report with column analysis can run well.    Expected Result:  report with any kind of analysis should works    {code}  2014-08-20 14:59:52,161 ERROR org.talend.dq.persistence.handlertype.AbstractPersistenceHandler  - Could not get the date row corresponding to 8/20/14 6:59 AM. Check that the calendar table is correctly filled with data.    org.hibernate.PropertyValueException: not-null property references a null or transient value: org.talend.dataprofiler.datamart.hibernate.TdqMatchIndValue.tdqDayTime  at org.hibernate.engine.Nullability.checkNullability(Nullability.java:72)  at org.hibernate.event.def.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:284)  at org.hibernate.event.def.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:180)  at org.hibernate.event.def.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:121)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.saveWithGeneratedOrRequestedId(DefaultSaveOrUpdateEventListener.java:186)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.entityIsTransient(DefaultSaveOrUpdateEventListener.java:175)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.performSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:98)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.onSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:70)  at org.hibernate.impl.SessionImpl.fireSaveOrUpdate(SessionImpl.java:507)  at org.hibernate.impl.SessionImpl.saveOrUpdate(SessionImpl.java:499)  at org.hibernate.engine.CascadingAction$1.cascade(CascadingAction.java:218)  at org.hibernate.engine.Cascade.cascadeToOne(Cascade.java:268)  at org.hibernate.engine.Cascade.cascadeAssociation(Cascade.java:216)  at org.hibernate.engine.Cascade.cascadeProperty(Cascade.java:169)  at org.hibernate.engine.Cascade.cascade(Cascade.java:130)  at org.hibernate.event.def.AbstractSaveEventListener.cascadeBeforeSave(AbstractSaveEventListener.java:412)  at org.hibernate.event.def.AbstractSaveEventListener.performSaveOrReplicate(AbstractSaveEventListener.java:261)  at org.hibernate.event.def.AbstractSaveEventListener.performSave(AbstractSaveEventListener.java:180)  at org.hibernate.event.def.AbstractSaveEventListener.saveWithGeneratedId(AbstractSaveEventListener.java:121)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.saveWithGeneratedOrRequestedId(DefaultSaveOrUpdateEventListener.java:186)  at org.hibernate.event.def.DefaultSaveEventListener.saveWithGeneratedOrRequestedId(DefaultSaveEventListener.java:33)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.entityIsTransient(DefaultSaveOrUpdateEventListener.java:175)  at org.hibernate.event.def.DefaultSaveEventListener.performSaveOrUpdate(DefaultSaveEventListener.java:27)  at org.hibernate.event.def.DefaultSaveOrUpdateEventListener.onSaveOrUpdate(DefaultSaveOrUpdateEventListener.java:70)  at org.hibernate.impl.SessionImpl.fireSave(SessionImpl.java:535)  at org.hibernate.impl.SessionImpl.save(SessionImpl.java:523)  at org.hibernate.impl.SessionImpl.save(SessionImpl.java:519)  at org.talend.dq.persistence.DatabasePersistence.persist(DatabasePersistence.java:140)  at org.talend.dataquality.reporting.engine.ReportDocGenerator.historizeData(ReportDocGenerator.java:494)  at org.talend.dataquality.reporting.engine.ReportDocGenerator.generate(ReportDocGenerator.java:269)  at org.talend.dataprofiler.core.tdq.action.LocalReportDocGenerator.generate(LocalReportDocGenerator.java:130)  at org.talend.dataprofiler.core.tdq.ui.action.GenerateReportFileAction$2.run(GenerateReportFileAction.java:334)  at org.eclipse.core.internal.jobs.Worker.run(Worker.java:54)      {code}",8
"when download jdbc dirver get an error in error log
issue 1  1. try to create a mysql connection on TOP  2. when click ""check"" on the wizard, get the jdbc driver download dialog popup, and get an error in error log.    Expected Result:  should not get any error    Actual Result:  when jdbc driver download dialog popup, also get an error.    issue 2  on this build, when create analysis, not need to download any jars(except glazedlists_java15-1.9.0.jar), but for earlier build should to download jcommon-1.0.15.jar, jfreechart-1.0.12.jar and several others.      error for issue1  {code}  java.io.FileNotFoundException: F:\560\TOS_DQ-20140820_1932-V5.6.0SNAP_a\configuration\librariesIndex.xml (The system cannot find the file specified)  at java.io.FileInputStream.open(Native Method)  at java.io.FileInputStream.<init>(FileInputStream.java:146)  at org.eclipse.emf.ecore.resource.impl.FileURIHandlerImpl.createInputStream(FileURIHandlerImpl.java:105)  at org.eclipse.emf.ecore.resource.impl.ExtensibleURIConverterImpl.createInputStream(ExtensibleURIConverterImpl.java:301)  at org.eclipse.emf.ecore.resource.impl.ResourceImpl.load(ResourceImpl.java:1254)  at org.talend.librariesmanager.model.service.LibrariesIndexManager.loadResource(Unknown Source)  at org.talend.librariesmanager.model.service.LocalLibraryManager.retrieve(Unknown Source)  at org.talend.librariesmanager.model.service.LocalLibraryManager.retrieve(Unknown Source)  at org.talend.librariesmanager.model.service.LocalLibraryManager.retrieve(Unknown Source)  at org.talend.core.model.metadata.builder.database.ExtractMetaDataUtils.connect(Unknown Source)  at org.talend.core.model.metadata.builder.util.MetadataConnectionUtils.createConnection(Unknown Source)  at org.talend.core.model.metadata.builder.util.MetadataConnectionUtils.createConnection(Unknown Source)  at org.talend.core.model.metadata.builder.util.MetadataConnectionUtils.createConnection(Unknown Source)  at org.talend.core.model.metadata.builder.database.DqRepositoryViewService.isSchemaHasChildren(Unknown Source)  at org.talend.dq.nodes.DBViewFolderRepNode.hasChildrenInDataBase(Unknown Source)  at org.talend.dq.nodes.DBViewFolderRepNode.hasChildren(Unknown Source)  at org.talend.dataprofiler.core.ui.views.provider.ResourceViewContentProvider.hasChildren(Unknown Source)  at org.eclipse.ui.internal.navigator.extensions.SafeDelegateTreeContentProvider.hasChildren(SafeDelegateTreeContentProvider.java:110)  at org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.callNormalHasChildren(NavigatorContentServiceContentProvider.java:428)  at org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.access$4(NavigatorContentServiceContentProvider.java:423)  at org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider$3.run(NavigatorContentServiceContentProvider.java:393)  at org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)  at org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.hasChildren(NavigatorContentServiceContentProvider.java:379)  at org.eclipse.ui.internal.navigator.NavigatorContentServiceContentProvider.hasChildren(NavigatorContentServiceContentProvider.java:420)  at org.eclipse.jface.viewers.AbstractTreeViewer.isExpandable(AbstractTreeViewer.java:2082)  at org.eclipse.jface.viewers.TreeViewer.isExpandable(TreeViewer.java:588)  at org.eclipse.jface.viewers.AbstractTreeViewer.isExpandable(AbstractTreeViewer.java:2112)  at org.eclipse.jface.viewers.AbstractTreeViewer.updatePlus(AbstractTreeViewer.java:2794)  at org.eclipse.jface.viewers.TreeViewer.updatePlus(TreeViewer.java:852)  at org.eclipse.jface.viewers.AbstractTreeViewer.createTreeItem(AbstractTreeViewer.java:830)  at org.eclipse.jface.viewers.AbstractTreeViewer$1.run(AbstractTreeViewer.java:804)  at org.eclipse.swt.custom.BusyIndicator.showWhile(BusyIndicator.java:70)  at org.eclipse.jface.viewers.AbstractTreeViewer.createChildren(AbstractTreeViewer.java:778)  at org.eclipse.jface.viewers.TreeViewer.createChildren(TreeViewer.java:644)  at org.eclipse.jface.viewers.AbstractTreeViewer.createChildren(AbstractTreeViewer.java:749)  at org.eclipse.jface.viewers.AbstractTreeViewer.handleTreeExpand(AbstractTreeViewer.java:1444)  at org.eclipse.jface.viewers.TreeViewer.handleTreeExpand(TreeViewer.java:952)  at org.eclipse.jface.viewers.AbstractTreeViewer$4.treeExpanded(AbstractTreeViewer.java:1455)  at org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:132)  at org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1077)  at org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1062)  at org.eclipse.swt.widgets.Tree.wmNotifyChild(Tree.java:7408)  at org.eclipse.swt.widgets.Control.wmNotify(Control.java:5096)  at org.eclipse.swt.widgets.Composite.wmNotify(Composite.java:1887)  at org.eclipse.swt.widgets.Control.WM_NOTIFY(Control.java:4726)  at org.eclipse.swt.widgets.Control.windowProc(Control.java:4215)  at org.eclipse.swt.widgets.Display.windowProc(Display.java:4873)  at org.eclipse.swt.internal.win32.OS.CallWindowProcW(Native Method)  at org.eclipse.swt.internal.win32.OS.CallWindowProc(OS.java:2362)  at org.eclipse.swt.widgets.Tree.callWindowProc(Tree.java:1536)  at org.eclipse.swt.widgets.Tree.WM_LBUTTONDOWN(Tree.java:6303)  at org.eclipse.swt.widgets.Control.windowProc(Control.java:4195)  at org.eclipse.swt.widgets.Tree.windowProc(Tree.java:5844)  at org.eclipse.swt.widgets.Display.windowProc(Display.java:4886)  at org.eclipse.swt.internal.win32.OS.DispatchMessageW(Native Method)  at org.eclipse.swt.internal.win32.OS.DispatchMessage(OS.java:2459)  at org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3655)  at org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)  at org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)  at org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)  at org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)  at org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)  at org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)  at org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)  at org.talend.dataprofiler.rcp.intro.Application.start(Unknown Source)  at org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)  at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)  at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)  at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)  at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)  at java.lang.reflect.Method.invoke(Method.java:606)  at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)  at org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)  at org.eclipse.equinox.launcher.Main.run(Main.java:1407)    {code}",3
"Build file org.talend.dataprofiler.persistence/build_datamart.xml refers to SVN location
The build file org.talend.dataprofiler.persistence/build_datamart.xml refers to relative paths based on SVN, such as:  <property name=""tos.dir"" value=""../../../tos/trunk/"" />  <property name=""tdq.dir"" value=""../../../tdq/trunk/"" />    See:  https://github.com/Talend/tdq-studio-ee/blob/7d40de3ac4e194535c71139cb7831579a1c37ee7/main/plugins/org.talend.dataprofiler.persistence/build_datamart.xml    These need to be updated to be able built based on Git. I believe the relative paths should actually just be ""../"", as is the case in org.talend.dataprofiler.datamart/build_datamart_init.xml.",2
"no ""Generate job"" selection for dq rule analysis when db is ""oracle service name"" and ""oracle oci""
1. create a dq rule analysis about  ""oracle service name"" or ""oracle oci"" connection.  2. run it.  3. turn to result page, try to generate a job about the rule    Expected Result:  should get this menu    Actual Result:   no this menu.",5
"remove duplidate job and pattern ETL job can not transfer DB type when connection is oracle service name
issue1:  1. create an ""oracle service name"" connection, create a column analysis about it,  2. add simple indicator, add a pattern, run  3. turn to result page, try to generate Remove Duplicate job. and on Pattern try to generate get Valid/Invalid rows job    Expected Result:  job should get correct db information    Actual Result:  for Remove duplicate job, the output can not get correct db type.  for pattern Valid/Invalid row job,  for input component can not get correct db type    Issue 2:  about issue1, when db is ""oracle oci"" remove duplicate job and pattern's job can not generated   {code}  ERROR org.talend.datacleansing.core.ui.actions.IndicatorJobAction  - UnSupport Database Component Exception    java.lang.NullPointerException    org.talend.datacleansing.core.ui.jobs.template.ADatabaseJobAction.extractDBProductInfo(ADatabaseJobAction.java:70)    org.talend.datacleansing.core.ui.actions.IndicatorJobAction.<init>(IndicatorJobAction.java:86)    org.talend.datacleansing.core.ui.actions.pattern.PatternIndicatorJobAction.<init>(PatternIndicatorJobAction.java:44)    org.talend.datacleansing.core.ui.actions.pattern.PatternRowsJobAction.<init>(PatternRowsJobAction.java:50)    org.talend.datacleansing.core.ui.actions.ui.pattern.PatternJobSelectWizardPage.getJobAction(PatternJobSelectWizardPage.java:128)    org.talend.datacleansing.core.ui.actions.ui.pattern.PatternJobSelectWizard.performFinish(PatternJobSelectWizard.java:62)    org.eclipse.jface.wizard.WizardDialog.finishPressed(WizardDialog.java:811)    org.eclipse.jface.wizard.WizardDialog.buttonPressed(WizardDialog.java:430)    org.eclipse.jface.dialogs.Dialog$2.widgetSelected(Dialog.java:624)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.jface.window.Window.runEventLoop(Window.java:825)    org.eclipse.jface.window.Window.open(Window.java:801)    org.talend.datacleansing.core.ui.service.DatabaseJobService.createJobActon(DatabaseJobService.java:97)    org.talend.datacleansing.core.ui.service.DatabaseJobService.executeJob(DatabaseJobService.java:77)    org.talend.dataprofiler.core.ui.editor.preview.model.ChartTableFactory$1.widgetSelected(ChartTableFactory.java:158)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:234)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1053)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4066)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3657)    org.eclipse.ui.internal.Workbench.runEventLoop(Workbench.java:2640)    org.eclipse.ui.internal.Workbench.runUI(Workbench.java:2604)    org.eclipse.ui.internal.Workbench.access$4(Workbench.java:2438)    org.eclipse.ui.internal.Workbench$7.run(Workbench.java:671)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:664)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:149)    org.talend.rcp.intro.Application.start(Application.java:155)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:110)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:79)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:369)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:179)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:619)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:574)    org.eclipse.equinox.launcher.Main.run(Main.java:1407)    {code}",5
"Use Existing Connection option of tMatchGroupHadoop component is not working
I've created a HDFS connection using tHDFSConnection and use it in tMatchGroupHadoop, it's not working out.",5
"in mr job, two tMatchGroup both checked ""Sort the output data by GID"", job can not run finished.
1. create a mr job, add component like: input+tGenkey+tMatchGroup+tMatchGroup + output.    configure tGenkey and two tMatchGroup(set matching key, and first tMatchGroup set blocking key T_GEN_KEY)    for the two tMatchGroup both checked ""Sort the output data by GID"".    Actual Result:  job can not run.    Expected Result:  job should run correctly, no matter check sort function or not.    {code}  java.lang.IllegalArgumentException: The Mapper output key class does not match the previous Mapper input key class    org.talend.hadoop.mapred.lib.Chain.addMapper(Chain.java:195)    org.talend.hadoop.mapred.lib.ChainMapper.addMapper(ChainMapper.java:45)    test1.copy_of_mr_1_0_1.Copy_of_mr_1$2.run(Copy_of_mr_1.java:13649)    test1.copy_of_mr_1_0_1.Copy_of_mr_1$2.run(Copy_of_mr_1.java:1)    java.security.AccessController.doPrivileged(Native Method)    javax.security.auth.Subject.doAs(Subject.java:415)    org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1136)    test1.copy_of_mr_1_0_1.Copy_of_mr_1.tMRInput_tSortRowAfter_tMatchGroup_10Process(Copy_of_mr_1.java:13596)    test1.copy_of_mr_1_0_1.Copy_of_mr_1.tJDBCInput_1Process(Copy_of_mr_1.java:5565)    test1.copy_of_mr_1_0_1.Copy_of_mr_1.run(Copy_of_mr_1.java:25142)    org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:65)    test1.copy_of_mr_1_0_1.Copy_of_mr_1.runJobInTOS(Copy_of_mr_1.java:25117)    test1.copy_of_mr_1_0_1.Copy_of_mr_1.main(Copy_of_mr_1.java:25103)  {code}",5
"tMatchGroupHadoop component is throwing an error when using with Hive2 - Different versions of sl4j-log4j jar
In Talend studio, configure tHiveInput component with hive2 in Standalone mode.  add tMatchgroupHadoop component to the job and configure it to Cloudera CHD4.X MR1 mode.  While running the job it is throwing below error    SLF4J: Class path contains multiple SLF4J bindings.  SLF4J: Found binding in [jar:file:/H:/TalendWrkSpc_Ravi/.Java/lib/slf4j-log4j12-1.6.1.jar!/org/slf4j/impl/StaticLoggerBinder.class]  SLF4J: Found binding in [jar:file:/H:/TalendWrkSpc_Ravi/.Java/lib/slf4j-log4j12-1.7.5.jar!/org/slf4j/impl/StaticLoggerBinder.class]  SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.  Exception in thread ""main"" java.lang.NoSuchMethodError: org.apache.hadoop.conf.Configuration.addDeprecations([Lorg/apache/hadoop/conf/Configuration$DeprecationDelta;)V    each component is loading different versions of slf4j-log4j jar.  ",5
"Create version 5.6.0M4 in Babili and populate it
nan",2
"create a mysql connection, can not get catalogs directly, need to reload it.
1. create a  mysql connection, set parameters,   2. click ""check"" on the wizard, pop up download mysql driver dialog, download it.  3. mysql connection created successfully, but can not get  catalogs      Expected Result:  get structure successfully.    Actual Result:  can not get catalogs, and get error in error log.    NOTE: reload database list can show the catalog  Before reload , check detail view, type: mysql, it is correct.    error:  ERROR org.talend.cwm.management.api.SoftwareSystemManager  - null database type:mysqldb_1",3
"in report doc Percentage value in table  for benford law different with other indicator's formart 
1. create a column analysis, add benford law indicator.  2. create a report with the analysis.  3. generate report file, check the generated doc.    Actual Result:  Percentage value is different with other indicator values' format    Expected Result:  should show with same format    NOTE: same with 551",1
"Rename the tCloudAddressRow component to tAddressRowCloud
Due to naming restrictions (tCloud* is reserved for iPaaS components), we must rename this component. ",1
"Manage deprecation of old version of EMF Compare
Remove the use of EMF compare.   Replace the reload function with a home made function that compares the structures and handles the deletion of items used in analyses.     # implement a comparison function that compares two lists of DQ items (Catalogs, tables, or columns). This gives some differences between the two input lists.   # implement a way to copy the differences from one list (remote items) to the other list (local items)  # implement a UI on top of the previous function. When the output differences are not empty, we can display them. And that can also apply the copy. ",3
"improve about MapDB mode
1.The folder ""Work_MapDB"" should be start by "".""  2.sourceforge.sqlexplor plugin don't should contain ""MapDB"" libraries,try to move the wizard to ""common.ui"" plugin.  3.CsvExportOptionsDlg need to change group name.  4.ColumnSetIndicatorEvaluator.handleObjects method is very long should try to extract method for different if clause.  5.same to issue 4 executeSqlQuery method is too long.  6.From ColumnSetResultPage and DrillDownEditor class extract pagination Table.  7.TupleArray class is not useful again.  8.IndicatorImpl.saveTempDataToFile should change to useMapDBMode.  9.ColumnSetMultiValueIndicatorImpl.ConvertToStringArray should be remove.  10.FrequencyIndicatorImpl add commont on this class for some new method.  11.IndicatorImpl.getMapDB method can extract same part.  12.Write junit for Soundex.handle method and refactor this method make it more clear.  13.Try to change folder name to UUID",20
"issues about import rule in match analysis and some other improvements for match analysis.
issue1,   if a vsr/t-swoosh match analysis import a t-swoosh/vsr rule, analysis will turn to t-swoosh/vsr type   we'd better can not import the rule or give some warning if rule type is different with analysis.    issue2,  on the import dialog, it is not case sensitive, but in analysis editor, it is case sensitive, refer to pic.      issue3,  when import a t-swoosh rule, if analysis has exist same ""Match Key Name"" key, we will get inform information, if import a vsr rule, we can not get it.      issue 4(from TDQ-9270),  open preference page, click Talend->Profiling->Editor, on the right pane click ""Hide graphics in analysis result page"".  back to match analysis editor, run it, on result page, pic chart still there.    issue 5 (from TDQ-9270)  in the ""Match and Survivor"" section, select varchar  type column as ""Input column"",  select ""Largest (for numbers)"" as ""Function"",  click ""chart"" button, no atction, just get error in error log, should we pop up an error dialog?    {code}  java.lang.NumberFormatException  at java.math.BigDecimal.<init>(Unknown Source)  at java.math.BigDecimal.<init>(Unknown Source)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.parseNumberValue(MFBRecordMerger.java:208)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.createMergeValue(MFBRecordMerger.java:121)  at org.talend.dataquality.matchmerge.mfb.MFBRecordMerger.merge(MFBRecordMerger.java:62)  {code}    ",3
"Export babili translations into git on master branch
nan",2
"Handle the closure of mapDB when running the analysis and drilling down.
In the preference , create a page for mapDB parameter settings.",20
"Can't import because 'check item conflict failed'
Customer try to import the old project from v5.3.1 to v5.5.1, firstly, he import the DI's items, when he try to import DQ's items, he got 'check item conflict failed' warning even ticked the 'Overwrite' option, this block the import process and customer can't import DQ items into the new project.",3
"Create version 5.6.0RC1 in Babili and populate it
nan",2
"remove MapDBDrillDown and  DataValidation interface from indicator class
nan",8
"Remove % symbol from i18n
The property key MatchAnalysisConstant.Percentage should be deleted. No need to translate the ""%"" symbol",3
"Export babili translations into git on 5.6 and master branches
nan",2
"TOPImport Item:Able to detect report and do import action
1.Logon TOP build ,try to import a Report item (able to use data from attachment)  2.able to detect the import items and ""finish"" button is available  3.Click finish button    Actual Result:  no item import in studio , there is an error log   {noformat}  2014-09-25 11:11:53,565 ERROR org.talend.dq.helper.SqlExplorerUtils  - Missing the plugin net.sourceforge.sqlexplorer!  {noformat}     Expect Result:  TOP not support report , maybe give user some friendly info when try to import report",1
"out of memory issue in column analysis with Java engine
got gc overhead limit exceeded when running a column analysis on 30 columns with 500 000 rows.  Used java engine. Allowed drill down with no limit.     Then I'm asked to restart the studio.   ",13
"Handle the exception when studio is closed abnormally
1.Here should have a error log to record the issue.  2.When restart the stdio if find out some mapDB is not close Then delete old mapDb file.",5
"job tdqReportRun use mysql as the datamart will get exception
nan",5
"User customisable input / output schemas for tQASBatchAddressRow
At the current time, the tQASBatchAddressRow component is hard coded to a single input column (Address) and a fixed output schema, determined by the country selected. This means that the component needs to be manually altered in the tQASBatchAddressRow_java.xml to match the customers desired output from QAS, with all the support issues that implies.    It would be much better if the component worked like tLoqateAddressRow, with customizable input / output schemas. The output of QAS is positional, so we should not hard code in any column names at all.    TODO:   Have the same UI as tLoqateAddressRow for the standard settings.   No Advanced settings. ",8
"code refactor:Remove some unuseful classes and functions
After some code refactor,there are some functions are deprecated.  1.Currently,we reuse DI code to create database.we could remove these unuseful classes:   - org.talend.dataprofiler.core.ui.wizard.database.DatabaseConnectionWizard  - org.talend.dataprofiler.core.ui.wizard.database.DatabaseMetadataWizardPage  - org.talend.dataprofiler.core.ui.wizard.database.DatabaseWizardPage    2. in org.talend.cwm.db.connection.ConnectionUtils.java,we can remove these functions:  - existTable(String url, String driver, Properties props, String tableName, String schema);(it is't called)  - checkConnection(String url, String driverClassName, Properties props)  - createConnection(String url, String driverClassName, Properties props)  - createConnectionWithTimeout(Driver driver, String url, Properties props)  - getClassDriverFromSQLExplorer(String driverClassName, Properties props)    There isn't any palce call them:     - fillConnectionInformation(List<Connection> conns)    - fillDbConnectionInformation(DatabaseConnection dbConn)    - fillAttributeBetweenConnection(Connection target, Connection source)    3.in plugin net.sourceforge.sqlexplorer  - SqlExplorerUtils.getClassDriverFromSQLExplorer(String driverClassName, Properties props)  - ISqlexplorerService.getClassDriverFromSQLExplorer(String driverClassName, Properties props)   - SqlexplorerService.getClassDriverFromSQLExplorer(String driverClassName, Properties props)  - SqlexplorerService.loadDriverByLibManageSystem(String dbType, String dbVersion, String driverClassName) ",5
"Add support of new databases for the data mart and the DQ portal - Part 1
This implies:  # adapt the jasper reports  # adapt the hibernate configuration  # adapt the database creation and initialisation script  # adapt the data mart API  # adapt the installer (new pages)  # adapt the reports in DQ portal  # adapt QBE in DQ portal  # tests the other DQ portal features    The requirements are, in this order of priority:       - Align with the database versions for the databases we already support (confirm that they are fully supported):       --    MySQL 5.6       --   Oracle 12      See also DOCT-3867",20
"Create version 5.6.0 in Babili and populate it
nan",2
"Export babili translations into git on 5.6 and master branches
nan",2
"Support Java 8
nan",5
"Simplify HDFS file Profiling with Hive - step 1
Aim: The user should be able to run an analysis on an HDFS file.     When the user can create a Hive connection when he selects an HDFS file to profile.    See subtask for the DDL statement to create a hive table over a file.",20
"Use smart sampling in the match analysis
Add an option to choose how to extract the sample of the data. this option is either:      # n first rows    # n random rows     # x percent of rows (maybe look at the tSampleRow component implementation)    # n last rows      Use the reservoir sampling algorithm to select 10 000 rows.   This can be done with the *java engine*.     The sampling methods must be packaged in an API that will be reused at different places in the DQ  project.     -For the *SQL engine*, only the first two options will be available : top n rows, bottom n rows.-  In column analysis, we extract a sample of data to display them, but we don't apply any indicator on this data sample. There is no need to distinguish between java and sql engine here.   The analysis execution is always done on the full data set.     The other analysis (column analysis...) that display the data also need this same feature. ",13
"need DQ support for MS SQL Server to match MySQL &/or Oracle
Partner needs DQ support for MS SQL Server to be as mature as that for MySQL and/or Oracle, e.g., there are tMySqlInvalidRow and tOracleInvalidRow components but no tMSSQLServerInvalidRow component.    activate related menus that generate jobs with these components (business rule analysis).",5
"Remove org.talend.rcp.branding.top plugin if possible
We currently use org.talend.dataprofiler.rcp to launch TOS_DQ, This plugin is not really useful.",1
"Change null verification level to be Unverified when the address provider is google.
The verification level for Google provider is not correct when set address to be AAABBBCCCAAAAAAAAAAAAAAA, the status is ZERO_RESULTS.the verification level is NULL.",3
"vsr match analysis import vsr match rule, when same name items exist, can not get correct inform message.
nan",1
"Allow scroll down and copy/paste of the error in tmatchgroup
enable scroll down and copy/paste of the java error in tmatchgroup    to reproduce the error, see below:  -created a job with multiple matchgroups (see attached job)  -used the replicate component to duplicate the flow and show the difference in the results when we use one matchgroup and two matchgroups  -the jobs runs correctly  -but when i double-click the first tmatchgroup in the upper part of the job, i got an error message (see attached). The matchgroup configuration wizard opens, but when i click ""chart"", i got the same error.",1
"wrong column header for column correlation results
When running SOME column correlation analyses, on Results tab, under Data section, column headers in table are sometimes incorrect.",3
"remove init**Map or init**Set in DistinctCount Duplicate and unique indicator
DistinctCount Duplicate and unique indicator contain some init method which has exist on the indicatorImpl, the different is we need to support old hashMap or hashSet in those indicator.Should remove those method and instead of it with super one.",5
"Selection of Indicators does not display well with large fonts
I use large fonts (150%) with a screen resolution of 1920x1080. This helps prospects see/read my screen over WebEx and on Projectors (well, the resolution often has to go down for projectors so I have my own no instead!)    Is it possible to render the selection grid based on the system font size?",5
"No value shows for UDI frequency in the generated document after run report.
nan",1
"Automatically create the data mart database from the installer
Once issue often happens that people don't create the talend_dq database before they run the installer.   Therefore, when they configure the datamart, they got an error message.    In order to avoid that, we will now create the datamart (if it does not exist) within the datamart.init API. ",8
"Create version 5.6.1 in Babili and populate it
nan",2
"Remove unused feature org.talend.rcp.branding.tdqsa-feature
The org.talend.rcp.branding.tdqsa-feature has the same id as the feature org.talend.rcp.branding.tdq-feature. If tdqsa is no longer being used, it should be removed, otherwise it needs to be renamed as it interferes with the Tycho build migration.",1
"match analysis with special operations, ""chart"" result in table chart and pic chart are different.
1.  create a match analysis set vsr algorithm, set matching key  2. click ""chart"" in ""Matching key"" section,  3. change the value for  ""hide groups less than"" to ""3""  4. both table chart and pic chart result show correctly.  5. change algorithm to ""t-swoosh"", the ""hide groups less than"" value also change to 2 automatic.  6. save analysis, click ""chart"" under ""Match and survivor"" section.  7. check the Result and pic chart, they are different.  on table chart show the result of group size less than 3 but not 2.    Expected Result:  both table chart and pic chart can show correctly.    Actual Result:  only pic chart show result correctly.    ",1
"Export babili translations into git on 5.6
nan",2
"import  Survivorship Rules, ""Rules Management"" can not show node name correctly--no function affected
1. in DI perspective import the zip file AccountDedupe_tRuleSurvivorship.zip  2. open the imported job ""AccountDedupe_tRuleSurvivorship"", focus on the  ""Component"" tab of ""tRuleSurvivorship""  click ""Generate rules and survivorship flow ""  then on the Repository Metadata->Rules Management->Survivorship Rules, we get a folder named ""AccountDedupe"".  3. export(by click ""Export Items"") the job and  file generated on step 2.  4. delete the job and file generated on step 2.  5. import (by click ""Import Items"") the file exported on step 3    Actual Result:  on the step 5, the import dialog can not show the node name correctly.  NOTE: no function affected.    Expected Result:  should show the name node correctly.  ",2
"Add support to Melissadata in tBatchAddressRowCloud
Information about Melissadata WS is available at http://wiki.melissadata.com/index.php?title=Global_Address_Verification   See also http://wiki.melissadata.com/index.php?title=Global_Address_Verification%3AGetting_Started   and the best practices http://wiki.melissadata.com/index.php?title=Web_Service%3ABest_Practices     For documentation purpose, information is available about address verification codes at http://wiki.melissadata.com/index.php?title=Global_Address_Verification%3AFAQ  The global Reference guide is at http://wiki.melissadata.com/images/8/8e/DQT_WS_Global_RG.pdf     Result codes: http://wiki.melissadata.com/index.php?title=Returned_Result_Codes%3AWeb_Services#Global_Address_Verification     A sample of Java code with xml is at ftp://ftp.melissadata.com/SampleCodes/Current/DQWS3/International/International_XML_Java.zip     Some code from the first Address API that we developed can probably be reused because the json returned by the batch API is a list of json objects (records) that have the same structure as for the transactional API (one record). ",3
"Email validation component - Step 1
What is an email: http://en.wikipedia.org/wiki/Email_address    Create an API and a component called *tVerifyEmail* under Data_Quality    By default, this component will check a generic email regex: {noformat}<DEFAULT>""^\s*(([^\s\p{Cntrl}\(\)&lt;>@,;:'\\\""\.\[\]]|')+|(""[^""]*""))(\.(([^\s\p{Cntrl}\(\)&lt;>@,;:'\\\""\.\[\]]|')+|(""[^""]*"")))*$""</DEFAULT> {noformat}  In the advanced setting, this regex can be edited.     Parameters in the component will help the user to specify further the email format.   The user will be able to specify the local part (string before the '@' sign).  Either by writting a simplified expression such as    - w that means there is a word   - a.a  that means ""letter\.letter""   - a.w that means ""letter\.letter+""   - 1.w that means  a digit followed by dot followed by a word.   - w1.w means word followed by one digit followed by dot followed by a word   - wN means word followed by a numeric   - w[-_]w means word followed by either - or _ then word   - a* means any number of characters after a letter.     An option (checkbox) enables the user to decide whether the local part can be case sensitive or not (the domain part is never case sensitive).  When this option is checked, then we must distinguish between ""Aw"" which means one word starting with an upper case and ""aw"" which is equivalent to ""w"" and means a word in lower case.    the user must be able to define a list of valid domains or a list of invalid domains (he can't define both at the same time).  The domain is the string after the '@' sign.   A black list is the list of all domains that are not valid: every email with a domain from the blacklist must be invalid  In the case of blacklist, when the TLD is invalid, then no need to check other conditions, the email is invalid    A white list is the list of all acceptable domains: every email with a domain NOT in the list is invalid  In the case of the whitelist, there is no need to check the TLD (it's up to the user to provide the correct domain part of the email)      Optionally, this component will reuse code from the email UDI to check the email via socket queries.     Think about the reusability of the API in some Java DQ indicator (later).     _(it has been suggested to reuse the same syntax as the one used in tStandardizeRow, but it's more readable to have something like aw than LETTER WORD and it's clear that there is no space in aw whereas it's not so clear in ""LETTER WORD"". Therefore, I suggest we keep the above syntax or a similar one. )_    In this first step, the output schema will have only one fixed columns: ""VERIFICATION""     The content of the VERIFICATION column can be:  - verified (meaning that the email complies to the given rules)  - invalid (meaning that the email does not comply to the rules)    See some existing code at  http://leshazlewood.com/2006/11/06/emailaddress-java-class/  http://commons.apache.org/proper/commons-validator/apidocs/org/apache/commons/validator/routines/EmailValidator.html    These codes may have performance issues or other problems that the TLD list is not complete.     We should provide an option for the user to choose whether the algorithm must validate TLD names or not. Or maybe, we need to allow the user to add his own valid TLD names.   See https://data.iana.org/TLD/tlds-alpha-by-domain.txt ",40
"The ""org.talend.dataquality.reporting.JasperReportBuilder - java.util.Date cannot be cast to java.sql.Timestamp""error shows after run tDqReportRun job with Pivotal HD2.
1.Start studio and create Pivotal db connection.  2.Create column analysis and report with analysis.  3.Select Launch a report by right clicking report.  4.Run job.    Expected result:  The document should be generated, no error shows for job.  Actual result:  The error shows.  see attachment.  ",5
"Email validation component - Step 2
This is step 2 of the email validation component.     The user will be able to specify the local part (string before the '@' sign) by writing an expression built from other columns of the schema such as     - first character of firstname    - n first characters of     - n last characters      - all characters of lastname    - pick n first characters and m last characters of the column (2 parameters here: n and m)     The output schema will have two fixed columns: ""VERIFICATION"", SUGGESTED_EMAIL.     The content of the VERIFICATION column can be:  - verified (meaning that the email complies to the given rules)  - corrected (meaning that the email has been corrected)  - invalid (meaning that the email does not comply to the rules)    The email can be corrected when some rules are defined from other columns, such as first character of column Firstname and all characters of column LastName.  The email formed by these rules will be output in the  SUGGESTED_EMAIL column.     We should also think about a way to refresh the TLD list from https://data.iana.org/TLD/tlds-alpha-by-domain.txt       ",20
"Add support of new databases for the data mart and the DQ portal - Part 2
This implies:  # adapt the jasper reports  # adapt the hibernate configuration  # adapt the database creation and initialisation script  # adapt the data mart API  # adapt the installer (new pages)  # adapt the reports in DQ portal  # adapt QBE in DQ portal  # tests the other DQ portal features    The requirements are, in this order of priority:       - Cover the missing databases we keep getting demands for which are, by order of priority:       --  SQL Server --> version 2012       --  PostgreSQL --> version 9.3      If time allows, check with the other databases we support in the UP for consistency. For instance TAC will also support MariaDB.      See also DOCT-3867",13
"problems about Eclipse 4.4 migration and change to Maven
nan",3
"Support for ""multi-level"" jdbc schemas, such as denodo
In denodo it's possible to have the following type of format:   database.schema.tablename    In DI, with generic JDBC it generates statements such as:  select * from database.tablename;    While in DQ it's generating things such as:  select count(*) from database.shema.tablename;    The first is correct, while the second throws the error:  ""Select count(*) from database.schema.tablename; is an invalid statement.""      We should change the behavior of DQ to mirror DI's behavior, or provide an option to do so. ",13
"""pattern frequency indicator""  result for db2 connection  varchar type column have some redudant character.
1. create a db2connection, create a column analysis about the connection, add a varchar type column  2. add Pattern Frequency indicator to this column.  3. run it.  4. turn to analysis result page check the result, there are some redundant character.    Expected Result:  should show the result correctly.",1
"Change the column analysis editor to display the data - Step 2
See attached Mockup.",8
"Port tBatchAddressRowCloud to 5.6
As this component is required by TIC, we must port it to the 5.6 branch. ",5
"Improvements of the tBatchAddressRowCloud component
See subtasks",8
"Download net.sourceforge.sqlexplorer.nl after installation
In the p2 build, including the NL fragment net.sourceforge.sqlexplorer.nl in org.talend.top.feature pulls net.sourceforge.sqlexplorer into the TOS DQ product.    Since we cannot include net.sourceforge.sqlexplorer at installation, we need to exclude net.sourceforge.sqlexplorer.nl and find another way to fetch it.",1
"Cannot add connections in Data Explorer
In my integration or my profiler perspective, I have the metadata Db Connections available, but in my Data Explorer perspective, I don't have any connections and I cannot even add connections.    I have moved my workspace to a different folder (C:\TOS_jobs\workspace)when installing the new version. For every new version, I had to import the projects again before.",3
"design a prototype with the new version of SpagoBI
use the last stable version of SpagoBi and import the reports and other objects (dashboards, QBE,...) from an old DQ portal.  Try different layouts in SpagoBI...",8
"Update some tdq system routines file
 Update some tdq system routines file :   now we parser the routines function parameter from the annotation on studio side.   for example : code\routines\system\Numeric_0.1.item                            {code}    /**       * return numbers using an implied decimal format.       *        * {Category} Numeric       *        * {talendTypes} float | Float       *        * {param} String(""9V99"") format: float pointing format.       *        * {param} String(""123"") toConvert: read this value.       *        * {example} convertImpliedDecimalFormat(""9V99"", ""123"") result: 1.23 ...       *        */      public static Float convertImpliedDecimalFormat(String format, String toConvert) {  {code}                                                          => we parser "" format: ""and ""toConvert:"" as param , but now some dq routines file not keep the same rule ,it is a wrong format.    like this files :   \code\routines\system\DQTechnical_0.1.item ,   \code\routines\system\DataQuality_0.1.item ,     {code}      /**       * isNameStringValid: Returns true or false if the string is a valid formed name: [Initial] Firstname [Initial]       * Lastname       *        * {talendTypes} Boolean       *        * {Category} Data Quality       *        * {param} string(""Mrs. Marty Smith"") the string to be processed       *        * {example} isNameStringValid(""Mrs. Marty Smith "") # returns true       */        public static boolean isNameStringValid(String inStr) {  {code}     ==> The old string :  {param} string(""Mrs. Marty Smith"") the string to be processed  The new string need add the parameters :   {param} string(""Mrs. Marty Smith"") inStr: the string to be processed",3
"improve call back option on tVerifyEmail
we need to be able to configure the callback parameters such as the sender (qiongli@talend.com) (check other parameters in the indicator) - The callback should throw exceptions when invalid configuration (wrong parameters set) log level to discuss again. IMO because the callback takes time, it's good to keep the info level here (the user may still decide to hide the logs with log4j). ",8
"Upgrade Drools to the lastest stable version (Step 2)
Lastest Drools version is 6.2.0Final.",10
"tdqReportRun component exist compile error on the 6.0
StandaloneRepositoryContextService class has been move to package ""org.talend.core.repository.services"" instead of old one ""org.talend.repository""      PreferenceInitializer line:92 there should be a OS path rather than common path string mean ""\"" will be used in this case. It will cause compile error on the code of component",8
"the remain issues after TDQ-9820 we support of new databases for the data mart and the DQ portal
nan",8
"Automatically create the data mart database from the installer - Part 2
Automatically create the data mart database from the installer  - -oracle-  (For Oracle, the schema must exist before the installation)  - ms sql server  - postgresql    This means that:  - a DB user having the appropriate permissions to create a database can use the installer to create the data mart (no prerequisite except setting the permissions of this user).  - the user does not need to manually create the database before running the installer  - for each database, list the prerequisites (creation of user statement, grant of permissions, ...)  - a DB user that does not have the appropriate permissions won't be able to create the database and there should appear an exception to the user of the installer explaining why the installation failed.  - if the database already exists, then the installer will simply populate it (as it's already done)      The change only needs to be done in the installer.   No change required in the studio.",8
"The chart doesn't show in the ""Analysis Results"" page after running analysis in studio.
nan",5
"Column analysis improved editor
for detail issue refer to the sub-task.",13
"API for discovering data semantic
Based on regex, dictionnaries and lucene indexes, define an API that take a data flow and returns expected data semantic.   See Aicha's code base about the category indicators.   ",20
"got NPE when run Match analysis without jfreechart
{code}  org.eclipse.swt.SWTException: Failed to execute runnable (java.lang.NullPointerException)    org.eclipse.swt.SWT.error(SWT.java:4441)    org.eclipse.swt.SWT.error(SWT.java:4356)    org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:139)    org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032)    org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148)    org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)    org.talend.dataprofiler.rcp.intro.Application.start(Application.java:78)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:603)    org.eclipse.equinox.launcher.Main.run(Main.java:1465)  Caused by: java.lang.NullPointerException    org.talend.dataquality.record.linkage.ui.composite.chart.DuplicateRecordPieChart.refreshChart(DuplicateRecordPieChart.java:64)    org.talend.dataquality.record.linkage.ui.section.DuplicateRecordStatisticsSection.refreshChart(DuplicateRecordStatisticsSection.java:203)    org.talend.dataprofiler.core.ui.editor.analysis.MatchAnalysisResultPage.refresh(MatchAnalysisResultPage.java:94)    org.talend.dataprofiler.core.ui.editor.analysis.MatchMasterDetailsPage.fireRuningItemChanged(MatchMasterDetailsPage.java:1446)    org.talend.dataprofiler.core.ui.action.actions.RunAnalysisAction$1$2.run(RunAnalysisAction.java:252)    org.eclipse.ui.internal.UILockListener.doPendingWork(UILockListener.java:167)    org.eclipse.ui.internal.UISynchronizer$3.run(UISynchronizer.java:165)    org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)    org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)  	... 23 more  {code}",2
"on TOS_DQ ""Additional Talend Packages"" can not list the  chart.jar, manually install it, cannot pop up dialog to install necessary jars
issue1   start TOS_DQ build, on the  ""Additional Talend Packages"" dialog can not  list chart.jar to download.    issue 2.  manually put chart.jar to plugins folder, when re-run analysis can not pop up dialog to download the jars necessary for chart.jar. but we can on M1 build(attached the pic needed by chart.jar)",3
"Plugin org.talend.libraries.jfreechart is not included in any features in TOS_DQ
The plugin org.talend.libraries.jfreechart is required by org.talend.dataprofiler.top.chart, but as it is not included in any SE features, it is not included in any SE products.",2
"issue for tVerifyEmail(black list, white list, checked entire email with regular expression)
*issue1*  1. import the job attached, run it.    -- all item are verified.  2. add black list ""cc.zbzz13""    run the job again.    Expected Result:  only item 5 should be invalid, for its domain in the black list.    Actual Result:  item 2,3,5 are invalid.    *ISSUE 2:*  when check with white list, but white list is empty, should we treat all email as VERIFIED or invalid,  now all treat as VERIFIED.    *issue 3*: the ""Check the entire email with regular expression"" doesn't works on my side  1. set input as 2@qq.com  2. checked ""use standard regular expression"" as -->""^\\d$""  3. checked ""Check the entire email with regular expression"" and set value-->""^\w+([-+.]\w+)+@\w+([-.]\w+)*\.\w+([-.]\w+)*$""  run the job, still treat input as VERIFIED, should not.",8
"right click on a pattern or a rule in table rule analysis, job can generated but dialog can not close
1. create a column analysis, add a pattern, run the analysis  2. turn to ""Analysis Results"" page, right click on the pattern -->Generate job  3. on the pop up dialog select one options and click ""Ok""  Expected Result:  job generate without error and dialog close.    Actual Result:  job can generate but the pop up dialog on step3 can not close, and error log get error.    same issue when right click on the rules in table Rule analysis to generate job(dialog can not close, get error)    for other generate job operation will also get error in error log:  1. right click report-->Generate jobs-->Launch a report/Alter threshold violation  2. generate the remove duplicate job      {code}java.lang.IllegalArgumentException: Argument not valid    org.eclipse.swt.SWT.error(SWT.java:4422)    org.eclipse.swt.SWT.error(SWT.java:4356)    org.eclipse.swt.SWT.error(SWT.java:4327)    org.eclipse.swt.graphics.Image.init(Image.java:1557)    org.eclipse.swt.graphics.Image.<init>(Image.java:180)    org.talend.designer.core.ui.editor.AbstractTalendEditor.saveOutlinePicture(AbstractTalendEditor.java:1083)    org.talend.designer.core.ui.editor.AbstractTalendEditor.savePreviewPictures(AbstractTalendEditor.java:1154)    org.talend.designer.core.ui.editor.AbstractTalendEditor.doSave(AbstractTalendEditor.java:518)    org.talend.designer.core.ui.AbstractMultiPageTalendEditor.doSave(AbstractMultiPageTalendEditor.java:975)    org.talend.designer.core.ui.MultiPageTalendEditor.doSave(MultiPageTalendEditor.java:176)    org.talend.datacleansing.core.ui.jobs.template.AJobAction.checkAndSave(AJobAction.java:316)    org.talend.datacleansing.core.ui.jobs.template.AJobAction.addTemplateNodes(AJobAction.java:297)    org.talend.datacleansing.core.ui.jobs.template.AJobAction.doRun(AJobAction.java:153)    org.talend.repository.ui.actions.AContextualAction$2.run(AContextualAction.java:635)    org.talend.repository.RepositoryWorkUnit.executeRun(RepositoryWorkUnit.java:93)    org.talend.core.repository.model.AbstractRepositoryFactory.executeRepositoryWorkUnit(AbstractRepositoryFactory.java:237)    org.talend.repository.localprovider.model.LocalRepositoryFactory.executeRepositoryWorkUnit(LocalRepositoryFactory.java:3205)    org.talend.core.repository.model.ProxyRepositoryFactory.executeRepositoryWorkUnit(ProxyRepositoryFactory.java:1977)    org.talend.repository.ui.actions.AContextualAction.run(AContextualAction.java:641)    org.talend.datacleansing.core.ui.actions.IndicatorJobAction.run(IndicatorJobAction.java:338)    org.talend.datacleansing.core.ui.service.DatabaseJobService.executeJob(DatabaseJobService.java:79)    org.talend.dataprofiler.core.ui.editor.preview.model.ChartTableFactory$1.widgetSelected(ChartTableFactory.java:149)    org.eclipse.swt.widgets.TypedListener.handleEvent(TypedListener.java:248)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032)    org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148)    org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)    org.talend.rcp.intro.Application.start(Application.java:162)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:603)    org.eclipse.equinox.launcher.Main.run(Main.java:1465)    {code}  ",3
"The sections do not fold for column analysis and match analysis when check ""Fold all sections"" in the Preference page.
nan",1
"upgrade libphonenumber in tStandardizePhoneNumber and studio
Current version of the library is 7.3.0 provided by  https://github.com/googlei18n/libphonenumber  http://repo1.maven.org/maven2/com/googlecode/libphonenumber/libphonenumber/",5
"Wrong null result on tRuleSurvivorship 
We want to create a golden record with the tRuleSurvivorship. The address of the golden records needs to be the address of the most complete record in the matchgroup. => function most complete.  When we use the function most complete we got the following output (see attached)    As you can see in the screenshot the function only seems to be working for the first matchgroup. The other matchgroups get NULL values in the fields.  We've tested this in a studio which has been patched and we've also tested in a non-patched studio.  ",2
"Profiling / Analysis results on MacOS / N-1 entries in the Result versus N bars in Result graph
Profiling / Analysis results on MacOS / N-1 entries in the Result table versus N bars in the Result graph.    Example in attached screensho: there are 3 bars in the graph and only 2 entries in the table. 1st is missing...    The problem appears initially. Selecting the first table entry row and then scrolling or pressing the top arrow key shows all expected entries.",2
"Drill down not working with custom REGEX
I have created a custom REGEX and added it to a column in a column analysis.  When I run the analysis, I get the correct results.  However, when I try to drill down (right mouse click) I get a SQL error (see attached screenshot).      Here is the SQL that's generated.  For some reason, it's adding an extra $' at the end of the REGEX.    SELECT *  FROM `crm`.`clients`  WHERE ( `idState`  NOT REGEXP BINARY '^(A[KLRZ]|C[AOT]|D[CE]|FL|GA|HI|I[ADLN]|K[SY]|LA|M[ADEINOST]|N[CDEHJMVY]|O[HKR]|P[AR]|RI|S[CD]|T[NX]|UT|V[AIT]|W[AIVY])$' $' OR `idState` IS NULL )    Here's another custom one that works.  No extra $; on this one.    SELECT *  FROM `crm`.`cust`  WHERE ( `Code`  NOT REGEXP BINARY '^[A-Za-z]+$'  OR `Code` IS NULL )    My REGEX looks correct, so I'm not sure why there is a difference.  This is for a POC that I'm having next week.  I've attached the custom REGEX.  States_check is the one I'm having a problem with.",5
"tMatchGroup issue in a joblet 
When using a tMatchGroup component in a joblet it's not possible to open the wizard of that component. When we try to configure the tMatchGroup component beforehand, and refactor it to a joblet, the configuration is lost and the job does not work. Is this meant to work that way?    The same error occurs when copying a tMatchGroup component from one job to another; only the blocking key definition is kept, but the rules are gone.  ",2
"Add  ""Minimum verification level"" option for 'loqate' of Address Provider when test ""tAddressRowCloud"" component job. 
The Reverted verification level can be shown when add minimum verification level for loqate.       https://www.everythinglocation.com/server-options/  [17:35:36] Wei.zhaojun.talendbj(): http://www.loqate.com/wp-login.php?redirect_to=/support/fielddescrip/address-verification-code/  [17:38:52] Wei.zhaojun.talendbj(): The verification status C (Conflict) is for future expansion, and currently it is unused.     The verification status R (Reverted) will be returned, if the address could not be verified to the specified criteria level, e.g., MinimumVerificationLevel, MinimumMatchscore.  For example, 999 Baker Way, San Mateo, 94404, CA,  US.  During verification, a V4 is returned as we can see below. However, if we set the option MinimumVerificationLevel to 5, which is higher than the verification level 4 that the address gets, then the address will be reverted with a R4 returned.  Please refer to the screenshots below,      MinimumMatchscore 	Used to specify the minimum matchscore a record must reach in order to avoid reversion. Default is 0 (zero), valid values are 0-100  MinimumVerificationLevel 	Used to specify the minimum verification level a record must reach in order to avoid reversion. Default is 0 (zero), valid values are 0-5",5
"Profiling: Analysis - Number of results shown 
When changing the parameter  'number of results shown' in a column>pattern freaquency table analysis, the pattern is lost, instead it's replaced by the individual values from the source file. see attached document.    This is just happened on File Delimited Connection, in my testing, it's Ok on Database connection.",2
"fail to copy sub process if tRowGenerator exist.
fail to copy sub process if tRowGenerator exist in the TOS_DI-20150305_0334-V5.6.2SNAP product.",2
"upload a correct ""org.talend.dataprofiler.top.chart_6.0.0.jar"" file to the server after resolve this issue
Jar will be automatically published on nexus from now on: http://newbuild.talend.com:8081/nexus/content/repositories/TalendOpenSourceRelease/org/talend/studio/   Thanks Irene for https://github.com/Talend/tdq-studio-se/commit/fed43e50c52f4d6e42cb4d34e06aaeb105b02b53   We still need to provide them to Mike after they are built so that they appear at https://talend-update.talend.com/nexus/content/repositories/libraries/org/talend/libraries/",3
"Port the tVerifyEmail to 5.6 branch
This component is required by TIC.",5
"Enrich with results of analysis
After the execution of the analysis, the results should be stored in the ontology.   Results like min, max are important to define a domain on numeric data. (only for numeric columns, not for dates)  Thresholds set by the user are already stored in the ontology. Some thresholds can be computed from results of analysis.    Rules:  Attribute domain (defined by Min and Max Indicators thresholds) min and max values are updated according to the following rules:  - if there is no threshold on the min (max) indicator, and if the min  (max) indicator value is less (greater) than the attribute domain min (max) value, then the domain min (max) value is updated with the new value of the min indicator  - if the indicator has some thresholds set, then the min (and/or max) threshold will update the domain min (and/or max) value every time.      Use WARN instead of ERROR for the message saying that ""Failed to connect to the Semantic Repository Server. Please check your settings and make sure the server is up...""    Store min/max indicator percentage threshold information into ontology repository and reuse for analysis generation. (TDQ-10952)  ",5
"improve the tdqportal after upgrade to spagobi 5.1
nan",8
"Email validation component - Step 3 - Auto-refresh TLD list
This is step 3 of the email validation component.   We need a way to refresh the TLD list from https://data.iana.org/TLD/tlds-alpha-by-domain.txt       ",20
"Can't use context in PREVIEW dialog on tMatchGroup
I encounter a problem with tMatchGroup component in version 5.6.1.    During my test, I try to set a context variable for the __INTERVAL_RULE__ (as a Double).    On execution, I have the error below.    I'm a little bit bored, because I have a customer who uses a context variable without any problem in version 5.3.1 and I guess a potential migration problem here.      Exception in component tMatchGroup_1_GroupIn  java.lang.NumberFormatException: For input string: ""context.INTERVAL_RULE""      at sun.misc.FloatingDecimal.readJavaFormatString(FloatingDecimal.java:1250)      at java.lang.Double.valueOf(Double.java:504)      at org.talend.dataquality.record.linkage.grouping.AbstractRecordGrouping.createRecordMatcher(AbstractRecordGrouping.java:541)      at org.talend.dataquality.record.linkage.grouping.AbstractRecordGrouping.initialize(AbstractRecordGrouping.java:508)      at di_demo.testmatchgroup_0_1.TestMatchGroup.tFixedFlowInput_1Process(TestMatchGroup.java:1655)      at di_demo.testmatchgroup_0_1.TestMatchGroup.runJobInTOS(TestMatchGroup.java:2183)      at di_demo.testmatchgroup_0_1.TestMatchGroup.main(TestMatchGroup.java:2030)  [statistics] disconnected   ",5
"Create version 5.6.2 in Babili and populate it
nan",2
"start  tdqportal can not show the login page--installed by installer
1. install dqportal by  installer build. successfully  2. start it by click ""start_tdqp.bat""  3. try to visit web page by ""http://IP:8580/tdqportal""    Expected Result:  show the logon page correctly.    Actual Result:  can not show the logon page, and errors show.    NOTE: we have  ""hsqldb1_8_0_2.jar"" and  ""mysql-connector-java-5.0.8-bin.jar"" in tomcat/lib",5
"job about tBatchAddressRowCloud + MelissaData get NPE when input data more than 100 rows
1. import the job , set license for melissadata  try to run it.    *NOTE* : the ""query"" in the input component controls the input rows.    Expected Result:  can get result correctly.    Actual Result:  get NPE directly.    {code}  [ERROR]: org.talend.dataquality.address.api.AsyncAddressObjectHandler - java.lang.NullPointerException  java.util.concurrent.ExecutionException: java.lang.NullPointerException   at java.util.concurrent.FutureTask$Sync.innerGet(FutureTask.java:252)   at java.util.concurrent.FutureTask.get(FutureTask.java:111)   at org.talend.dataquality.address.api.AsyncAddressObjectHandler$AsynchronizedOutputRunnable.run(AsyncAddressObjectHandler.java:100)   at java.lang.Thread.run(Thread.java:724)  Caused by: java.lang.NullPointerException   at org.talend.dataquality.address.melissaData.batch.BatchMelissaQueryCallable.parseJsonResult(BatchMelissaQueryCallable.java:108)   at org.talend.dataquality.address.melissaData.batch.BatchMelissaQueryCallable.call(BatchMelissaQueryCallable.java:67)   at org.talend.dataquality.address.melissaData.batch.BatchMelissaQueryCallable.call(BatchMelissaQueryCallable.java:41)   at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)   at java.util.concurrent.FutureTask.run(FutureTask.java:166)   at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   ... 1 more  {code}",5
"Export babili translations into git (for 6.0.0M5)
nan",2
"Upgrade Drools Guvnor (KIE Drools Workbench) to 6.2 
nan",10
"The result is not correct when set ""9a*"" for "" Simplified Pattern"".
nan",2
"Export babili translations into git on 5.6
nan",2
"Create version 6.0.0M4 in Babili and populate it
nan",2
"add MariaDB driver in driver list for DQ components
Refer to TDI-30249. Need update DQ components too.  tMySQLInvalidRows  tMySQLValidRows",5
"Update jar version for Postgresql on the component of DQ
tPostgresqlInvalidRows",3
"Allow store analysis data into datamart without generating report
Sometimes customer only want to store analysis data, and use dqportal to generate report later, but currently you have to generate the report with the store process, it's better to allow this feature to enhance usability.    Attached screen capture for the UI part of this feature.  A question mark icon appears after the checkbox with a tooltip: ""The results of the analysis will be stored into the data mart. No output (pdf, html, xls) file will be generated when not checked"".    When the user opens the editor, the checkbox is checked (default behavior).  When the checkbox is checked, the behavior is like in previous versions.    When the checkbox is NOT checked, the user wants to run the report execution, but does not want to get a pdf (or html, xls) report: so no pdf report will be generated, but the analysis results are nevertherless stored in the data mart.  When the checkbox is NOT checked, all fields are grayed out  When the checkbox is NOT checked, the information in these fields is not taken into account (but may still be stored in EMF file).    The label of the checkbox is: ""Generate output file"".    Change the ""generate a single file"" label for ""with timestamp""    --  by default, now this checkbox is checked    --  technically, the logic inverted (with timestamp = ! generate single file)    --  don't change the EMF variables (keep GEN_SINGLE_REPORT = ""Single output"")    The tooltip of this checkbox can be improved:  ""when checked, the file name will get a timestamp and the generated file will be not overwritten at each time a report is generated""  ",8
"Improve the way we use regexes
Currently there is one validator class for one regex. As the validator not only validates regexes, we want to keep them, but the design is not scalable when we want to add more regexes.   We will use a json file to store the additional regexes and their name, (and description?).    Aicha had about 30 regexes (if I remember). See in the indicators. ",8
"Simplify HDFS file Profiling with Hive - step 2
See subtasks below",20
"UX : new icon set
integrate the new icons in the studio (data-profiling.zip)  These icons come from https://github.com/Talend/tdq-studio-se/tree/master/main/plugins/org.talend.dataprofiler.core/icons     and integrate the new icons of components: Data_Quality v1.zip  ",5
"redundant characters show for value in ""tdq_indicator_definition"" (datamart)table
1. check the value in datamart -tdq_indicator_definition, there are some value surrounded by !!!  refer to the pic attached,   also in dqportal.    Expected Result:  show the value correctly both in datamart and dqportal.",1
"Create back thread to load data on the preview table of column analysis
1.reopen analysis editor  2.right click to create new column analaysis editor.  3.create column analysis by the menu and select columns on the wizard.    Those action only open the preview table and not load data.  Because we don't want to waitting it.  Create a back ground thread to load data.  ",5
"Create Semantic Discovery UI
Attached pictures show some ideas of this UI.    This wizards opens after a right click on a table (or a set of columns) in the repository view and select the menu ""Suggest analysis"".     Three steps.  # finding semantic names of each column using the semantic categorization API  # finding the concept mapping using the semantic mapping API  # the last step is the metadata page of the new analysis creation wizard    In the first page, the user can edit the semantic names.  These semantic names created by the user are kept during the second step.     The second steps lists all concepts that matched and display on a chart the number of matched columns (number of columns in common in the semantic schema and the concept).  ",20
"check in DQ side for TDI-32272
Since MDM components has a new drop-down list:""MDM Version""with 2 options: ""5.6 server"" and ""6.0 server"", Need gui team to add the same drop-down list for mdm repository",2
"Deduplicate lucene dependency
remove lucene-core-3.0.1 from library plugin, update component reference to 3.0.3",1
"run column analysis focus on ""Analysis Result"" page  get many errors in error log--for some frequency indicators(analysis can run successfully)
1. create a column analysis, set sql engine, add int, date, varchar columns  2. add all available System indicators for the three columns.  3. run the analysis when focus on ""Analysis Settings"" page, successfully  4. turn to ""Analysis Results"" page. re-run it by click ""Run"" icon.      Expected Result:  analysis run without error.    Actual Result:  analysis can run successfully(check by Execution Status, and Last Successful Execution), but get errors in error log.      {code}  org.eclipse.swt.SWTException: Failed to execute runnable (java.lang.ClassCastException: org.jfree.data.category.DefaultCategoryDataset cannot be cast to org.talend.dataprofiler.common.ui.editor.preview.ICustomerDataset)    org.eclipse.swt.SWT.error(SWT.java:4441)    org.eclipse.swt.SWT.error(SWT.java:4356)    org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:139)    org.eclipse.swt.widgets.Display.runAsyncMessages(Display.java:4147)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3764)    org.eclipse.jface.window.Window.runEventLoop(Window.java:832)    org.eclipse.jface.window.Window.open(Window.java:808)    org.eclipse.ui.internal.views.log.EventDetailsDialog.open(EventDetailsDialog.java:181)    org.eclipse.ui.internal.views.log.EventDetailsDialogAction.run(EventDetailsDialogAction.java:98)    org.eclipse.ui.internal.views.log.LogView$15.doubleClick(LogView.java:537)    org.eclipse.jface.viewers.StructuredViewer$1.run(StructuredViewer.java:831)    org.eclipse.core.runtime.SafeRunner.run(SafeRunner.java:42)    org.eclipse.ui.internal.JFaceUtil$1.run(JFaceUtil.java:50)    org.eclipse.jface.util.SafeRunnable.run(SafeRunnable.java:178)    org.eclipse.jface.viewers.StructuredViewer.fireDoubleClick(StructuredViewer.java:828)    org.eclipse.jface.viewers.AbstractTreeViewer.handleDoubleSelect(AbstractTreeViewer.java:1472)    org.eclipse.jface.viewers.StructuredViewer$4.widgetDefaultSelected(StructuredViewer.java:1237)    org.eclipse.jface.util.OpenStrategy.fireDefaultSelectionEvent(OpenStrategy.java:252)    org.eclipse.jface.util.OpenStrategy.access$0(OpenStrategy.java:249)    org.eclipse.jface.util.OpenStrategy$1.handleEvent(OpenStrategy.java:311)    org.eclipse.swt.widgets.EventTable.sendEvent(EventTable.java:84)    org.eclipse.swt.widgets.Display.sendEvent(Display.java:4353)    org.eclipse.swt.widgets.Widget.sendEvent(Widget.java:1061)    org.eclipse.swt.widgets.Display.runDeferredEvents(Display.java:4172)    org.eclipse.swt.widgets.Display.readAndDispatch(Display.java:3761)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine$9.run(PartRenderingEngine.java:1151)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.e4.ui.internal.workbench.swt.PartRenderingEngine.run(PartRenderingEngine.java:1032)    org.eclipse.e4.ui.internal.workbench.E4Workbench.createAndRunUI(E4Workbench.java:148)    org.eclipse.ui.internal.Workbench$5.run(Workbench.java:636)    org.eclipse.core.databinding.observable.Realm.runWithDefault(Realm.java:332)    org.eclipse.ui.internal.Workbench.createAndRunWorkbench(Workbench.java:579)    org.eclipse.ui.PlatformUI.createAndRunWorkbench(PlatformUI.java:150)    org.talend.rcp.intro.Application.start(Application.java:197)    org.eclipse.equinox.internal.app.EclipseAppHandle.run(EclipseAppHandle.java:196)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.runApplication(EclipseAppLauncher.java:134)    org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:104)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:380)    org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:235)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:648)    org.eclipse.equinox.launcher.Main.basicRun(Main.java:603)    org.eclipse.equinox.launcher.Main.run(Main.java:1465)  Caused by: java.lang.ClassCastException: org.jfree.data.category.DefaultCategoryDataset cannot be cast to org.talend.dataprofiler.common.ui.editor.preview.ICustomerDataset    org.talend.dataprofiler.core.ui.events.FrequencyDynamicChartEventReceiver.handle(FrequencyDynamicChartEventReceiver.java:57)    org.talend.dataprofiler.core.ui.events.EventManager.publish(EventManager.java:123)    org.talend.dataprofiler.core.service.TOPRepositoryService.publishDynamicEvent(TOPRepositoryService.java:656)    org.talend.dq.analysis.ColumnAnalysisSqlExecutor$1.run(ColumnAnalysisSqlExecutor.java:1383)    org.eclipse.swt.widgets.RunnableLock.run(RunnableLock.java:35)    org.eclipse.swt.widgets.Synchronizer.runAsyncMessages(Synchronizer.java:136)  	... 43 more    {code}",1
"Move sampling plugin from EE to SE
nan",2
"Find a way to resolve the lucene dependency in sampling project
for 6.0.0M5, the Function SYNONYM_REPLACE is deactivated in the API, in order to remove the dependency on org.talend.dataquality.standardization plugin, which we don't want to include in TOS_DQ.    For related compoenent (tDuplicateRow), the dependency jar is created during each build, so the Function is not available in this M5 release either.    We will need to split this dependency from the sampling feature.",5
"Create version 6.0.0M5 in Babili and populate it
nan",2
"Export babili translations into git (for 6.0.0RC1)
nan",2
"Survivorship  rule doesn't appear in studio GUI metadata if the rule name contains ""_""
If we put ""_"" in the tRuleSurvivorship component-Rule package name(see image RulePackageName_ContainsCharacter.png);    it can generate well under ""workspace\MDM541\metadata\survivorship"" and job runs well(see image Generated.png);    but it doesn't appear in the Repository-Metadata-Rules Management-Survivorship Rules(see image RulePackageName_ContainsCharacter.png).     If we delete the ""_"", it appears in GUI.(see image RulePackageName_WithoutCharacter.png)",5
"UI improvements in Indicator selection dialog
See subtasks",13
"[DQ Portal] - rename QBE to ""Custom Reports""
rename ""Reporting"" to ""Reports"" too",1
"Support MariaDB well in Studio(include datamart) and DQ portal
for the data mart    because the mariadb is similiar to mysql,  the only differences with mysql as follows:  driverClassName=""org.mariadb.jdbc.Driver""   url=""jdbc:mariadb://...""  and the jar as the attachment file    so in our studio, we can add a mariadb version when create datamart as mysql(like components)  and the same in the installer and dqportal    ",20
"Allow the user to create a column analysis with a right-click on an HDFS file
A new analysis can be applied on an HDFS file.   When the user wants to analyze an HDFS file, the analysis is actually done on the related Hive columns.     When the user right-clicks on a HDFS file in the repository view, a new wizard is launched with the following pages:  - Hive table creation pages like in TDQ-9605   - new column analysis page (all columns are preselected with simple statistics indicators)  ",8
" tRule job doesn't work on 6.0M5
run the job with tRule on M5.  it doesn't work and get an error:  --------------------------------------------------------------------------------------------------------------------------------------------------------  Exception in thread ""main"" java.lang.NoClassDefFoundError: org/eclipse/core/runtime/Plugin    java.lang.ClassLoader.defineClass1(Native Method)    java.lang.ClassLoader.defineClass(ClassLoader.java:792)    java.security.SecureClassLoader.defineClass(SecureClassLoader.java:142)    java.net.URLClassLoader.defineClass(URLClassLoader.java:449)    java.net.URLClassLoader.access$100(URLClassLoader.java:71)    java.net.URLClassLoader$1.run(URLClassLoader.java:361)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:424)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:357)    org.codehaus.jdt.groovy.integration.LanguageSupportFactory.tryInstantiate(LanguageSupportFactory.java:140)    org.codehaus.jdt.groovy.integration.LanguageSupportFactory.getLanguageSupport(LanguageSupportFactory.java:125)  [statistics] disconnected    org.codehaus.jdt.groovy.integration.LanguageSupportFactory.getParser(LanguageSupportFactory.java:54)    org.eclipse.jdt.internal.compiler.Compiler.initializeParser(Compiler.java:743)    org.eclipse.jdt.internal.compiler.Compiler.<init>(Compiler.java:298)    org.eclipse.jdt.internal.compiler.Compiler.<init>(Compiler.java:164)    org.drools.compiler.commons.jci.compilers.EclipseJavaCompiler.compile(EclipseJavaCompiler.java:412)    org.drools.compiler.commons.jci.compilers.AbstractJavaCompiler.compile(AbstractJavaCompiler.java:49)    org.drools.compiler.rule.builder.dialect.java.JavaDialect.compileAll(JavaDialect.java:402)    org.drools.compiler.compiler.DialectCompiletimeRegistry.compileAll(DialectCompiletimeRegistry.java:46)    org.drools.compiler.compiler.PackageRegistry.compileAll(PackageRegistry.java:123)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.compileAll(KnowledgeBuilderImpl.java:1255)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.compileAllRules(KnowledgeBuilderImpl.java:901)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.addPackage(KnowledgeBuilderImpl.java:892)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.addPackageFromDrl(KnowledgeBuilderImpl.java:433)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.addKnowledgeResource(KnowledgeBuilderImpl.java:653)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.add(KnowledgeBuilderImpl.java:2164)    org.drools.compiler.builder.impl.KnowledgeBuilderImpl.add(KnowledgeBuilderImpl.java:2153)    demodrools.t_0_1.T$1KnowledgeBase_tRules_1.readKnowledgeBaseDRL(T.java:716)    demodrools.t_0_1.T$1KnowledgeBase_tRules_1.readKnowledgeBase(T.java:699)    demodrools.t_0_1.T.tFileInputDelimited_1Process(T.java:777)    demodrools.t_0_1.T.runJobInTOS(T.java:1327)    demodrools.t_0_1.T.main(T.java:1184)  Caused by: java.lang.ClassNotFoundException: org.eclipse.core.runtime.Plugin    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:424)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:357)  ",13
"Add a feature to delete existing report in datamart in DQPortal
Now we don't have a way to delete the existing report in datamart, we can't truncate database each time, it's better to add a featue in DQPortal to do this.",13
"Create version 6.0.0RC1 in Babili and populate it
nan",2
"No related hadoop cluster information shows in the ""Export Items"" dialog.
No hadoop cluster item display in the dialog, another issue is the Import Items still shows for The import Items still shows for hdoop cluster, hdfs and hive link.",13
