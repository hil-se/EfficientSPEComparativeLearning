Issue,Storypoint
"Upgrade to Spring Boot 1.2.0
As to prepare for 1.1 release, we would like to upgrade to Spring Boot 1.2.0 (RC1) (depends on Spring 4.1.2) so that we can leverage the new features, enhancement and bug fixes.     [Spring Boot Milestones|https://github.com/spring-projects/spring-boot/milestones]",3
"Upgrade to Spring Integration 4.1.0
As to prepare for 1.1 release, we would like to upgrade to Spring Integration 4.1.0 (RC) so that we can leverage the new features, enhancement and bug fixes.     ",3
"Document the configuration of the JobRepository 
XD-2172 added a custom BatchConfigurer to allow the configuration of various properties when creating the JobRepository, isolationLevel, tablePrefix etc.  This should be documented in either the Application Configuration second of the docs or in the Batch Job section.",1
"Support for GemXD as a target database in a batch job
Getting Caused by:  {quote} org.springframework.transaction.CannotCreateTransactionException: Could not open JDBC Connection for transaction; nested exception is java.sql.SQLException: S QLSTATE=XJ045,SEVERITY=-1: (Server=localhost[1529],Thread[DRDAConnThread_24,5,gemfirexd.daemons]) Invalid or (currently) unsupported isolation level, '8', passed to Conn ection.setTransactionIsolation(). The currently supported values are java.sql.Connection.TRANSACTION_NONE, java.sql.Connection.TRANSACTION_READ_UNCOMMITTED, java.sql.Con nection.TRANSACTION_READ_COMMITTED and java.sql.Connection.TRANSACTION_REPEATABLE_READ.   org.springframework.jdbc.datasource.DataSourceTransactionManager.doBegin(DataSourceTransactionManager.java:242)   org.springframework.transaction.support.AbstractPlatformTransactionManager.getTransaction(AbstractPlatformTransactionManager.java:373)   org.springframework.transaction.interceptor.TransactionAspectSupport.createTransactionIfNecessary(TransactionAspectSupport.java:420)   org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:257)   org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:95)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy95.getLastJobExecution(Unknown Source)   org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:98) {quote}  when launching a simple batch job with GemXD configured as the database  {quote} job create --name myjob --definition ""filejdbc --resources=file:///home/mpollack/csv/*.csv --driverClassName=com.pivotal.gemfirexd.jdbc.ClientDriver --names=id,name,test --tableName=APP.mytable"" job deploy --name myjob  job launch --name myjob  {quote}  {quote} spring:   datasource:     url: jdbc:gemfirexd://localhost:1527/     username: admin     password: admin     driverClassName: com.pivotal.gemfirexd.jdbc.ClientDriver {quote}",5
"Intermittent TcpModulesTests.testTcpSink test failure
{noformat}  org.junit.ComparisonFailure: org.junit.ComparisonFailure: expected:<[Hi there!  ]> but was:<[]>  org.junit.ComparisonFailure: expected:<[Hi there!  ]> but was:<[]>    org.junit.Assert.assertEquals(Assert.java:115)    org.junit.Assert.assertEquals(Assert.java:144)    org.springframework.xd.shell.command.TcpModulesTests.testTcpSink(TcpModulesTests.java:63)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)  (60 more lines...)  {noformat}    https://build.spring.io/browse/XD-JDK8-JOB1-1162/test",1
"Vary Producer and Consumer in combination using 2 Queues (ECB-6)
The results from EC2 testing show that once prefetch and message size are set, varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies.     Using 500 prefetch, 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.    Test 1 (one producer / one consumer):  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  Test 2 (one producer / two consumers):  -a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500  Test 3 (two producers / one consumer):  -a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500  -a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500  Test 4 (two producers / two consumers):  -a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500  -a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500  ",3
"Vary message size (EC-DB-2)
Use a single producer, single consumer, prefetch size = 50.  Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.    Vary the message size and measure the msg/sec rate and calculate data transfer rate in MB/sec.    *Message Sizes:*  100 bytes  1000  10,000  100,000     During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",3
"Vary prefecth size (EC-DB-3)
Use a single producer, single consumer, message size of 1000 bytes.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.    Vary the prefetch size.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.    *Prefetch Sizes:*  * 1  * 10  * 50  * 100  * 10000    During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",3
"Vary queue number (ECB-7)
Based on the the results from B-6, select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate, prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ‘top’ for the broker and PerfTest processes.      Test 1 (2 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 2 (3 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  Test 3 (4 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500  Test 4 (5 queues)  -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500  -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500  etc.  ",3
"Vary consumer size (EC-DB-4)
Using a single producer, message size of 1000 bytes, Pretch of 100.   Send 1M messages and increase or decrease so that a given test iteration takes about 2 minutes.    Vary the number of consumers.   Measure the msg/sec rate and calculate the data transfer rate in MB/sec.    *Number of consumers:*  * 1  * 2  * 4  * 6  * 10  * 50    During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",2
"Vary producer size (EC-DB-5)
Use the number of consumers gave a maximum throughput in the previous test (say 10 consumers), message size 100 bytes, Prefetch 100.   Send 1M messages    Vary the number of producers.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.    *Number of producers:*  * 2  * 4  * 6  * 10  * 50    During the measurements look at the RabbitMQ Admin UI and see if the queue is backing up.",3
"Vary Producer and Consumer in combination using 2 Queues (B-6) 
The results from EC2 testing show that once prefetch and message size are set, varying the number of producers or consumers independently does not impact the message rate.  The in-house testing numbers need another plan to try an understand some discrepancies.     Using 500 prefetch, 1000 byte message size run two instances of PerfTest at the same time with each instance referencing a different queue.  Vary the number of consumer and publishers.    Test 1 (one producer / one consumer):  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 2 (one producer / two consumers):  * -a -u q1 -p -x 1 -y 2 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 2 -s 1000 -z 60 -q 500    Test 3 (two producers / one consumer):  * -a -u q1 -p -x 2 -y 1 -s 1000 -z 120 -q 500  * -a -u q2 -p -x 2 -y 1 -s 1000 -z 120 -q 500    Test 4 (two producers / two consumers):  * -a -u q1 -p -x 2 -y 2 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 2 -y 2 -s 1000 -z 60 -q 500  ",1
"Vary queue number (B-7)
Based on the the results from B-6, select the number of consumer/producers that give a distinct >5% increase in message rate.  Below 5% change in message rate, prefer lower consumer/producer count.    Vary the number of PerfTest instances that are run simultaneously and use their own independent queue from 1 until the overall messages/sec on the broker plateaus.   Note the CPU performance using ‘top’ for the broker and PerfTest processes.    Test 1 (2 queues)  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 2 (3 queues)  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 3 (4 queues)  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500    Test 4 (5 queues)  * -a -u q1 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q2 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q3 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q4 -p -x 1 -y 1 -s 1000 -z 60 -q 500  * -a -u q5 -p -x 1 -y 1 -s 1000 -z 60 -q 500    etc...    ",1
"Vary queue number on 32 core machine (ECB-8)
Rerun test XD-2278 on a EC2 32 core machine and see when we max out.",5
"CompositeModuleDefinition should contain more than List<ModuleDefinition>
CMD should contain not only name and type of the child module, but also capture the options that were used in the composition. An intermediate between ModuleDefinition and ModuleDescriptor should be created for that purpose (and maybe be part of ModuleDescriptor then)",5
"Change composed module behavior to ""black box"" 
Composed Module currently behave as ""white boxes"". As soon as a module is composed (say ""http | filter"") then all options of the children modules are available (as e.g. http.port and filter.expression in the example above).  Change this so that a composed module is a black box: user has to explicitly expose an option for it to be available (most certainly using a short name). Hardcoding of values would be retained (and possibly overridable).  Possible syntaxes : 1) {code} module compose foo --definition ""http --port=${myport:1234} | filter"" {code}  2) {code} module compose foo --definition ""http | filter"" --expose port {code}  2.1) in case of ambiguity (simulated in this particular example): {code} module compose foo --definition ""http | filter"" --expose http.port {code}  2.2) for specifying a default: {code} module compose foo --definition ""http | filter"" --expose port=1234 {code}  3) allow both 1) and 2), using 1) mainly for cases where we don't map 1 to 1 with the underlying option, e.g.: {code} filter --expression=${expr}+'foo' {code}  ",8
"Simple OOTB job for testing
Similar to {{time | log}}, we should ship a simple batch job that appends a timestamp to a file. This will make it much easier to validate job functionality, especially in automated tests.",2
"Have ResourceModuleRegistry transparently proxy a remote root thru filesystem
ArchiveModuleRegistry and the use of Boot Archives inherently relies on java.io.File  Have ResourceModuleRegistry extend/compose ArchiveMR to transparently download and cache (remote) jars that may be located in a (non-file:) location.    The staging area should be customizable, but some subdir of java.io.tmpdir sounds like a sensible default",5
"Research how to use 'admin' server ports from ZK
As a user, I'd like to have the ability to access the random port (generated by tomcat) of the admin server (via _xd-shell_) so that I can point to the server and continue my interactions.   *Spike Details:* * Research whether connecting _xd-shell_ directly to ZK is a good approach or have a LB in-charge for the interaction. * How about something other than a pointer to a ZK directory in the shell for folks to experiment a bit before getting a LB involved?  *Note:* On some hadoop/hdfs setups access to zk is mandatory from hdfs client libs. There are some HA and federation setups which would anyway require xd shell to get access to zk if fs shell commands are used. ",8
"Redis backed aggregate counters should return results inclusive of start,end time interval
An aggregate counter query should return results inclusive of start and end time, [start,end] for time resolutions, minute, hour, day, month.  ",8
"Documentation for aggregate counter REST API should include query parameters
Query parameters for resolution, from, and to should be documented along with how to specify the time string (yyyy-MM-dd HH:mm:ss).",1
"Shell - Handle Pagination
This may be broken down into 2 issues. First of all we need to define the proper UI interaction for the CLI to deal with pagination and then of course the actual implementation.  ",8
"Upgrade to Kafka 0.9 and rerun failing tests
As a follow-up to Kafka message bus support, we would like to rerun the failing tests after upgrading to new [consumer|https://cwiki.apache.org/confluence/display/KAFKA/Kafka+0.9+Consumer+Rewrite+Design] rewrite.   [Response from Kafka support|http://mail-archives.apache.org/mod_mbox/kafka-users/201410.mbox/%3CCAHwHRrWZmLr94eHX1z5i36BYz%2B%3DCisx7GcbW1_Nn7ooNJcShMw%40mail.gmail.com%3E].",3
"Make processor:header-enricher available
nan",1
"Add support for audio/video source
As a user, I'd like to stream ingest audio and video data so that I can apply predictive analytics algorithms for facial detection.  *Spike scope:* * Research the feasibility of implementing [Motion-JPEG|http://en.wikipedia.org/wiki/Motion_JPEG] * Design specs on Motion-JPEG format  *Note:* [opencv|http://docs.opencv.org/trunk/doc/py_tutorials/py_objdetect/py_face_detection/py_face_detection.html], although having OOTB support, it is not platform compatible. ",8
"Add config parameter to enable/disable message rates in cluster view
As a user, I'd like to have a config parameter preferably in _servers.yml_ file so that I can enable/disable message rates in the cluster view. ",2
"Review POC and identify scope for gpload as OOTB Batch Job
As a user, I'd like to mass ingest data from databases (and others) into HDFS/HAWQ/GPDB so that I don't have to write custom code and as well as be able to ingest in an efficient way.",5
"Placeholder for 1.0.2 and 1.1M1 release testing effort
nan",8
"Research Spark integration options
*Spike scope:*  * Brainstorm * Identify options * Document ",8
"UI: Update AngularJS to v1.3
  * https://docs.angularjs.org/guide/migration#migrating-from-1-2-to-1-3  * http://angularjs.blogspot.com/2014/10/ng-europe-angular-13-and-beyond.html  * http://angularjs.blogspot.com/2014/10/angularjs-130-superluminal-nudge.html    ",4
"Update https://github.com/spring-projects/spring-xd/wiki/Modules
Need to update the Modules page and any other that describes top level xml files. Also describe alternate module implementations: XD-713, XD-1805, XD-2100",1
"Research refactoring effort for Kafka source to use simple consumer instead of high-level API
As a user, I'd like to use Kafka source through simple consumer API (as opposed to high-level) so that I can gain full control to offsets and partition assignment deterministically.    *Spike scope*:  - Study simple consumer API functionality  - Document findings, approach and next steps",8
"POC for Spark Integration
*Spike Scope:*    * Experiment with identified options  * POC with the logical integration choice",8
"Add support to install custom module archive
As a user, I'd like to push the custom module (built as uber-jar) via a REST API so that I can install the custom module in cluster. ",8
"Add support for PHD 2.1 (XD 1.1 M1 Release)
*XD 1.1 M1 Release + PHD 2.1 Upgrade - Action Items:*    * Update to SHDP 2.1.M2,   * Add Hadoop 2.5 (hadoop25)  * Remove hadoop22  * Remove PHD 1.0 (phd1)   * Change PHD 2.x from phd20 to phd21  * Test PHD 2.0 with phd21",3
"Create sample app to demonstrate Kafka integration
As a user, I'd like to have a sample app (GitHub project) so that I can use it as a reference while provisioning Spring XD cluster with Kafka.    Consider:  * Kafka as message bus  * Kafka as source    ",8
"Incremental data import with jdbchdfs job
Enhance the current jdbchdfs job in spring-xd to have an incremental load / delta load feature similar to sqoop. See sqoop documentation [here|http://sqoop.apache.org/docs/1.4.5/SqoopUserGuide.html#_incremental_imports]. The job will need to maintain some state between executions in order to decide the start point for the next data load.     The jdbchdfs job definition could take the following 2 new options.     h5. checkColumn   optional  Specifies the column to be examined when determining which rows to import. (the column should not be of type CHAR/NCHAR/VARCHAR/VARNCHAR/ LONGVARCHAR/LONGNVARCHAR). Column should be numeric or timestamp.  h5. lastValue   optional  If specified this will override any data saved from previous job runs. If not specified will take the saved max-value from the last job run. If no last job run data is available then it will not be an incremental load and all the data which satisfies the query will be used.    Sqoop provides 2 modes of operation for incremental load, 'append' and 'lastModified'. For jdbchdfs the job will always append as it is writing to a hdfs file.    Example: To import data from the database table some_table which has a last update column called lastUpdated, you could use.  {code}  xd:> job create myjob --definition ""jdbchdfs --sql='select col1,col2,col3 from some_table' --checkColumn=lastUpdated"" --deploy  {code}    The batch job should also be capable of being partitioned to run in parallel across multiple containers",5
"Parsing issues with kafka-bus.xml
Using Kafka as a transport option yields:    [2014-11-04 12:18:30.528] boot - 24061 ERROR [main] --- SpringApplication: Application startup failed  org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Failed to import bean definitions from URL location [classpath*:/META-INF/spring-xd/transports/kafka-bus.xml]  Offending resource: class path resource [META-INF/spring-xd/bus/message-bus.xml]; nested exception is org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    org.springframework.beans.factory.parsing.FailFastProblemReporter.error(FailFastProblemReporter.java:70)    org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:85)    org.springframework.beans.factory.parsing.ReaderContext.error(ReaderContext.java:76)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:248)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseDefaultElement(DefaultBeanDefinitionDocumentReader.java:199)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.parseBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:184)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.doRegisterBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:141)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.registerBeanDefinitions(DefaultBeanDefinitionDocumentReader.java:110)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.registerBeanDefinitions(XmlBeanDefinitionReader.java:508)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:187)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsFromImportedResources(ConfigurationClassBeanDefinitionReader.java:313)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitionsForConfigurationClass(ConfigurationClassBeanDefinitionReader.java:138)    org.springframework.context.annotation.ConfigurationClassBeanDefinitionReader.loadBeanDefinitions(ConfigurationClassBeanDefinitionReader.java:116)    org.springframework.context.annotation.ConfigurationClassPostProcessor.processConfigBeanDefinitions(ConfigurationClassPostProcessor.java:330)    org.springframework.context.annotation.ConfigurationClassPostProcessor.postProcessBeanDefinitionRegistry(ConfigurationClassPostProcessor.java:243)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanDefinitionRegistryPostProcessors(PostProcessorRegistrationDelegate.java:254)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:94)    org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:320)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.SingleNodeApplication.run(SingleNodeApplication.java:63)    org.springframework.xd.demo.kafka.KafkaDemo.main(KafkaDemo.java:28)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  Caused by: org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 9 in XML document from URL [jar:file:/Users/mbogoevici/.gradle/caches/modules-2/files-2.1/org.springframework.xd/spring-xd-dirt/1.1.0.BUILD-SNAPSHOT/cf6a9a013dbde49d2925e2b5177d01a028379758/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar!/META-INF/spring-xd/transports/kafka-bus.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:398)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:335)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:303)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:180)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:216)    org.springframework.beans.factory.xml.DefaultBeanDefinitionDocumentReader.importBeanDefinitionResource(DefaultBeanDefinitionDocumentReader.java:242)  	... 31 more  Caused by: org.xml.sax.SAXParseException; lineNumber: 9; columnNumber: 26; Open quote is expected for attribute ""{1}"" associated with an  element type  ""value"".    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.fatalError(ErrorHandlerWrapper.java:177)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:441)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    com.sun.org.apache.xerces.internal.impl.XMLScanner.reportFatalError(XMLScanner.java:1436)    com.sun.org.apache.xerces.internal.impl.XMLScanner.scanAttributeValue(XMLScanner.java:829)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanAttribute(XMLNSDocumentScannerImpl.java:439)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:255)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:428)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:390)  	... 36 more",1
"Add ""generator"" source (perf. testing)
As a user, I'd like to have a _generator_ source module so that I can create a number of messages of a specified size (similar to Rabbit's PerfTest utility).  Example: generator --numMsgs 10000 --msgSize 1024 --numThreads 1 ",8
"Add ""perf_meter"" sink (perf. testing)
As a user, I'd like to have a _perf-meter_ sink that will collect and push metrics to the standard container log file.    Example: perf-meter --numMsgs 1000  Will write to the container log a timestamp, message count, and message rate every 1000 messages.  The message rate is the value since the last log event.  Default values are those specified above. ",8
"Baseline (XD-B-1)
As a user, I'd like to create a stream such as _generator | perf-meter_ so that I can ingest 1M messages of 1000 bytes and one thread using XD's 'singlenode' container and measure performance characteristics.",8
"Vary producer threads (XD-B-2)
Send 1M messages of 1000 bytes via the generator, vary the number of producer threads.  Measure the msg/sec rate and calculate the data transfer rate in MB/sec.  *Number of threads* * 2 * 4 * 8",8
"UI: Add support for stoppable notifications
* Update Angular Growl to v2  * Allowing for stoppable notifications (in case you want to see it for longer than 5 secs)  ",3
"REST: ""jobs/configurations"" returns 404 if one job has error
There is a bug in the deployments rest end-point.     *How to reproduce:*     * Deploy a Batch job (success) that for example does not all necessary libraries in the class-patch and thus causes a “java.lang.ClassNotFoundException�?    *Result:*    You cannot retrieve the list of deployments list anymore using:    * http://localhost:9393/jobs/configurations    The rest endpoint will now report:    [{""links"":[],""logref"":""NoSuchBatchJobException"",""message"":""Batch Job with the name myJob doesn't exist""}]    This message is not entirely wrong…but extremely misleading. I think we should still return the entire list and rather mark the job as having an error.    Also returning an “404 Not Found�? is misleading as well.  ",3
"Add Greenplum Sink
User should have the option of Greenplum DB sink so they can write data directly to Greenplum DB via the pgfdist/gploader (Greenplum bulk loader).  The existing JDBC sinks are not suitable for high volume loads. The JDBC approach utilizes the master segment of Greenplum for loading datasets instead of the bulk loader utility.",3
"Create Boot Starters for Modules
Create various boot starter projects for module developers. This should include templates for source, processor, sink, and job and ideally different options for each. For example, a processor configured with XML, SI Java DSL, or SI Java DSL with lambdas.  ",5
"Add spring-xd-python to the distribution
nan",1
"UI: Create a dedicated Launch Page for Jobs
Create a dedicated Launch Page for Jobs. Currently we create a launch form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.",4
"UI: Create a dedicated scheduling page for Jobs
Create a dedicated Scheduling Page for Jobs. Currently we create a form underneath the deployments table. That is a bit unwieldy when many deployed jobs are shown in the table.    Similar to XD-2320",4
"Enable configuration of replication factor on the Kafka message bus
The field exists and it is referred to in application.yml, but it does not have a setter and the bus will always use the configured default, which is 1.",3
"Filejdbc jobs status shows ""STARTED"" even when job is complete
SHA: 67473dc71332c0727516b6f3fd11a55561b2472e  Deployment: 1 Admin, 2 Containers  JobStore: HSQLDB  OS: Mac OSX & Ubuntu  Reproducible: Yes  Job: job create foo \-\-definition ""filejdbc \-\-resources=file:filejdbctest/filejdbctest.out \-\-names=data --tableName=filejdbctest \-\-initializeDatabase=true ""\-\-deploy    When using Rabbit as a transport with more than one container and launching the job above.  The Job execution stays as ""STARTED"" status, even though the job is actually finished.   We expect it to reach a state of ""COMPLETED"".  Using Redis as a transport the job execution status does reach ""COMPLETED"".       The execution step list shows:   Id  Step Name                Job Exec ID  Start Time               End Time                 Status    --  -----------------------  -----------  -----------------------  -----------------------  ---------    8   step1-master             4            2014-11-06 15:28:29,820                           STARTED    9   step1-master:partition0  4            2014-11-06 15:28:29,854  2014-11-06 15:28:29,890  COMPLETED",3
"Add Partitioned Job Integration Tests Using Other Bus Implementations
{{JobCommandTests}} in xd-shell only uses a {{LocalMessageBus}} so the problem in XD-2323 was not discovered until a manual integration test was executed.  At a minimum, {{JobCommandTests.testLaunchPartitionedJob()}} should be run with all bus implementations.",8
"Set 'auto-startup' to false in Kafka source
We have to explicitly set it to false, in order to avoid an early start of the poller and the associated DistpatcherHasNoSubscribersException.",1
"Can't create stream running on Windows
Trying to test on Windows and getting the following exception when createing a stream - 'stream create --name tictoc --definition ""time | log'    {code}  09:34:20,789 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..  09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//  09:34:20,790 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application  09:34:20,793 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo  dules/  09:34:20,794 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  09:34:20,795 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Seattle:9393/admin-ui  09:34:20,797 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424  09:34:20,798 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  09:34:20,799 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  09:34:20,913 1.1.0.SNAP  INFO LeaderSelector-0 server.DeploymentSupervisor - Leader Admin singlenode:default,admin,singlenode,hsqldbServer:9393 is watching for  stream/job deployment requests.  09:34:21,013 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: type=INITIALIZED  09:34:21,070 1.1.0.SNAP  INFO main server.AdminServerApplication - Started AdminServerApplication in 6.364 seconds (JVM running for 18.031)  09:34:22,593 1.1.0.SNAP  INFO main server.ContainerRegistrar - Container {ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849  099f} joined cluster  09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\..  09:34:22,594 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  09:34:22,595 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:C:\Test\spring-xd-1.1.0.BUILD-SNAPSHOT\xd\bin\../config//mo  dules/  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container IP address: 192.168.0.120  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Container hostname:   Seattle  09:34:22,596 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop22  09:34:22,597 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Path cache event: path=/containers/08c72e88-66d4-4b47-bd4a-8f5e5849099f, type=CH  ILD_ADDED  09:34:22,600 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: type=INITIALIZED  09:34:22,607 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Container arrived: Container{name='08c72e88-66d4-4b47-bd4a-8f5e5849099f', attrib  utes={ip=192.168.0.120, host=Seattle, groups=, pid=1108, id=08c72e88-66d4-4b47-bd4a-8f5e5849099f}}  09:34:22,609 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.ContainerListener - Scheduling deployments to new container(s) in 15000 ms  09:34:22,611 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath: 2.2.0  09:34:22,612 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:64424  09:34:22,613 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  09:34:22,615 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  09:34:22,616 1.1.0.SNAP  INFO main server.ContainerServerApplication - Started ContainerServerApplication in 0.61 seconds (JVM running for 19.576)  09:36:15,837 1.1.0.SNAP ERROR http-nio-9393-exec-3 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.StringIndexOutOfBoundsException: String index out of range: -1          at java.lang.String.substring(String.java:1954)          at org.springframework.xd.dirt.module.ArchiveModuleRegistry.fromResource(ArchiveModuleRegistry.java:140)          at org.springframework.xd.dirt.module.ArchiveModuleRegistry.findDefinition(ArchiveModuleRegistry.java:68)          at org.springframework.xd.dirt.module.DelegatingModuleRegistry.findDefinition(DelegatingModuleRegistry.java:48)          at org.springframework.xd.dirt.module.store.ZooKeeperModuleDefinitionRepository.findByNameAndType(ZooKeeperModuleDefinitionRepository.java:78)          at org.springframework.xd.dirt.stream.XDStreamParser.resolveModuleType(XDStreamParser.java:317)          at org.springframework.xd.dirt.stream.XDStreamParser.determineType(XDStreamParser.java:212)          at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:168)          at org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)          at org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)          at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)          at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)          at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)          at java.lang.reflect.Method.invoke(Method.java:483)          at org.springframework.web.method.support.InvocableHandalerMethod.invoke(InvocableHandlerMethod.java:215)          at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)          at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)          at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:781)          at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:721)          at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)          at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)          at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)          at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)          at org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)          at javax.servlet.http.HttpServlet.service(HttpServlet.java:646)          at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)          at javax.servlet.http.HttpServlet.service(HttpServlet.java:727)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf  iguration.java:280)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)          at org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)          at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)          at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)          at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)          at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)          at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)          at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)          at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)          at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)          at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)          at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)          at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)          at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)          at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)          at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)          at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)          at java.lang.Thread.run(Thread.java:745)  {code}",3
"Zip created by Publish 1.1 only contains the shell.
XD, gemfire, directories in the zip file are missing.",1
"Job deployment list returns 404 after Laptop wakes up
*Version:*  XD 1.0.1  Mac OSX 10.9.5    *Problem:*  - Deployed a simple batch job in 'singlenode'  - Laptop put to sleep mode  - After login: notice that ZK is establishing connection   - Continues to clean-up prior to redeployment, but never goes through successfully  - Listing job both in UI and Shell states it is ""undeployed""    *Gunnar's experiment:*  - System is running in Single Node  - Laptop goes to sleep  - After waking up your laptop from sleep, you cannot retrieve the list of deployed jobs anymore (in AdminUI)    *Error:*  Only getting back a *404* - ""NoSuchBatchJobException"", ""Batch Job with the name abcd doesn't exist""",5
"AdminUI - Provide Server-Side Cron Expression Validation
It is easy to get a cron expression wrong.     Provide validation of the cron expression on the Schedule Job page using async validation.     * Submit the cron expression to the server-side - and validate that the expression is valid.  * Send a success message back (we may even send back some meta data … e.g. when is the next execution going to take place)  ",5
"Add test coverage for Kafka source and sink modules
As a PM, I'd like to have test coverage for both Kafka source and sink modules so that we can assert its functionality as part of the CI builds. ",8
"Create base perf test criteria
Since Kafka and Rabbit have different strategies on how a message system is implemented, we will need to update the tests used on rabbit to work with Kafka.  While they will not be exactly the same as before, they should exercise the same principles.  This story covers:   * Create the consumer and producer execution configurations for  kafka-producer-perf-test.sh and kafka-consumer-perf-test.sh.   * Record the tests a spreadsheet much like the Rabbit Base test spreadsheet    ",2
"Update Performance AMI to include Kafka
Create an AMI that will contain the Kafka Executable as well as the Kafka performance test tools.",1
"Feature Request: ZeroMQ (ZMQ, 0MQ) source
Requesting a ZeroMQ based source.  ",5
"Upgrade to Gradle 2.2
Looks like upgrade to Gradle 2.2 is not a simple version change, e.g. I see:   {code} FAILURE: Build failed with an exception.  * Where: Build file '/Users/hillert/dev/git/spring-xd/build.gradle' line: 219  * What went wrong: A problem occurred evaluating root project 'spring-xd'. > Could not find method forceDependencyVersions() for arguments [project ':documentation-toolchain'] on root project 'spring-xd'. {code}",3
"Remove external config properties for modules
There are some modules that use external config properties (kafka producer/consumer, hadoop properties etc.,). We need to avoid using such properties and have them configured inside module so that module and its properties are self contained.    ",5
"Ensure that branch-specific documentation is pulled and generated
nan",3
"Deleting a job and then re-adding a new definition with the same name fails
Using single-node deployment of Spring XD 1.0 GA, we needed to redefine several batch jobs. We deleted the jobs (""job destroy all""). When attempting to re-add, we received an error that a job with the name already exists. Performing ""job list"" confirms the jobs were gone.  To workaround, I needed to terminate the instance (server) of Spring XD and restart it. Since this was the single-node deployment without a live stream of data coming in this was okay, but would have been a major problem if bouncing the Spring XD server was not acceptable (i.e., live data being actively received).",5
"JDBCHDFS Job Password issue
Password for 'jdbchdfs' job definition is only hashing the initial portion of the password not the entire password (See attached image).    The password has an '_' char but it shouldn't matter. The entire password should be masked with '*' instead.",3
"Allow ""module compose"" to specify an explicit type
Currently, module composition always guesses the correct type because we don't have a module with a given name N that is both a source and a processor, or a processor and a sink (we only have the case source and sink, as in jdbc/jdbc or file/file).  If it were the case, then the heuristics for guessing the resulting type of a composition would break.  This issue is about adding the option for the user to explicitly specify the expected type of the composition, /if needed/.",8
"UI should quote parameters containing a space
Trying to deploy the `timestampfile` job using the UI.    Seems the UI doesn't quote string parameters that contains a space so the job creation fails.    Keeping all the defaults I get the following ""Resulting Definition"" in the UI:    timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true    (note: the --format parameter has a space)    which causes:    XD100E:(pos 128): Found unexpected data after stream definition: 'HH' timestampfile --restartable=false --directory=/tmp/xd/output/ --fileExtension=txt --fileName=${xd.job.name} --format=yyyy-MM-dd HH:mm:ss --dateFormat=yyyy-MM-dd --makeUnique=true *^  ",3
"XD UI not usable with IE 11
Trying to use the XD UI with Internet Explorer (version 11.0.9600.17031) is difficult. The screen doesn't refresh when streams/jobs are created or deployed. Had to erase the browsing history continuously to get state updates to show in the UI.",5
"Document Kafka message bus
As a user, I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a message bus as recommended. ",2
"Document Spark job
As a user, I'd like to refer to documentation in wiki so that I can setup and configure Spark as a Batch job as recommended. ",1
"Document Kafka source/sink
As a user, I'd like to refer to documentation in wiki so that I can setup and configure Kafka as a source or a sink as recommended. ",1
"User wants to package and deploy an XD application
Install a boot uberjar containing custom modules plus stream and job definitions, and possibly specific configuration. This potentially includes the ability to export and import all deployable resources defined in an XD environment.  ",8
"POM generation creates the correct dependency list
We are referencing Spring.IO deps when we shouldn't (since we moved to a different version of boot than in in the platform).",8
"Boot upgrade caused test failures
spring.groovy.template.check-template-location=false must now be set in the properties file.  ",3
"EC2 Integration Tests fail after Boot 1.2 upgrade
Many of the tests fail with:    {code}  java.lang.IllegalStateException: Cannot find template location: class path resource [templates/] (please add some templates, check your Groovy configuration, or set spring.groovy.template.check-template-location=false)  {code}    Somehow we need to disable this check, using the property suggested.",1
"xd-singlenode --verbose prints configuration information twice
If you start xd-singlenode with the --verbose flag the configuration information is printed twice.    Steps to reproduce   1) run {{xd-singlenode --verbose}}    Example output:  {code}     _____                           __   _______  /  ___|          (-)             \ \ / /  _  \  \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |   `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |  /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /  \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/        | |                  __/ |        |_|                 |___/  1.1.0.BUILD-SNAPSHOT             eXtreme Data      Started : SingleNodeApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    20:40:43,098 1.1.0.SNAP  INFO main server.SingleNodeApplication - Starting SingleNodeApplication v1.1.0.BUILD-SNAPSHOT on gauss with PID 79926 (/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-xd-dirt-1.1.0.BUILD-SNAPSHOT.jar started by tom in /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd)  20:40:43,512 1.1.0.SNAP  INFO main server.SingleNodeApplication - Started SingleNodeApplication in 0.993 seconds (JVM running for 1.374)  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: local  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  20:40:56,218 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://gauss:9393/admin-ui  20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:38225  20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  20:40:56,219 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: memory  20:40:56,226 1.1.0.SNAP  INFO main util.XdConfigLoggingInitializer -   	Apple_PubSub_Socket_Render=/tmp/launch-k1iYmY/Render  	BROWSER=open  	CRASH_HOME=/Users/tom/.gvm/crash/current  	DISPLAY=/tmp/launch-16fQxe/org.macosforge.xquartz:0  	EDITOR=vim  	GAIDEN_HOME=/Users/tom/.gvm/gaiden/current  	GEM_HOME=/Users/tom/.rvm/gems/ruby-1.9.3-p484  	GEM_PATH=/Users/tom/.rvm/gems/ruby-1.9.3-p484:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global  	GLIDE_HOME=/Users/tom/.gvm/glide/current  	GRADLE_HOME=/Users/tom/.gvm/gradle/current  	GRAILS_HOME=/Users/tom/.gvm/grails/current  	GREP_COLOR=1;33  	GREP_OPTIONS=--color=auto  	GRIFFON_HOME=/Users/tom/.gvm/griffon/current  	GROOVYSERV_HOME=/Users/tom/.gvm/groovyserv/current  	GROOVY_HOME=/Users/tom/.gvm/groovy/current  	GVM_BROADCAST_SERVICE=http://cast.gvm.io  	GVM_BROKER_SERVICE=http://release.gvm.io  	GVM_DIR=/Users/tom/.gvm  	GVM_INIT=true  	GVM_PLATFORM=Darwin  	GVM_SERVICE=http://api.gvmtool.net  	GVM_VERSION=2.2.0  	HADOOP_DISTRO=hadoop25  	HOME=/Users/tom  	IRBRC=/Users/tom/.rvm/rubies/ruby-1.9.3-p484/.irbrc  	JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_25.jdk/Contents/Home  	JAVA_MAIN_CLASS_79926=org.springframework.xd.dirt.server.SingleNodeApplication  	JBAKE_HOME=/Users/tom/.gvm/jbake/current  	LANG=en_US.UTF-8  	LAZYBONES_HOME=/Users/tom/.gvm/lazybones/current  	LC_ALL=en_US.UTF-8  	LC_CTYPE=UTF-8  	LESS=-F -g -i -M -R -S -w -X -z-4  	LESS_TERMCAP_mb=[01;31m  	LESS_TERMCAP_md=[01;31m  	LESS_TERMCAP_me=[0m  	LESS_TERMCAP_se=[0m  	LESS_TERMCAP_so=[00;47;30m  	LESS_TERMCAP_ue=[0m  	LESS_TERMCAP_us=[01;32m  	LOGNAME=tom  	LSCOLORS=exfxcxdxbxGxDxabagacad  	LS_COLORS=di=34:ln=35:so=32:pi=33:ex=31:bd=36;01:cd=33;01:su=31;40;07:sg=36;40;07:tw=32;40;07:ow=33;40;07:  	MAVEN_HOME=/Applications/dev/tools/apache-maven-3.2.1  	MY_RUBY_HOME=/Users/tom/.rvm/rubies/ruby-1.9.3-p484  	OLDPWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  	PAGER=less  	PATH=/Users/tom/.gvm/vertx/current/bin:/Users/tom/.gvm/springboot/current/bin:/Users/tom/.gvm/lazybones/current/bin:/Users/tom/.gvm/jbake/current/bin:/Users/tom/.gvm/groovyserv/current/bin:/Users/tom/.gvm/groovy/current/bin:/Users/tom/.gvm/griffon/current/bin:/Users/tom/.gvm/grails/current/bin:/Users/tom/.gvm/gradle/current/bin:/Users/tom/.gvm/glide/current/bin:/Users/tom/.gvm/gaiden/current/bin:/Users/tom/.gvm/crash/current/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484/bin:/Users/tom/.rvm/gems/ruby-1.9.3-p484@global/bin:/Users/tom/.rvm/rubies/ruby-1.9.3-p484/bin:/Library/Frameworks/Python.framework/Versions/2.7/bin:/usr/local/bin:/usr/local/sbin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/go/bin:/usr/texbin:/Users/tom/.rvm/bin:/Users/tom/.yadr/bin:/Users/tom/.yadr/bin/yadr:/Applications/dev/tools/apache-maven-3.2.1/bin:/Applications/dev/tools/apache-ant-1.9.2/bin:/Users/tom/.rvm/bin  	PID=79926  	PS4=+ %* %F{red}%x:%I %F{green}%N:%i%F{white} %_  	PWD=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd  	SCREEN_NO=  	SECURITYSESSIONID=186a4  	SHELL=/bin/zsh  	SHLVL=1  	SPRINGBOOT_HOME=/Users/tom/.gvm/springboot/current  	SSH_AUTH_SOCK=/tmp/launch-KXqpmP/Listeners  	TERM=xterm-256color  	TERM_PROGRAM=Apple_Terminal  	TERM_PROGRAM_VERSION=326  	TERM_SESSION_CLASS_ID=D65D4C24-B8F2-4B53-9179-EC38F2DCD1AE  	TERM_SESSION_ID=3FA5B432-B6C3-4F62-A7FB-00EB6B0F18C7  	TMPDIR=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/  	USER=tom  	VERTX_HOME=/Users/tom/.gvm/vertx/current  	VISUAL=vim  	XD_ANALYTICS=memory  	XD_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//  	XD_CONFIG_NAME=servers,application  	XD_HOME=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd  	XD_JMX_ENABLED=true  	XD_MODULE_CONFIG_LOCATION=file:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config//modules/  	XD_MODULE_CONFIG_NAME=modules  	XD_TRANSPORT=local  	__CF_USER_TEXT_ENCODING=0x1F5:0:0  	__CHECKFIX1436934=1  	_system_arch=x86_64  	_system_name=OSX  	_system_type=Darwin  	_system_version=10.9  	analytics=memory  	awt.toolkit=sun.lwawt.macosx.LWCToolkit  	catalina.base=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  	catalina.home=/var/folders/6b/qk0vj57j3dd579_vd8z0_fjr0000gn/T/tomcat.7064945282515648982.9393  	catalina.useNaming=false  	document=--  	embeddedHsql=true  	endpoints.jmx.enabled=true  	endpoints.jmx.uniqueNames=true  	endpoints.jolokia.enabled=true  	file.encoding=UTF-8  	file.encoding.pkg=sun.io  	file.separator=/  	ftp.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  	gopherProxySet=false  	http.nonProxyHosts=local|*.local|169.254/16|*.169.254/16  	java.awt.graphicsenv=sun.awt.CGraphicsEnvironment  	java.awt.headless=true  	java.awt.printerjob=sun.lwawt.macosx.CPrinterJob  	java.class.path=/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/modules/processor/scripts:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/config:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/activation-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/amqp-client-3.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aopalliance-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/args4j-2.0.16.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/asm-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjrt-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/aspectjweaver-1.8.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/avro-compiler-1.7.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/cglib-2.2.1-v20090111.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/classmate-1.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/com.ibm.jbatch-tck-spi-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-beanutils-1.9.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-cli-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-codec-1.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-collections-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-compress-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-configuration-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-daemon-1.0.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-dbcp-1.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-digester-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-el-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-fileupload-1.3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-httpclient-3.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-io-2.4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-jexl-2.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-lang-2.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-math-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-net-3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool-1.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/commons-pool2-2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-client-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-framework-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/curator-recipes-2.6.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/disruptor-3.2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/groovy-all-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/gs-collections-api-5.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guava-16.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/guice-servlet-3.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hibernate-validator-5.0.3.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/hsqldb-2.3.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-annotations-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-core-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-databind-2.3.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jackson-mapper-asl-1.9.13.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javassist-3.18.1-GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.batch-api-1.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.inject-1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/javax.mail-1.4.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jboss-logging-3.1.1.GA.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jcl-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jedis-2.5.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jersey-guice-1.9.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jettison-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jline-2.11.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/joda-time-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jolokia-core-1.2.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jopt-simple-4.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-path-0.9.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-simple-1.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/json-smart-1.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jsr305-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/jul-to-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kafka_2.10-0.8.1.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-data-core-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kite-hadoop-compatibility-0.17.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/kryo-2.22.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-1.2.17.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/log4j-over-slf4j-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-annotation-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/metrics-core-2.2.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/mongo-java-driver-2.12.2.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/netty-3.7.0.Final.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/objenesis-2.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/ognl-3.0.6.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/opencsv-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/paranamer-2.3.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-avro-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-column-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-common-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-encoding-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-format-2.0.0.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-generator-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-hadoop-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/parquet-jackson-1.4.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/postgresql-9.2-1002-jdbc4.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/reactor-core-1.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/scala-library-2.10.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-api-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/slf4j-log4j12-1.7.7.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snakeyaml-1.14.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/snappy-java-1.1.0.1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-amqp-1.4.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-aop-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-manager-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-admin-resources-1.3.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-core-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-infrastructure-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-batch-integration-3.0.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-beans-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-actuator-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-autoconfigure-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-loader-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-logging-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-security-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-thymeleaf-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-tomcat-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-boot-starter-web-1.2.0.RC1.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-cloudfoundry-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-core-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-cloud-spring-service-connector-1.0.0.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-context-support-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-core-4.1.2.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-commons-1.9.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-mongodb-1.5.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring/spring-xd/build/dist/spring-xd/xd/lib/spring-data-redis-1.4.1.RELEASE.jar:/Users/tom/Documents/dev/repos/spring...",2
"Add starting offset support for Kafka source
As a user, I want to be able to control the starting offset of the Kafka source when a stream is deployed, so that I can replay a topic if necessary.    Note:  - starting offset is only considered when the stream is deployed  - progress made by modules must survive their crash for a running stream  - undeploying and redeploying a stream with a specific start offset will cause the stream to read again from the start     TBD: what happens when streams are undeployed/redeployed - where do they resume from?",8
"Add partition allocation support for Kafka source
As a user, I want to be able to control the partition allocation for the Kafka source modules when a stream is deployed, so that I can colocate with other data sources.",8
"Pre-allocate partitions for Kafka source
As a user, I want Spring XD to pre-allocate a set of partitions between the Kafka source modules when a stream is deployed, so that deployment is simpler, and rebalancing doesn’t take place. ",8
"Pre-allocate partitions for Kafka message bus
As a user, I want Spring XD’s message bus to be able to pre-allocate partitions between nodes when a stream is deployed, so that rebalancing doesn’t happen when a container crashes and/or it’s redeployed.",8
"Created Acceptance CI test environment for 1.0.x
* Create the infrastructure (Mongo, Hadoop, ActiveMQ, Gemfire, Mysql, etc) in EC2 for the 1.0.2 acceptance tests  * Retrofit the 1.0.2 to use the new infrastructure  * Create a 1.0.2 branch for XD-EC2",5
"Remove usage of <context:property-placeholder location=.../> in module defitions
This doesn't follow the conventions we have with other modules and it also means it isn't easy to override via environment variables etc.  This is in HDFS and some others.",5
"Direct binding with singlenode leaves stream broken
xd:>stream create --name foo --definition ""time|log"" xd:>stream deploy --name foo --properties ""module.*.count=0""  {code} 16:42:35,121 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module java.lang.IllegalArgumentException: LocalMessageBus does not support consumer property: directBindingAllowed for foo.0. {code}  Ok, that's cool. Let's destroy and create again:  xd:>stream destroy --name foo  xd:>stream create --name foo --definition ""time|log"" --deploy  {code} org.springframework.context.ApplicationContextException: Failed to start bean 'org.springframework.integration.monitor.IntegrationMBeanExporter#0#9363c963-41db-4cd6-b273-b52b02aba80d'; nested exception is org.springframework.jmx.export.UnableToRegisterMBeanException: Unable to register MBean [MessageChannelMonitor: [name=output, sends=0]] with key 'org.springframework.integration:type=MessageChannel,name=output'; nested exception is javax.management.InstanceAlreadyExistsException: xd.foo:module=time.0,component=MessageChannel,name=output {code}   {code} xd:>runtime modules    Module Id       Container Id                          Options                                     Deployment Properties  Unit status   --------------  ------------------------------------  ------------------------------------------  ---------------------  -----------   foo.sink.log.1  ce5cf83f-3e62-4960-8d46-e5cb06203992  {name=foo, expression=payload, level=INFO}  {count=1, sequence=1}  failed {code}",3
"Doc generation accesses http://docbook.sourceforge.net
When generating docs, the build tries to access    http://docbook.sourceforge.net/release/images/draft.png    You will observe output like:    {code}  Error with opening URL 'http://docbook.sourceforge.net/release/images/draft.png': docbook.sourceforge.net  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  Background image not available: http://docbook.sourceforge.net/release/images/draft.png  {code}",2
"Investigate TypeConvertingStreamTests.testBasicTypeConversionWithTap test failure in CI builds
TypeConvertingStreamTests.testBasicTypeConversionWithTap() is failing intermittently. Why?",1
"Research Spark integration options (phase #2)
As a continuation, we would like to further investigate Spark, develop POC and identify the best appropriate design and implementation for XD.",8
"Make Asciidoc documentation compatible with Asciidoctor 1.5.x
""the meaning of the backtick has changed. The backtick now only does monospaced formatting, it does not escape the content. The migration guide walks you through the options:   http://asciidoctor.org/docs/migration/#migration-scenarios  ""  For more details see: https://github.com/asciidoctor/asciidoctor-gradle-plugin/issues/134",3
"Remove Test Scripts From XD
The acceptance tests cover the entire suite of script tests.  Thus they are no longer needed.  The only test that was remaining was posting 10 messages to a http source and writing to a long and making sure we didn't get an error.  This test (httpbash) was never called from the scripts CI build.",1
"Allow registering default SpEL functions to simplify expressions
Often one has to perform some basic conversion / parsings in Stream definitions. It would be helpful if one could provide some helper functions to simplify SpEL expressions.  E.g. instead of: {code} transform --expression=T(java.lang.Long).parseLong(payload.value.toString()) {code} it would be nice to be able to write: {code} transform --expression=parseLong(payload.value) {code}  I'm thinking of support for: * parseByte * parseInt * parseShort * parseLong * parseFloat * parseDouble * parseBoolean * parseTuple  (I don't think we'd need support for parseCharacter)  This issue is about: 1) providing the centralised infrastructure for defining the SpEL expressions 2) Add support for the above listed predefined SpEL expressions  Those functions should be able to work with String based as well as {{JsonToStringFriendlyNode}} as input.",8
"Allow arbitrary headers to be set in http-client processor
See http://stackoverflow.com/questions/26880903/using-mappedrequestheaders-in-spring-xd  ",4
"Distributed test should verify container shutdown
After each test execution, the containers are shut down via:  {code} @After public void after() { 	distributedTestSupport.shutdownContainers(); 	distributedTestSupport.ensureTemplate().streamOperations().destroyAll(); } ... public void shutdownContainers() { 	for (Iterator<Map.Entry<Long, JavaApplication<SimpleJavaApplication>>> iterator = 				mapPidContainers.entrySet().iterator(); iterator.hasNext();) { 		iterator.next().getValue().close(); 		iterator.remove(); 	} } {code}  The problem is that {{close()}} guarantees that the process is shut down, but it does not guarantee that the container is no longer registered in ZooKeeper. The cleanup procedure should verify that no containers appear in the output of  the {{runtime containers}} shell command. This will prevent the next test from deploying to a non-existent container.",2
"Research reactor-stream integration options
As a user, I'd like to have a _reactor-stream_ processor module so that I can ingest data using XD source modules and process them as time-window operations.     *Example 1:*  http | reactor-stream --timeWindow=10s --field=payload.sensorData --expressions=min,avg    This would give you 10 second time window of the min and avg values.    *Example 2:*  Reactor as a module    *Example 3:*  Integration with Spark streaming and reactor",8
"Add batching support for Rabbit Message Bus
As a user, I'd like to have _microbatching_ capability so that I can ingest based on batch intervals for enhanced performance throughput.     *Example:*  ""http --batchInterval=10 | log""",5
"Update ""About"" section in UI with relevant release links
As a user, I'd like to have API and Documentation links in the [""About""|https://github.com/spring-projects/spring-xd/blob/master/spring-xd-ui/app/scripts/shared/views/about.html] section within _admin-ui_.     It would be ideal to have the version # dynamically replaced for every release.  ",1
"Add ability to logout using the Admin UI
While there is a server endpoint to logout, we don't have that ability yet from the UI. As indicated by XD-2122 we will also need a meta-data REST endpoint  so we can interrogate whether security is enabled, whether the user is logged etc. So we can fulfill the requirements:     * Show a logout button only if a) security is enabled and b) user is logged in  * Show the username and/or full name of the user being logged in   ",5
"syslog-tcp Configure a FIxed Thread Pool
The {{syslog-tcp}} source uses the default tcp connection factory which has an unbounded thread pool; this can cause OOM if the bus blocks (e.g. rabbit is out of resources). ",2
"New sink for REST resources
A new sink that would POST the message payload to a REST service over http.  Could be created with code something like this, except without hardcoded user and password for basic auth...  rest-store.xml {code} <?xml version=""1.0"" encoding=""UTF-8""?> <beans xmlns=""http://www.springframework.org/schema/beans""        xmlns:xsi=""http://www.w3.org/2001/XMLSchema-instance"" xmlns:int=""http://www.springframework.org/schema/integration""        xmlns:http=""http://www.springframework.org/schema/integration/http""        xsi:schemaLocation=""http://www.springframework.org/schema/beans 		http://www.springframework.org/schema/beans/spring-beans.xsd 		http://www.springframework.org/schema/integration 		http://www.springframework.org/schema/integration/spring-integration.xsd 		http://www.springframework.org/schema/integration/http 		http://www.springframework.org/schema/integration/http/spring-integration-http.xsd"">  	<int:channel id=""input"" /> 	<int:channel id=""restout"" /> 	<int:header-enricher input-channel=""input"" output-channel=""restout""> 		<int:header name=""Content-Type"" value=""${contenttype:application/json}""/> 	</int:header-enricher>  	<http:outbound-channel-adapter url=""${url}""                                        request-factory=""clientHttpRequestFactory""                                                                           channel=""restout""                                                                                                              http-method=""${method:POST}""                                                                                                                          header-mapper=""""/>  	<bean id=""httpComponentsMessageSender"" class=""org.springframework.ws.transport.http.HttpComponentsMessageSender""> 		<property name=""credentials""> 			<bean class=""org.apache.http.auth.UsernamePasswordCredentials""> 				<constructor-arg value=""myuser""/> 				<constructor-arg value=""mypassword""/> 			</bean> 		</property> 	</bean>  	<bean id=""clientHttpRequestFactory"" class=""org.springframework.http.client.HttpComponentsClientHttpRequestFactory""> 		<property name=""httpClient"" value=""#{httpComponentsMessageSender.httpClient}""/> 	</bean> </beans>			 {code}  rest-store.properties {code} options.url.description = The URL to send data to options.url.type = String  options.method.description = HTTP method. Default POST options.method.type = String  options.contenttype.description = Content-Type header to set. Default application/json options.contenttype.type = String {code}",5
"Decouple messagebus dependencies
*Refactoring scope:* (_spring-xd-dirt_)  * Message bus dependencies      The goal is to decouple them from startup phase to further enhance initialization time. ",8
"Re-run Kafka baseline tests in new infrastructure
As a developer, I'd like to setup a performance testing infrastructure (rackspace), so I can start benching Kafka baselines and continue with XD use-cases.",8
"Add a Shell command to push custom module
As a user, I'd like to have a Shell command so that I can point to the custom-built _module_ archive and push it to the runtime for immediate usage. ",3
"Document custom module install procedures
As a user, I'd like to refer to documentation so that I can build the custom module based on recommended standards and patterns.",3
"hdfs-dataset sink should support JSON and a Map as input formats
The hdfs-dataset sink currently requires a POJO as input. We should also support JSON and a Map as input plus the ability to specify an Avro schema to be used.",8
"Need TCP-Client Source Acceptance test
nan",3
"Acceptance test for Kafka source and sink
nan",5
"Add support to host custom module in HDFS
As a user, I'd like to have the custom module (built as uber-jar) hosted in HDFS so that I can deploy the module to newly arriving containers. ",8
"Streams section of doc should explicitly mention that labels are required for ambiguous modules
Currently I believe we only mention labels in this section of the doc:  https://github.com/spring-projects/spring-xd/wiki/DSL-Reference#labels    And it is not even clear there that they are *required* when 2 or more module names would otherwise be ambiguous. It was probably written before we made that a mandatory part of the definition.    We should mention this somewhere in the 'streams' section of the manual. Even if none of the examples there currently have more than one occurrence of the same module, we should add one to illustrate this point.  ",2
"Add regression test
Verify that network interruptions will not negatively affect the XD cluster.    Verify that a container that looses connectivity will be able to rejoin the cluster cleanly.  Modules will redploy when the network is back up.  ",3
"Add integration tests
Scope is to have integration test coverage for source and sink modules. ",5
"incremental jdbcfile process for loading data into Isilon cluster
Users should have the ability to load data from a jdbc source to a file sink pointing to a file location (NFS mount to an Isilon cluster) in a particular directory structure.  Isilon support multiple protocols, including NFS and HDFS. by storing data directly into an NFS mount we would eliminate the HDFS overhead.  This functionality should be similar to the jdbchdfs job that is currently available in SpringXD. See Jira issue 'XD-2309' for more details.",5
"Need a way to specify a specific namenode for a given hdfs based job
A scenario where I have multiple jobs deployed to one singlenode or distributed instance of SpringXD that need to use different namenodes can easily exist.   The ability to specify a namenode, much the same way I can specify a directory would solve this problem.  The desired behavior would be to specify a namenode that wasn't set using 'hadoop config fs <namenode>' in the job description and have that value used instead of the value set at the SpringXD global level.",3
"XD requires long duration tests
In order to identify potential problems that may occur if XD is running for multiple hours we need to create a long duration test regime. Create an environment from which we can run both Singlenode and a simple cluster (1 Admin 2 container) for 24+ hours.  * Create 2 simple streams   * http|file  * file|log  * Send data to http source 2 times a second for 24 hours * This test should execute checkprocs every 5 minutes to capture and record the status of the XD> * Record memory usage and system load.",8
"TCP-Client source module throws ClassNotFoundException
*Version:*  XD: 1.1 M1    *Problem:*  Trying to use tcp-client source module and observing an exception while deploying the stream.    *Stream Definition:*  {code:xml}   curl --data name=dummy-firehose --data definition='tcp-client --decoder=LF --port=8080 | log' --data deploy=true http://localhost:9393/streams/definitions  {""name"":""dummy-firehose"",""status"":null,""definition"":""tcp-client --decoder=LF --port=8080 | log"",""_links"":{""self"":{""href"":""http://localhost:9393/streams/dummy-firehose""}}}  {code}    The same curl command works fine against XD 1.0.1 release.  ",3
"Add Websocket sink
As a user, I should be able to leverage native _WebSocket_ sink so that I can take the advantage of full-duplex communications channels over a single TCP connection.",8
"EC2 CI build improvements
As a developer, I'd like to include the following improvements as part of the EC2 CI infrastructure, so that we can reliably run the CI builds and also assert over feature functionalities.    *Scope:*  * Enable 'distributed jvm test'  * Change from using artifactory gradle task to a command task (that calls ./gradlew)  * Test w/ embedded hadoop off  * Turn on maxParallelForks  ",5
"Investigate why builds have more WARN logs
As a developer, I'd like to investigate the increase in WARN logs so that I can troubleshoot and fix PMD/Sonar violations.  Consider notifying the violations through SONAR configurations. The committer should be notified.",3
"Spike: Study elastic instances and scheduling in Bamboo to create Windows CI infrastructure
As a build manager, I'd like to setup CI infrastructure so that I can run integration tests in Windows OS automatically as we commit-trigger new builds.     *Scope:*  * Use the environment where Bamboo is running  * Gain access to powershell   * Setup services (redis, rabbit, etc.)  * Kick-off CI task",5
"Provide an XD Starter POM for module projects
Provide A maven pom to support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for 'MODULE' layout and other boilerplate build configuration. This should include a similar feature for gradle.",3
"Provide XD module build plugins to upload a module 
Provide maven and gradle plugins to execute module upload via REST to upload and install a module to Spring XD.  e.g. mvn xd:upload-module ...  ",5
"Create Sample Module projects
Create one or more Sample module projects in the Spring XD Examples repo to serve as templates for Spring XD module projects. Similar to https://github.com/dturanski/siDslModule, these should include unit and single node integration tests, and demonstrate the use of Spring XD build and packaging tools, and other module development support. This may be split out into separate tasks, but should include a sample for source, processor, sink, and job, using @Configuration or XML configuration (either as separate samples or using build profiles). ",3
"Enhance ""module upload"" to support exploded dirs (on the shell side)
Would be nice to have the shell zip the contents of a directory if not already in zipped form. This way, the development cycle (if one decided to use upload) is quicker and edits can be done in place.",3
"When a tap is re-deployed after undeploy, it doesn't work
When a tap on a stream is undeployed and re-deployed, it stops working.  To make it work, the main stream associated with the tap needs to be undeployed and re-deployed.  ",1
"hdfs-dataset sink with getName() method in Pojo
Having a pojo:  {code}  public class User{  	private String name;  	public String getName() {  		return user;  	}  	public void setName(String name) {  		this.name = name;  	}  }  {code}    with:  {code}  hdfs-dataset --inputType='application/x-java-object;type=test.User'  {code}    throws exception:  {code}  12:43:27,698 1.1.0.SNAP ERROR task-scheduler-1 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: Expression evaluation failed: payload.getClass().getName(); nested exception is org.springframework.expression.AccessException: Problem invoking method: public java.lang.String test.User.getName()  {code}    Which I believe is caused by `correlation-strategy-expression` spel in aggregator:  {code}  	<int:aggregator  			input-channel=""input""  			correlation-strategy-expression=""payload.getClass().getName()""  			release-strategy-expression=""size() == ${batchSize}""  			expire-groups-upon-completion=""true""  			send-partial-result-on-expiry=""true""  			message-store=""messageStore""  			output-channel=""objects""/>  {code}    Changing `getName()` method in pojo to something else works.",1
"Rename metrics repositories setValue(x, y, z) to something less ""javabean""
nan",1
"Make Redis RichGauge repository ""cluster safe""
The current implementation makes individual reads from redis and then writes back the average, so in a cluster environment the reads and writes are not serialized, client reads and writes for specific keys can interfere with each other.  Investigate options, such as use of redis transactions or use of lua scripting to solve this problem.",5
"Fix Redis FieldValueCounter repo save() method
That method is actually currently never called, but :  - The case where a mapping already exists is not covered (outstanding TODO comment)  - the semantics of the method should just be to ""save and override""    ",2
"Rollover support in hdfs-datasink
hdfs-datasink should support rollover option, just like hdfs sink.  This might be mutually exclusive with batchSize option which also performs rollover.",5
"Incorrect ""directory"" option described in hdfs-dataset docs
Please see [hdfs-dataset 1.0.2.RELEASE docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.2.RELEASE/reference/html/#hdfs-dataset-avroparquet].    According to docs there should be ""directory"" option in this sink but in code ""basePath"" is used.",1
"Using custom classes for module properties leads to ClassNotFoundException
Attached is module properties file. Both custom Java classes referenced in the properties are available in the JAR file under _SPRING_XD_HOME/xd/module/<the-module>/lib_ directory.    Following exception is thrown:  {code}6:26:03,064 1.0.2.RELEASE ERROR http-nio-9393-exec-4 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Can't find class used for type of option 'binding': com.emc.it.ds.rtd.springxd.binding.BindingStrategy    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:137)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:193)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:154)    org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)    org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:173)    org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)    org.springframework.xd.dirt.rest.XDController.save(XDController.java:223)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.web.method.support.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:215)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:132)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:104)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:749)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:689)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:83)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:938)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:870)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:961)    org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:863)    javax.servlet.http.HttpServlet.service(HttpServlet.java:646)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:837)    javax.servlet.http.HttpServlet.service(HttpServlet.java:727)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:303)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:110)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:280)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)    org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:88)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:89)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:241)    org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:208)    org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:220)    org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:122)    org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:501)    org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:171)    org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:103)    org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:116)    org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:408)    org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:1070)    org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:611)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1736)    org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.run(NioEndpoint.java:1695)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)    java.lang.Thread.run(Thread.java:745){code}    Please see attached patch file, this seems to be enough to resolve the problem.  ",1
"SpelParseException is thrown when using empty string ("""") inside of an expression
I can only reproduce this when using single quotes around the expression:    {code}  stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \""\"")' | log"" --deploy true  {code}    The following two alternatives work fine though:  {code}  # Using trim on a single space  stream create test --definition ""http | transform --expression='payload.replace(\""abc\"", \"" \"".trim())' | log"" --deploy true    # Not using single quotes or spaces in the expression  stream create test --definition ""http | transform --expression=payload.replace(\""abc\"",\""\"") | log"" --deploy true  {code}",1
"tcp-client reports error when using --close=true flag
When using the --close=true flag for the tcp-client the following exception is triggered. Caused by: java.lang.IllegalArgumentException: For client-mode, connection factory must have single-use='false'   org.springframework.util.Assert.isTrue(Assert.java:65)   org.springframework.integration.ip.tcp.TcpReceivingChannelAdapter.onInit(TcpReceivingChannelAdapter.java:96)   org.springframework.integration.context.IntegrationObjectSupport.afterPropertiesSet(IntegrationObjectSupport.java:135)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1627)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1564)",1
"Kafka Sink: Support async Producer
The kafka sink supports properties for an async producer (e.g. {{queue.buffering.max.ms}} ) but you cannot enable such a producer (only {{sync}} ). Async producers batch messages (at the risk of message loss).    Add a new property {{async}} default {{false}} and add the corresponding attribute to the {{<int-kafka:producer-configuration/>}} element    {{async=""$\{async\}""}}",1
"'module delete' tab completion includes undeletable modules
See my comment on https://github.com/spring-projects/spring-xd/pull/1295 for details",3
"Add support for common dependent jars for modules
As a user, I'd like to have a common shared location so that I can place the dependent jar's that are required by 2 or more custom modules.   *Current Recommendation:* * Place the dependent jar under xd/lib folder * if it necessary to support different versions of jar's then bundle it in custom module to get around the _classloader_ problem, if a older/newer version exist in xd/lib",5
"UI: List of Streams causes ""undefined is not an option""
See Screenshot.    The error is caused when loading all stream definitions in method *loadStreamDefinitions*.     Only 1 or two streams exist in the system.   ",2
"UI Provide fixed version numbers for NPM and Bower dependencies
nan",1
"WireTap is Applied to OutputChannel Before the Tap Channel has been Bound To The Bus
When establishing the tap, we create the tap channel and add the WireTap before the tap channel has been bound to the bus.    {quote}  17:00:23,918 ERROR task-scheduler-8 handler.LoggingHandler - org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'tap:stream:foo.time.0.tap.bridge'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.interceptor.WireTap.preSend(WireTap.java:129)  {quote}",1
"Profile / Improve performance of TupleBuilder
See discussion at https://github.com/spring-projects/spring-xd/pull/1311    1) there seems to be unused SimpleDateFormat in TupleBuilder which hurst perf  2) More generally, should take some time to profile / micro-benchmark TupleBuilder",5
"SpringXD's syslog source does not fully support syslog RFC5424
SpringXD's syslog source cannot parse rfc5424 messages into a Map.  For the messages we get in RFC 3164, springXD converts these to a Map.    Since the rfc5424 data cannot be interpreted then the map contains just one key called 'UNDECODED'.  The result of this is that we get a string that looks like this (when we convert the message to a String)  {code}   {UNDECODED=<182>Dec 02 2014 07:56:35: %ASA-6-113008: AAA transaction status ACCEPT : user = jbloggs}  {code}    Should be something like this (note the values below are for illustrative purposes only and should not be used as test data)    {code}   {FACILITY=22, SEVERITY=6, TIMESTAMP=Tue Dec 02 07:56:35, HOST=the-hostname-that-sent-the-data, TAG=%ASA-6-113008, MESSAGE=........}  {code}    h3. Root Cause  Spring integration does not parse these messages. There is a JIRA for SI here:  https://jira.spring.io/browse/INT-3450  ",5
"Travis CI improvements
Travis CI recently introduced docker based builds.  This prevents root access (which we don't need), but allows caching (which we could not use before) and seems to come with beefier machine specs",2
"Use repo.spring.io as NPM repository
In order to improve the build reliability, we should be using the NPM repo provided by *repo.spring.io*     See *spring-xd-ui/README.md* for further details.",1
"Bind Producer Before Consumer
{quote}  		Here is the full exception:  		org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'ResourceConfiguredModule [name=filter, type=processor, group=request-rate, index=0 @58b0f318]:use-expression,default,admin,singlenode,hsqldbServer:9393.output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers  		and here is that stream:  		topic:httpstartstop > filter --expression=payload.getHttpStartStop().getPeerType().name().equals('Client') | requestRateAggregator | appMetricsSplitter | router --expression='topic:app-request-rate-'+#jsonPath(payload,'$.appId')  [2:59 PM] Gary Russell: @MarkFisher  @IlayaperumalGopinathan @PatrickPeralta  This looks like another (not fixed by the previous fix) timing problem with taps when using singlenode. The tap is started before the tap stream is deployed. But it's not clear to me how the filter module could be deployed/bound as a consumer before the requestRateAggregator  [3:08 PM] Gary Russell: I see the problem: AbstractMessageBusBinderPlugin.bindConsumerAndProducers() binds the consumer before the producer - this is the wrong order for a passive component such as the filter. /cc @DavidTuranski  {quote}",1
"Create a Sqoop job and required batch tasklet integration code
Based on the POC from XD-2124 we should create the actual implementation.    Things to consider to store in step context:  - capture Log output/MapReduce job counters  - capture last-value from incremental imports  ",8
"Workaround latest boot snapshot issue
* The workaround explicitly updates spring-core (latest boot needs it)  * merges all application.yml documents that are not profile-specific under on spring: key (the latest boot requires it, at least for now. Boot may go back, see spring-projects/spring-boot#2022",3
"Define developer-facing interfaces for Spark Streaming modules
nan",3
"Implement a Spark Streaming Receiver that binds to the MessageBus
nan",8
"Acceptance test for Mail source
As a QA, I'd like to include acceptance test coverage for _Mail_ source module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for reactor-ip
As a QA, I'd like to include acceptance test coverage for _reactor-ip_ source module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for reactor-syslog
As a QA, I'd like to include acceptance test coverage for _reactor-syslog_ source module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for SFTP
As a QA, I'd like to include acceptance test coverage for _SFTP_ source module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""aggregator""
As a QA, I'd like to include acceptance test coverage for _aggregator_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for analytic-pmml
As a QA, I'd like to include acceptance test coverage for _analytic-pmml_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""bridge""
As a QA, I'd like to include acceptance test coverage for _bridge_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for http-client
As a QA, I'd like to include acceptance test coverage for _http-client_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for json-tuple
As a QA, I'd like to include acceptance test coverage for _json-tuple_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for script(s)
As a QA, I'd like to include acceptance test coverage for both _script_ and _scripts_ processor modules so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for Splitter
As a QA, I'd like to include acceptance test coverage for _splitter_ processor module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""gauge""
As a QA, I'd like to include acceptance test coverage for _gauge_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""aggregate-counter""
As a QA, I'd like to include acceptance test coverage for _aggregate-counter_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for field-value-counter
As a QA, I'd like to include acceptance test coverage for _field-value-counter_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for hdfs-dataset
As a QA, I'd like to include acceptance test coverage for _hdfs-dataset_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""mail"" sink
As a QA, I'd like to include acceptance test coverage for _mail_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""null"" sink
As a QA, I'd like to include acceptance test coverage for _null_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""rich-gauge""
As a QA, I'd like to include acceptance test coverage for _rich_gauge_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""router""
As a QA, I'd like to include acceptance test coverage for _router_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""shell""
As a QA, I'd like to include acceptance test coverage for _shell_ sink module so that I can validate the functionality as part of every CI build. ",5
"Acceptance test for ""splunk""
As a QA, I'd like to include acceptance test coverage for _splunk_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""throughput-sampler""
As a QA, I'd like to include acceptance test coverage for _throughput-sampler_ sink module so that I can validate the functionality as part of every CI build. ",3
"Acceptance test for ""spark-app"" batch job
As a QA, I'd like to include acceptance test coverage for _spark-app_ batch job so that I can validate the functionality as part of every CI build. ",5
"Acceptance test for ""timestampfie"" batch job
As a QA, I'd like to include acceptance test coverage for _timestampfile_ batch job so that I can validate the functionality as part of every CI build. ",3
"Update Base AMI to be a HVM
nan",3
"Update XD-EC2 to use placement groups
nan",3
"Update to use Compute optimized and standard machine types
nan",3
"Make XD-EC2 Bootiful
nan",3
"Acceptance test for Kafka as a message bus
As a QA, I'd like to include acceptance test coverage for _Kafka_ as a message bus so that I can validate the functionality as part of every CI build.",5
"Test with Java8 runtime
nan",3
"Implement an XD module type that integrates with Spark Streaming, reactor etc.,
nan",8
"Implement a dirt plugin for Spark Streaming support
nan",5
"Implement a Spark Streaming Driver application that can be controlled as an XD module instance
This should include lifecycle management, so that when the module's stream is undeployed, the Spark Streaming application should be stopped, etc.    Deploying a number of module instances should result in multiple receiver tasks, and those should bind to the bus using the consumer side partitioning metadata.  ",8
"Kafka Profiling for Base & Distributed base benchmarks
nan",5
"Parent Modules
Thinking about the UBS(?) scenario that MP described. They want all their Cassandra modules to share a connection, leading to the need for a parent context for those modules. We could introduce a parent module for this purpose. The module declares a parent in its properties which likely ends up as a parent module definition in the module definition. When the child module is deployed, its parent must be deployed first if it is not already (i.e., parent is a singleton per container). The module sets that as it's parent context.  We would have to make sure things happen in the correct order so the global context is the parent of the parent (ad infinitum). The alternative is to add a module parent context to the XD hierarchy which is extensible, but this is more elegant IMHO.  Also, in cases that don't require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module's classloader as the parent classloader, eliminating the need to install common jars in an HDFS path (basically the approach I described https://jira.spring.io/browse/XD-2420)   MP : >> Also, in cases that don't require singleton bean definitions, the parent could package and provide common jars to children, e.g., we set the parent module's classloader as the parent classloader This approach does not offer some of the advantages offered by a central yaml config noted in the JIRA . But it is simpler in many ways. The developer just installs a parent module containing dependent jars and sets that as a parent in the child modules. This requires no additional infrastructure. To address the hadoop scenario we discussed, we would need another level of indirection so the parent of the hdfs modules is bound to the configured hadoop distro.   e.g. something like  parent = ${xd.hadoop.distro} in module properties  MF: Possibly the parent modules could go in the ""common"" directory? They should be considered ""abstract"" also - in the same sense as abstract bean definitions in a Spring context (and they should only be started on demand when needed by at least one concrete child module - then destroyed when the last child module is destroyed).  Maybe this would also allow us to wrap up those xml files that currently live in ""common"" so that they are treated as parent modules?  MF: Yea, that sounds good wrt to common.  Also it might be a good idea to enable spring to throw an error if it finds more than one bean of the same name in the application context - i think that applies to searching in parent contexts as well.  this would avoid the 'last one wins' rule and give more deterministic behavior. ",8
"Identify scenario where XD JDBC based jobs fail to connect to DB
During an integration test over the weekend the cluster based tests failed.  They showed that a job was left in an inconsistent state (incomplete)   and other jdbc job tests failed because they could not connect to the database.    ",3
"Kafka Bus: Concurrency and compression support
As a user, I'd like to have concurrency and compression support for Kafka so that I can increase performance throughput and/or increase responsiveness    *Things to consider:*  * make global configuration options be ""defaults"" and allow per-deployment overrides  * add options for   ** concurrency  ** compression support",3
"Kafka Bus: Add support for ACK mode
As a user, I'd like to have the option to _ACK_ messages so that I can guarantee that the message/request sent is successful. ",3
"Add support for bindRequestor and bindReplier
As a user, I'd like to have the option to implement _bindRequestor_ and _bindReplier_ so that I can ""bind a producer that expects async replies"" and ""bind a consumer that handles requests from a requestor and asynchronously sends replies"" respectively.     ",3
"Add batching support to Spring AMQP/Rabbit
As a user, I'd like to have the option to setup _batching_ so that I can ingest data in batches as opposed to payload-at-a-time.",8
"Add support to stop existing Sqoop jobs
As a user, I'd like to have the option to _stop_ an existing Sqoop job so that I can clean-up resources at the time of completion.",8
"Add support to access Sqoop logs
As a user, I'd like to access Sqoop logs so that I can troubleshoot or evaluate the errors or current state respectively.   We will have to identify how to capture the Sqoop logs and stream them to our logging mechanism.",5
"Add METADATA store for incremental-load
As a user, I'd like to incremental-data-load so that I can retrieve only rows newer than some previously-imported.",5
"Benchmark: Sqoop vs. jdbchdfs
As a QA, I'd like to benchmark _Sqoop_ vs. _jdbchdfs_ batch job so that I can compare and contrast performance stats. ",5
"Define developer facing interfaces for Reactor Stream processors
What is the core interface contract users will be exposed to when creating a processor module that uses Reactor's Stream API.   Some consideration for error handling should be considered as it maybe outside normal exception throwing signatures.",2
"Add ""initialDelay"" to ""source:trigger""
Currently, the {{source:trigger}} module is based on 3 profiles: {{date}}, {{cron}} or {{fixedDelay}}, where the latter has precedence over the former in {{TriggerSourceOptionsMetadata}}:    {code:java}  @Override  public String[] profilesToActivate() {      if (cron != null) {          return new String[] { ""use-cron"" };      }      else if (fixedDelay != null) {          return new String[] { ""use-delay"" };      }      else {          return new String[] { ""use-date"" };      }  }  {code}    Therefore it is not possible to combine {{date}} and {{fixedDelay}} to start off at a specific point in time, and then repeat every X seconds.    This is a request to provide another parameter to {{source:trigger}} such as *{{initialDelay}}* to be able to achieve the desired behaviour.",1
"Add codec option to hdfs-dataset sink
As a user, I would like to be able disable snappy compression when using hdfs-dataset sink with Avro files. I'd also like to be able to provide a different codec.",1
"Update spring-data-hadoop version to 2.1.0.M3
nan",1
"Update spring-data-hadoop version to 2.0.4 for XD 1.0.3
nan",1
"Context Deserialize Doesn't Use Parent First Classloader
If a class is added to a batch execution context that is located in an isolated context, an exception will be thrown when that object is deserialized.  It appears the serialize doesn't use the ParentFirstClassloader during deserialization.",8
"Create ReactorMessageHandler for Reactor based XD processor/sink modules
The module should be flexible to act as a sink as well as a processor.  ErrorHandling will be considered as part of another JIRA",5
"Create sample module in spring-xd-modules for a Reactor Stream processor
A sample, perhaps taken from Pivotal Labs use-case in Denver, that would calculate some time window averages for a many individual senor values .",3
"Reference documentation on creating Reactive Stream processor/sink
nan",3
"Update Reactor Stream processor to use latest snapshots
The code base is changing a bit, so using 2.0 M1 for development is stable up until all major JIRA issues have bee completed.  Then we should track snapshots in preparation to move to 2.0. M2 when it gets released.",2
"JDBCHDFS Master Process Timeout error
The JDBCHDFS Master process fails with a timeout error while the child process is still processing data.  The error message on the error message on the master process is:  org.springframework.integration.MessageTimeoutException: Timeout occurred before all partitions returned   org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:141)   org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)   org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)   org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)   org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)   org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)   org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:162)   org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:141)   org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)   org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)   org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.batch.core.configuration.annotation.SimpleBatchConfiguration$PassthruAdvice.invoke(SimpleBatchConfiguration.java:127)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy47.run(Unknown Source)   org.springframework.batch.integration.launch.JobLaunchingMessageHandler.launch(JobLaunchingMessageHandler.java:50)   sun.reflect.NativeMethodAccessorImpl",3
"Increase Exit Description Text field on Job Execution Process step page
The Step Execution Process (http://localhost:9393/admin-ui/#/jobs/executions/38/52) page should list more lines of text for 'Exit Description' field to make sense of error messages.    *Scope:*  Investigate how much information can be collected directly from the ExecutionContext. It may be dependent on the error types. Let's have the observation documented to decide next steps.   ",2
"No support for Amazon s3 source module in xpring xd
There is no support for Amazon s3 source module in spring xd. Spring Integration for s3 as custom source module is also not working gracefully. ",1
"Make trigger options explicitly exclusive
see problem reported at http://stackoverflow.com/questions/27368351/spring-xd-module-sourcetrigger-does-not-work-as-expected  ",1
"Add Request/Reply support to Kafka message bus
* Environment: ** Can be reproduced on local machine with Admin and a single container. * create the following job ** job create ogg --definition ""filejdbc --resources=file:filejdbctest//filejdbctestpartition* --names=data --tableName=filejdbctest --initializeDatabase=true "" --deploy * note: this works on Rabbit and Redis as a message bus * The following exception is thrown on the admin: 6:54:22,856 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.JobDeploymentListener - Deployment status for job 'ogg': DeploymentStatus{state=failed,error(s)=java.lang.UnsupportedOperationException: Auto-generated method stub   org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)   org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) }  * The following exception is thrown on the container 21:08:14,721 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 config.ReleaseStrategyFactoryBean - No annotated method found; falling back to SequenceSizeReleaseStrategy, target:org.springframework.batch.integration.partition.MessageChannelPartitionHandler@692ee39f, methodName:null 21:08:15,946 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module java.lang.UnsupportedOperationException: Auto-generated method stub   org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindRequestor(KafkaMessageBus.java:289)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.processPartitionedJob(JobPartitionerPlugin.java:69)   org.springframework.xd.dirt.plugins.job.JobPartitionerPlugin.postProcessModule(JobPartitionerPlugin.java:53)   org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployJobModule(DeploymentListener.java:289)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745)",3
"Refactor use of getContainerHostForSource in integration tests
Some cleanup to make the tests a bit easer to read.",1
"Investigate lack of falling back to origin/master when building docs on a branch
When building on a branch, the docs should be defaulting to build from origin/master, but that doesn't seem to be happening.  Instead an explicit -Pwikibranch=origin/master is required to be specified on the command line.    ",2
"Add imap/smtp properties to Mail sink
As a user, I'd like to use the _Mail_ sink to connect to secured IMAP and/or SMTP mail servers. Currently, the sink doesn't support TLS.    _Mail_ sink config file requires a <util:properties/> bean (with ssl/tls properties), provided to the adapter via the java-mail-properties attribute. [Ref. Example|http://docs.spring.io/spring-integration/docs/latest-ga/reference/html/mail.html].    {code:xml}  <util:properties id=""javaMailProperties"">    <prop key=""mail.imap.socketFactory.class"">javax.net.ssl.SSLSocketFactory</prop>    <prop key=""mail.imap.socketFactory.fallback"">false</prop>    <prop key=""mail.store.protocol"">imaps</prop>    <prop key=""mail.debug"">false</prop>  </util:properties>  {code}    [List of all java-mail properties|https://javamail.java.net/nonav/docs/api/com/sun/mail/smtp/package-summary.html]",1
"Document 'partitionResultsTimeout' metadata attribute
As a user, I'd like to use _partitionResultsTimeout_ attribute for jobs that inherit singlestep-partitioning strategy but it is not exposed as a metadata attribute in the wiki.     *Note:*  The property should be available for all the jobs that import; 3 OOTB jobs have it imported (ref. attachment)",1
"Upgrade to Boot 1.2.0 RELEASE and the dependencies
As a XD Admin, I'd like to upgrade to Spring Boot 1.2.0 RELEASE and the associated dependencies so that we can catch up with the latest features, bug-fixes and enhancements.     *Following XD dependencies needs upgraded to sync-up with Boot 1.2.0 RELEASE:*    <activemq.version>5.10.0</activemq.version>  <aspectj.version>1.8.4</aspectj.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <h2.version>1.4.182</h2.version>  <hibernate.version>dd4.3.7.Final</hibernate.version>  <hibernate-validator.version>5.1.3.Final</hibernate-validator.version>  <hikaricp.version>2.2.5</hikaricp.version>  <hornetq.version>2.4.5.Final</hornetq.version>  <httpasyncclient.version>4.0.2</httpasyncclient.version>  <httpclient.version>4.3.6</httpclient.version>  <jackson.version>2.4.4</jackson.version>  <janino.version>2.6.1</janino.version>  <jetty.version>9.2.4.v20141103</jetty.version>  <jetty-jsp.version>2.2.0.v201112011158</jetty-jsp.version>  <joda-time.version>2.5</joda-time.version>  <jolokia.version>1.2.3</jolokia.version>  <junit.version>4.12</junit.version>  <liquibase.version>3.3.0</liquibase.version>  <log4j.version>1.2.17</log4j.version>  <log4j2.version>2.1</log4j2.version>  <mockito.version>1.10.8</mockito.version>  <mongodb.version>2.12.4</mongodb.version>  <mysql.version>5.1.34</mysql.version>  <reactor.version>1.1.5.RELEASE</reactor.version>  <reactor-spring.version>1.1.3.RELEASE</reactor-spring.version>  <servlet-api.version>3.1.0</servlet-api.version>  <spring.version>4.1.3.RELEASE</spring.version>  <spring-batch.version>3.0.2.RELEASE</spring-batch.version>  <spring-data-releasetrain.version>Evans-SR1</spring-data-releasetrain.version>  <spring-hateoas.version>0.16.0.RELEASE</spring-hateoas.version>  <spring-mobile.version>1.1.3.RELEASE</spring-mobile.version>  <spring-security.version>3.2.5.RELEASE</spring-security.version>  <tomcat.version>8.0.15</tomcat.version>  <undertow.version>1.1.1.Final</undertow.version>",5
"KafkaSourceSinkTests to use embedded Kafka server
Test is failing since Kafka isn't installed on the CI server.  Using an embedded server will make the testing more robust vs. needing an external server.",2
"RabbitMQ Message bus, RabbitMQ Source/Sinks are throwing exceptions
I believe it is being cause by the following PR:  XD-2381: Split MessageBus and Analytics dependencies from DIRT  PR:  1307  SHA: 8d28b2786acbdea1617d7e903b805e5af5369b90    *RabbitMQ Sink is throwing:*  {noformat}  09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  	... 30 more  09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)    com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)    com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)    com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)    com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)    com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)    com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)    com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)    com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)    com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)    com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)    org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)    org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  {noformat}  *Rabbit Message Bus is throwing:*  {noformat}  10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader    org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)    org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)    org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)    org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)    org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)    org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)    org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)    org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader    java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)    java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)    java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)    java.lang.reflect.WeakCache.get(WeakCache.java:141)    java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)    java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)    org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)    org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)    org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)    org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)    org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)    org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)  	... 28 more  {noformat}",3
"Upgrade CI Acceptance AMI to HVM
Replace the current paravirtual AMI used for CI tests needed to be replaced with a HVM based AMI  Paravirtual is being phased out by Amazon.  Also so we can utilize VPC and placement groups in the future.  ",5
"Undeploying HDFS module closes filesystem
When using the hadoop namespace to create a hadoop configuration and filesystem, the FileSystemFactoryBean uses Hadoop FileSystem.get and not newInstance which will return a FileSystem from the cache.  When undeploying the module, the FileSystemFactoryBean destroy method will close the FileSystem which closes for all other deployed Hadoop modules throwing a java.io.IOException: Filesystem closed",3
"""script"" processor options incorrect on docs
The EXAMPLE in the documentation (and the paragraph preceding the example) for the ""script"" processor uses both ""location"" and ""properties-location"" options, but these are in actuality ""script"" and ""locationProperties"" according to ""module info processor:script"" and the text of the documentation.  See: http://docs.spring.io/spring-xd/docs/1.0.2.RELEASE/reference/html/#script   {quote}To use the module, pass the location of a Groovy script using the location attribute. If you want to pass variable values to your script, you can optionally pass the path to a properties file using the properties-location attribute. All properties in the file will be made available to the script as variables.  {code}xd:> stream create --name groovyprocessortest --definition ""http --port=9006 | script --location=custom-processor.groovy --properties-location=custom-processor.properties | log"" --deploy{code} {quote}",1
"REST endpoints XML response is broken
When XML response is requested from the REST clients, the server has XML serialization errors.  For example: the endpoint  /jobs/configurations from the web browser has: nested exception is javax.xml.bind.MarshalException - with linked exception: [com.sun.istack.SAXException2: unable to marshal type ""org.springframework.xd.rest.domain.DetailedJobInfoResource"" as an element because it is not known to this context.]",5
"MQTT: Support the New Spring Integration 4.1 Features
HA Configuration, async sends.    http://docs.spring.io/spring-integration/reference/html/whats-new.html#4.1-mqtt",3
"Solve CP issues for the Rabbit MessageBus
Rabbit Message Bus is throwing:    {quote}  10:14:04,678 1.1.0.SNAP  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'foo': DeploymentStatus{state=failed,error(s)=org.springframework.amqp.UncategorizedAmqpException: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader      at org.springframework.amqp.rabbit.support.RabbitExceptionTranslator.convertRabbitAccessException(RabbitExceptionTranslator.java:66)      at org.springframework.amqp.rabbit.connection.RabbitAccessor.convertRabbitAccessException(RabbitAccessor.java:110)      at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:426)      at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.afterPropertiesSet(AbstractMessageListenerContainer.java:385)      at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.doRegisterConsumer(RabbitMessageBus.java:367)      at org.springframework.xd.dirt.integration.rabbit.RabbitMessageBus.bindConsumer(RabbitMessageBus.java:308)      at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:183)      at org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:138)      at org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)      at org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)      at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)      at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)      at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)      at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)      at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)      at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)      at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)      at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)      at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)      at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)      at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  Caused by: java.lang.IllegalArgumentException: interface org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer$ContainerDelegate is not visible from class loader      at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:616)      at java.lang.reflect.Proxy$ProxyClassFactory.apply(Proxy.java:592)      at java.lang.reflect.WeakCache$Factory.get(WeakCache.java:244)      at java.lang.reflect.WeakCache.get(WeakCache.java:141)      at java.lang.reflect.Proxy.getProxyClass0(Proxy.java:455)      at java.lang.reflect.Proxy.newProxyInstance(Proxy.java:738)      at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:121)      at org.springframework.aop.framework.JdkDynamicAopProxy.getProxy(JdkDynamicAopProxy.java:111)      at org.springframework.aop.framework.ProxyFactory.getProxy(ProxyFactory.java:96)      at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.initializeProxy(SimpleMessageListenerContainer.java:586)      at org.springframework.amqp.rabbit.listener.SimpleMessageListenerContainer.doInitialize(SimpleMessageListenerContainer.java:612)      at org.springframework.amqp.rabbit.listener.AbstractMessageListenerContainer.initialize(AbstractMessageListenerContainer.java:424)      ... 28 more  {quote}",2
"Fix classpath issues for RabbitMQ source/sink
RabbitMQ Sink is throwing:  {quote}  09:44:16,031 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)      at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)      at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)      at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)      at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)      at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)      at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)      at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)      at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)      at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)      at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)      at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)      at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)      at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)      at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)      at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)      at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)      at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)      at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)      at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)      ... 30 more  09:44:16,036 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  org.springframework.beans.factory.xml.XmlBeanDefinitionStoreException: Line 19 in XML document from class path resource [config/rabbit.xml] is invalid; nested exception is org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:399)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:336)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:180)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)      at org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)      at org.springframework.boot.SpringApplication.load(SpringApplication.java:620)      at org.springframework.boot.SpringApplication.run(SpringApplication.java:315)      at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)      at org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)      at org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)      at org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)      at org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)      at org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)      at org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)      at org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)      at org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)      at com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)      at org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)      at org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)      at org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)      at org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)      at java.util.concurrent.FutureTask.run(FutureTask.java:262)      at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)      at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)      at java.lang.Thread.run(Thread.java:745)  Caused by: org.xml.sax.SAXParseException; lineNumber: 19; columnNumber: 53; cvc-complex-type.3.2.2: Attribute 'default-delivery-mode' is not allowed to appear in element 'int-amqp:outbound-channel-adapter'.      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.createSAXParseException(ErrorHandlerWrapper.java:198)      at com.sun.org.apache.xerces.internal.util.ErrorHandlerWrapper.error(ErrorHandlerWrapper.java:134)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:437)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:368)      at com.sun.org.apache.xerces.internal.impl.XMLErrorReporter.reportError(XMLErrorReporter.java:325)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator$XSIErrorReporter.reportError(XMLSchemaValidator.java:458)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.reportSchemaError(XMLSchemaValidator.java:3237)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.processAttributes(XMLSchemaValidator.java:2714)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.handleStartElement(XMLSchemaValidator.java:2056)      at com.sun.org.apache.xerces.internal.impl.xs.XMLSchemaValidator.emptyElement(XMLSchemaValidator.java:766)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.scanStartElement(XMLNSDocumentScannerImpl.java:356)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl$FragmentContentDriver.next(XMLDocumentFragmentScannerImpl.java:2786)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentScannerImpl.next(XMLDocumentScannerImpl.java:606)      at com.sun.org.apache.xerces.internal.impl.XMLNSDocumentScannerImpl.next(XMLNSDocumentScannerImpl.java:117)      at com.sun.org.apache.xerces.internal.impl.XMLDocumentFragmentScannerImpl.scanDocument(XMLDocumentFragmentScannerImpl.java:510)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:848)      at com.sun.org.apache.xerces.internal.parsers.XML11Configuration.parse(XML11Configuration.java:777)      at com.sun.org.apache.xerces.internal.parsers.XMLParser.parse(XMLParser.java:141)      at com.sun.org.apache.xerces.internal.parsers.DOMParser.parse(DOMParser.java:243)      at com.sun.org.apache.xerces.internal.jaxp.DocumentBuilderImpl.parse(DocumentBuilderImpl.java:347)      at org.springframework.beans.factory.xml.DefaultDocumentLoader.loadDocument(DefaultDocumentLoader.java:76)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadDocument(XmlBeanDefinitionReader.java:429)      at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.doLoadBeanDefinitions(XmlBeanDefinitionReader.java:391)  {quote}",1
"New YML file as deployment manifest
As a user, I'd like to have a separate _YML_ file to list the deployment manifest properties so that I don't have to include as part of the stream definition. ",8
"Byte[] to String conversion should support application/json 
See http://stackoverflow.com/questions/27491237/spring-xd-tcp-source-outputs-byte-array-instead-of-string-how-to-output-regu.   Same behavior as --outputType text/plain but more intuitive to use application/json if the stream author expects the source to emit json. No content validation will be done.   ",2
"Add support for message compression
As a user, I'd like to have the option to _compress_ messages so that I can influence the performance throughput. It'd be beneficial to have support for gzip, zip compression, and decompression.",3
"Add compression support for Rabbit source/sink
As a user, I'd like to have the option of _compression_ for both Rabbit _source_ and _sink_ modules so that can further enhance the performance characteristics.",8
"Add batching support for Rabbit sink
As a user, I'd like to have the option of _batching_ for the Rabbit _sink_ so that I can write data in batches as opposed to one-at-a-time. ",5
"spring_rabbitmq_addresses environment variable is ignored
When trying to configure XD to use a RabbitMQ instance other than the default localhost:5672, a user is supposedto updated the ""spring_rabbitmq_addresses"" environment variable or the spring.rabbitmq.addresses setting in the servers.yml file.  In this case XD is ignoring this environment variable.      h3. Steps to reproduce     # set the transport by using ""export XD_TRANSPORT=rabbit""  # set the spring_rabbitmq_addresses by ""export spring_rabbitmq_addresses=foo:5672""  # Startup a admin container on your local machine  # deploy ticktock  #* this should fail  #* start up a local rabbitmq  #* deploy a new ticktock and stream will deploy.    ",3
"Clean up spring-xd-batch sub-project
We should move the org.springframework.xd.batch.jdbc.ColumnRangePartitioner and org.springframework.xd.batch.item.jdbc.FieldSetSqlParameterSourceProvider to the spring-xd-extension-batch project",3
"Upgrade to Gradle 2.2
nan",2
"Refactor Spark and Sqoop tasklets to use SystemCommandTasklet
The Sqoop tasklet introduced an AbstractProcessBuilderTasklet implementation in XD-2430. We are now adding similar support to Batch SystemCommandTasklet in BATCH-2329, BATCH-2330 and BATCH-2331. We should refactor Sqoop and Spark tasklets to use the SystemCommandTasklet as base.",3
"Add integration tests for Sqoop job
We need to add some integration tests for the Sqoop job introduced in XD-2430",5
"Add options for supporting compression on the message bus with RabbitMQ
https://jira.spring.io/browse/AMQP-453 Added support for compression with RabbitMQ.  XD should expose configuration options to enable and configure compression on the message bus.  Note, some options may be specific for brokers or require additional functionality in XD.      This issue should not address adding additional functionality to make the feature set as common as possible across msg bus implementations, but expose what makes sense with the current code base for rabbitmq   As an example, Kafka supports compressed.topics which lets you pick a subset of topics to be compressed.  ",2
"Further decouple message bus deps (test scope)
Commit https://github.com/spring-projects/spring-xd/commit/8d28b2786acbdea1617d7e903b805e5af5369b90 removed MessageBus implementations from the main dirt classpath, but used a trick to have tests working (basically, MB classes *are* on the CP when in test scope).  This story is about adding more gradle projects that support classpath isolation when running tests (and also when authoring a MB implementation).  This would avoid false positives such as https://github.com/spring-projects/spring-xd/pull/1340 were lacking jars go unnoticed",8
"Add gradle build support for custom module projects
As a user, I'd like to have a gradle build option so that I can support module projects that will declare the Spring XD dependencies as provided, configure the boot plugin for 'MODULE' layout and other boilerplate build configuration.    This is dependent on Boot's module layout scoping issue: https://github.com/spring-projects/spring-boot/issues/2187",3
"Update deprecated jackson methods in TupleToJsonStringConverter
warning: [options] bootstrap class path not set in conjunction with -source 1.6  /home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:53: warning: [deprecation] put(String,JsonNode) in ObjectNode has been deprecated  					root.put(name, toObjectNode((Tuple) value));  					    ^  /home/dturanski/spring-xd/spring-xd-tuple/src/main/java/org/springframework/xd/tuple/TupleToJsonStringConverter.java:57: warning: [deprecation] put(String,JsonNode) in ObjectNode has been deprecated  					root.put(name, root.pojoNode(value));",1
"In XD shell an incomplete command will be executed as the full command
When using the XD shell a user can enter the first character of a command and it will be accepted as the full command.  for example  e <return/>  will exit the shell The following commands below show how a user can target a new cluster and then get a job execution list by using the first character of the command.  server-unknown:>a c s http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 Successfully targeted http://ec2-54-90-166-140.compute-1.amazonaws.com:9393 xd:>j e l   Id  Job Name                                   Start Time               Step Execution Count  Execution Status  Deployment Status  Definition Status   --  -----------------------------------------  -----------------------  --------------------  ----------------  -----------------  -----------------   28  tsle2145f21d-5b0b-49df-b9cc-a3fe65c49ecc   2014-12-18 11:08:47,000  2                     COMPLETED         Undeployed         Destroyed   27  ec2Job3                                    2014-12-18 11:07:13,000  2                     COMPLETED         Undeployed         Destroyed   26  ec2Job3",2
"Create Acceptance Test for hdfs-dataset
As a QA, I'd like to include acceptance test coverage for hdfs-dataset module so that I can validate the functionality as part of every CI build.",3
"Add support to extend message compression 
As a user, I'd like to have the option to extend compression support so that I can override the defaults and customize as needed.  Follow-up from this PR: https://github.com/spring-projects/spring-xd/pull/1346",3
"Document Sqoop job
As a user, I'd like to refer to the documentation so that I can connect to Sqoop as recommended and create job definition based on the exposed _metadata_ options. ",1
"Spark Application Job fails when using remote Spark Master
When executing a Spark Application Job on XD against a remote Spark Master we receive a CNF exception for FSDataInputStream.  Running against a local[1] Spark Master works normally.  ",5
"Upgrade to Reactor 2.0 M2
nan",1
"Re-run baseline benchmarks with payload batching enabled
As a performance tester, I'd like to rerun baseline benchmarks with batching enabled on Rabbit so that I can compare the results with previous performance snapshots.   Note: - batchingEnabled = true - batchingSize = 100 (default)  We could also vary default size to compute and record at granular level. ",3
"Re-run baseline benchmarks with payload compression enabled
As a performance tester, I'd like to re-run baseline benchmarks with compression enabled on Rabbit so that I can compare the results with previous performance snapshots. ",3
"Provide IP binding to the spring-xd instance.
We wanted to bind the spring-xd to the public IP but am not able to do so.  I scanned at the code here and could make there is not way to bind the IP address  https://github.com/spring-projects/spring-xd/blob/master/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server/AdminServerApplication.java   This one looks a simple change, I can fix it and push the pull request.",1
"BackPort script.xml Bug Fix
An additional commit (https://github.com/spring-projects/spring-xd/commit/db1f585) for XD-2230 was applied only to master; it needs to be backported to 1.0.x.  {{s/$\{location\}/$\{script\}/}}   https://gopivotal-com.socialcast.com/messages/22909482",1
"Make DB an optional peripheral for DIRT
As a user, I'd like to have an option to disable DB requirement so that I can setup to use DIRT runtime when stream processing is the only requirement.",8
"XD 1.1.0.M2 Won't Run on Windows
See http://stackoverflow.com/questions/27725905/spring-xd-1-1-0-m2-fails-to-start    With {{XD_HOME}} set with back-whacks, it fails on {{\U...}} with {{XD_HOME}} set with whacks, it fails with {{/xd\...}}. The StackOverflow failure is similar.    1.0.3 works fine.    {noformat}  set XD_HOME=C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd    Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 5  .*C:\Users\gpr\Documents\spring-xd-1.1.0.M2-dist\spring-xd-1.1.0.M2\xd\lib\messagebus\([^/]*).*    set XD_HOME=C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd      Caused by: java.util.regex.PatternSyntaxException: Illegal/unsupported escape sequence near index 71  .*C:/Users/gpr/Documents/spring-xd-1.1.0.M2-dist/spring-xd-1.1.0.M2/xd\lib\messagebus\([^/]*).*  {noformat}",5
"Define developer facing interfaces for RxJava processors
As a user, I'd like to implement the core interface contract so that I can create a processor module that uses RxJava API.",1
"Create MessageHandler for RxJava based processor modules
As a user, I'd like to have a flexible RxJava module so that it can as a processor.   ",8
"Research approach to define and administer Access Control List (ACL)
As a user, I'd like to have the option to define access control list (ACLs) so that I can define access controls to the resource by 'each user', and what the privileges are for that 'resource'.    *Spike Scope:*  ** Review customer use cases and come up with design specs  ** Identify the best approach that fits XD runtime  ** Identify scope for DSL and UI   ** Document next steps and phases  ",8
"Create a loadGenerator source module
Create a load-generator source module that  will generate messages and dispatch messages to a XD stream.      ",5
"Create a PerfSink Module
Create a Sink that can capture the results of the messages sent and log the number of messages received per a configured interval in seconds.",2
"Create AMI for Spark Server installed
nan",2
"Accept any file name for top level module resources
Expecting <module-name> in module configuration is brittle, especially in conjunction with module upload command which permits the module to be registered under a different name.  The convention should be dropped in favor of any file name. This requires at most one foo.xml, foo.groovy, and/or foo.properties in the top level config folder. It is an exception if multiples are found.   Accepting any file name provides the most flexibility without sacrificing backward compatibility (except in rare cases in which a module developer may have violated the multiple xml or properties files condition). An alternate approach requiring a well known file name such as 'spring-module' were rejected over concerns that it would break any existing custom module implementations.",3
"Investigate why CPU startup is high for admin and container servers
As a performance tester, I'd like to investigate why there's high CPU startup time for both admin and container servers. Perhaps profiling would assist isolating the bottlenecks.     *Scope:*  * Identify the bottlenecks  * Document reasons  * List pros/cons",8
"Upgrade to SI-Kafka Extension release
We would want to upgrade SI Kafka extension dependency to inherit the refactoring work with Kafka simple consumer API.",1
"Add support to upload custom module artifact to HDFS
As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",3
"Add support to read custom module artifact from HDFS
As a user, I'd like to have the option to store the custom module uber-jar in HDFS so that I can rely on the HA feature to reliably read and reinstall under failure scenarios. ",3
"Add support to override CF Configs specific to custom module location in HDFS
As a CF user, I'd like to have the ability to override the HDFS location so that I can change where the custom module _uber-jar_ can be stored and retrieved. ",3
"Add support to read/write custom modules in YARN
As a CF user, I'd like to have the ability to override the YARN config location so that I can change where the custom module _uber-jar_ can be stored and retrieved. ",3
"Add support to stop existing Spark job
As a user, I'd like to have the option to stop an existing Spark job so that I can clean-up resources at the time of completion. ",3
"Create plugin module for reactor based processors
As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava.  A plugin should allow a reactor processor module to specify the bare minimum to work, e.g. the processor class.    Explore how additional configuration can be achieved with well known module option commands.    ",2
"Reference documentation on RxJava Stream processor
nan",1
"Upgrade to Reactor 2.0 RC1
As a developer, I'd like to upgrade to Reactor 2.0 RC1 release so that we can synchronize with stable dependencies.",5
"Fix test failures and hangs on various local builds
The scope is to use this as a bucket for any local test failures. Let's have them accounted in this story and fix as applicable. ",5
"Add Redis based Aggregate Field Value Counters
As a user, I'd like to have a Redis based _aggregation_ over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.    *Scope:*  * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters].  * Identify gaps  * Update reference documentation ",3
"Add in-memory based Aggregate Field Value Counters
As a user, I'd like to have a Redis based aggregation over field-value counters so that I can continuously write the aggregation in Redis as we ingest more data.  *Scope:* * Port specs from [previous implementation|https://github.com/spring-projects/spring-xd/wiki/OLD---Aggregate-Field-Value-Counters]. * Identify gaps * Update reference documentation",3
"Document minimum memory requirement for Gradle builds
The build failed on two classes from spring-xd-extension-process:  ShellCommandProcessor.java and ShellCommandProcessorTests.java  with error:  FAILURE: Build failed with an exception.    * What went wrong:  Execution failed for task ':spring-xd-extension-process:licenseTest'.  > License violations were found: /Users/victor.chugunov/git/repos/spring/spring-xd/extensions/spring-xd-extension-process/src/test/java/org/springframework/xd/extension/process/ShellCommandProcessorTests.java}      In both classes the license is misplaced:  package org.springframework.xd.extension.process;/*   *   *  * Copyright 2014 the original author or authors.   *  *   *  * Licensed under the Apache License, Version 2.0 (the ""License"");   *  * you may not use this file except in compliance with the License.   *  * You may obtain a copy of the License at   *  *   *  * http://www.apache.org/licenses/LICENSE-2.0   *  *   *  * Unless required by applicable law or agreed to in writing, software   *  * distributed under the License is distributed on an ""AS IS"" BASIS,   *  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.   *  * See the License for the specific language governing permissions and   *  * limitations under the License.   *   */",1
"Move the Hadoop test dependencies to a different project
As a developer, I'd like to isolate the Hadoop tests in a different project so that the DIRT project doesn't have to depend upon, thus eliminating the incorrect CP file generation in eclipse. ",3
"XD on YARN broken due to missing messagebus libs
Admin on YARN simply fails because messagebus libs are not copied in place during a build.    Already tried and simple fix is for gradle/build-dist.gradle:    {code}  task copyYarnMessageBusLibs(type: Copy) {    from ""$rootDir/lib/messagebus""    into ""$buildDir/dist/spring-xd-yarn/xd-yarn/lib/messagebus""  }  {code}    and execute it together with copyMessageBusLibs task.",1
"Enhance XD on YARN to use SHDP container clustering
Currently yarn runtime needs two yarn appmaster instances(one for admins, one for containers). SHDP's container grouping added functionality to run different type of containers within a same appmaster.    Beyond this, container grouping will also give more functionality like ramping containers up/down on-demand, creating groups with different settings dynamically and restarting failed containers.",2
"Remove MongoDB from main DIRT classpath
MongoDb driver is present on DIRT's classpath, while it should not (should be present on mongo-related modules though).  This is blocked by the shortcoming described here: https://github.com/spring-projects/spring-xd/pull/1116",1
"Add support to test XD on YARN in EC2
As a developer, I'd like to have acceptance test coverage for XD + YARN on EC2 so that I can verify simple XD features running on YARN on every build cycle.",8
"Strip MessageBus DeliveryMode Header
Since the messagebus refactoring, we now see     {noformat}  15:43:06,379 1.1.0.M2  WARN xdbus.foo.0-1 support.DefaultAmqpHeaderMapper - skipping header 'amqp_deliveryMode' since it is not of expected type [class org.springframework.amqp.core.MessageDeliveryMode], it is [class org.springframework.amqp.core.MessageDeliveryMode]  {noformat}    When using a rabbit transport and a rabbit sink (the sink Spring AMQP is in its own classloader).",1
"Yarn Environment for XD Acceptance Tests
Create an 2.6 Yarn Environment on EC2 for which XD can be deployed for acceptance tests.",5
"Update to Spring Boot 1.2.1.RELEASE
nan",3
"Create a new Broadcast stream per thread
The data that is entering a broadcast stream can only occur from one thread at a time to prevent race conditions inside the stream implementation.  The current handler shares a single broadcast stream.  Change to create a new one per thread usage.",2
"Update reactor-ip and syslog modules to Reactor 2.0 RC1
As a developer, I'd like to upgrade _reactor-ip_ and _syslog_ modules to Reactor 2.0 so that we can sync up with the latest release.",1
"Set fixed NPM version for Grunt Gradle Plugin
Ensure build works in Windows environments",1
"Full build with tests fail on Ubuntu
On Ubuntu 14.04 LTS using OpenJDK version  ""1.7.0_65""    OpenJDK Runtime Environment (IcedTea 2.5.3) (7u71-2.5.3-0ubuntu0.14.04.1)  OpenJDK 64-Bit Server VM (build 24.65-b04, mixed mode)    I see the following failures:    :spring-xd-dirt:test    org.springframework.xd.dirt.security.SingleNodeApplicationWithUserBasedSecurityTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSimpleBindTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithDefaultSecurityTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithSslTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithUsersFileTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    org.springframework.xd.dirt.security.SingleNodeApplicationWithLdapSearchAndBindTest > classMethod FAILED      org.springframework.beans.factory.BeanCreationException          Caused by: java.lang.IllegalStateException              Caused by: java.net.BindException    595 tests completed, 6 failed, 2 skipped  :spring-xd-dirt:test FAILED    The test reports has this:    Caused by: java.lang.IllegalStateException: HSQLDB could not be started on 0.0.0.0:7714, state: SHUTDOWN    org.springframework.xd.batch.hsqldb.server.HSQLServerBean.startServer(HSQLServerBean.java:162)    org.springframework.xd.batch.hsqldb.server.HSQLServerBean.afterPropertiesSet(HSQLServerBean.java:82)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 42 more  Caused by: java.net.BindException: Address already in use    java.net.PlainSocketImpl.socketBind(Native Method)    java.net.AbstractPlainSocketImpl.bind(AbstractPlainSocketImpl.java:376)    java.net.ServerSocket.bind(ServerSocket.java:376)    java.net.ServerSocket.<init>(ServerSocket.java:237)    java.net.ServerSocket.<init>(ServerSocket.java:128)    org.hsqldb.server.HsqlSocketFactory.createServerSocket(Unknown Source)    org.hsqldb.server.Server.openServerSocket(Unknown Source)    org.hsqldb.server.Server.run(Unknown Source)    org.hsqldb.server.Server.access$000(Unknown Source)    org.hsqldb.server.Server$ServerThread.run(Unknown Source)    So I assume I see this due HSQL running from another test.",5
"Gemfire sink SpringXD module does not support multiple locators
Gemfire sink module accepts useLocator, host and port properties but this only allows to use one locator at a time.    We have a need to use the Gemfire sink SpringXD Module in our Seamless access project that we want to go live in Q1.  The Version of SpringXD we planned on using is 1.1    However we need HA and we need to connect to a cluster with multiple locators. Problem is this isn’t supported yet in SpringXD.    We have used multiple locators in many projects in EMC and we don’t want to revert back to a situation where we have to put virtual IPs in front of locators just for SpringXD.    Ref to the SpringXD docs found in 1.0.3 and 1.1.0GA versions:    “The locator option is mostly intended for integration with an existing GemFire installation in which the cache servers are configured to use locators in accordance with best practice. While GemFire supports configuration of multiple locators for failover, this is currently not supported in XD. However, using a single virtual IP backed by hardware routers for failover has proven to be an effective and simpler alternative.�?    ",5
"HDFS sink should provide rolloverTime option not only idleTiemout
When using HDFS sink with ildeTimeout and rollover options in stream definition we have noticed that idleTimeout does not give you a flexibility when you would prefer a file to rollover after specific time regardless of the activity/inactivity of the file.    Proposed option:  rolloverTimeout  timeout after file will be automatically closed    Link: #XD-2413",5
"XD is not logging when deployed using yarn
When deploying XD (admin & container) using Yarn we only get the first 495 characters of the log which is the Ascii Art and Documentation links. {noformat}  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ 1.1.0.BUILD-SNAPSHOT             eXtreme Data   Started : ContainerServerApplication Documentation: https://github.com/spring-projects/spring-xd/wiki {noformat}",5
"Custom Module not loading class from the module/lib.
The module/lib contains the necessary jars but it is not taken, I am attaching the simple custom module which contains just few beans. Here is how I am creating the job from the xd-shell  job create --name job1 --definition ""job-custom"" --deploy    The server logs contains this error  ***************************************************************************************  10:43:20,193 1.1.0.M2  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@2963e1e2 moduleName = 'job-custom', moduleLabel = 'job-custom', group = 'job1', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = job, parameters = map[[empty]], children = list[[empty]]]  10:43:20,697 1.1.0.M2 ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed  java.lang.NoClassDefFoundError: org/springframework/oxm/Unmarshaller    java.lang.Class.getDeclaredMethods0(Native Method)    java.lang.Class.privateGetDeclaredMethods(Class.java:2531)    java.lang.Class.getDeclaredMethods(Class.java:1855)    org.springframework.util.ReflectionUtils.getDeclaredMethods(ReflectionUtils.java:571)  ***************************************************************************************    I already had been discussing this over the forums but could not get much help.  stackoverflow.com/questions/27878047/noclassdefinitionerror-with-simple-bean-configuration    If I place the spring-oxm jar in the spring-xd lib I get this error  ***************************************************************************************  java.lang.IllegalStateException: Cannot convert value of type [org.springframework.oxm.jaxb.Jaxb2Marshaller] to required type [org.springframework.oxm.Unmarshaller] for property 'unmarshaller': no matching editors or conversion strategy found   ***************************************************************************************  ",2
"Spring XD shell should maintain single log file (per user?)
Currently xd-shell script packaged in Spring XD dist creates spring-shell.log file in invocation directory.   When xd-shell is added to $PATH user will usually invoke the script from many directories leaving log files all over the file system.  Would it be possible to keep the log files in one predefined location (e.g. $HOME/.spring-shell.log or $DIST/shell/logs/spring-shell.log)?",1
"Failed to create a stream with Script processor
I attempted to create a stream with a Script processor using Spring XD shell: {code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --location=print-stacktrace.groovy | null"" Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor:     location: option named 'location' is not supported {code}  I've corrected the syntax as described in docs by replacing --location with --script: {code}xd:>stream create --name test1 --definition ""tcp --port=17654 | script --script=print-stacktrace.groovy | null"" Created new stream 'test1'{code}  My stream was created but the deployment failed with exception: {code} 20:04:45,105 1.0.3.RELEASE  INFO Deployer server.StreamDeploymentListener - Deployment status for stream 'test1': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'org.springframework.integration.config.ServiceActivatorFactoryBean#0' defined in null: Could not resolve placeholder 'location' in string value ""${location}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""   org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:211)   org.springframework.context.support.PropertySourcesPlaceholderConfigurer.processProperties(PropertySourcesPlaceholderConfigurer.java:180)   org.springframework.context.support.PropertySourcesPlaceholderConfigurer.postProcessBeanFactory(PropertySourcesPlaceholderConfigurer.java:155)   org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)   org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:162)   org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:609)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:464)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:320)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:142)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:201)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}""   org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174)   org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126)   org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:194)   org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:158)   org.springframework.context.support.PropertySourcesPlaceholderConfigurer$2.resolveStringValue(PropertySourcesPlaceholderConfigurer.java:175)   org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveStringValue(BeanDefinitionVisitor.java:282)   org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:209)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitIndexedArgumentValues(BeanDefinitionVisitor.java:150)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:84)   org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:169)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitIndexedArgumentValues(BeanDefinitionVisitor.java:150)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:84)   org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:169)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitPropertyValues(BeanDefinitionVisitor.java:141)   org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:82)   org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:208) 	... 31 more {code}  # [script.xml in 1.0.3 tag|https://github.com/spring-projects/spring-xd/blob/v1.0.3/modules/processor/script/config/script.xml] uses {code}<int-groovy:script location=""${location}"" ...{code} # The [Script 1.0.3 processor docs|http://docs.spring.io/autorepo/docs/spring-xd/1.0.3.RELEASE/reference/html/#script] have issues with properties naming e.g. example is using --location while later --script is used. Same with --propertiesLocation and --properties-location.",1
"JDBC sink doesn't deserialize JSON types correctly
*Expected*   1. Create MYTABLE table with DATE or TIMESTAMP column MYTIME 2. Create a stream ending with {code}... | object-to-json | jdbc --tableName=MYTABLE ...{code} 3. Send a message with payload being a Java object that has a property myTime of type java.util.Date 4. Message payload is inserted into MYTABLE table, date is correctly stored in MYTIME column.  *Actual*  4. Exception is thrown from JDBC sink which attempts to bind a long into MYTIME column.  *Root cause*  JDBC sink uses *org.springframework.xd.jdbc.JdbcMessagePayloadTransformer* class to deserialize JSON payload into Map which will later be used to bind parameters into java.sql.PreparedStatement.  Unfortunately JdbcMessagePayloadTransformer, and MessageTransformingHandler which is calling it, doesn't respect *json\_\_TypeId\_\_* message header so information about Java types is lost. Other Spring XD components serialize java.util.Date as Unix timestamp e.g. object-to-json transformer. JDBC sink will deserialize the date as java.lang.Long and later attempt to bind incorrect type to query parameter.  In case of GemFire XD following exception will be thrown during query parameter binding phase: {code} com.pivotal.gemfirexd.internal.shared.common.sanity.AssertFailure: ASSERT FAILED Number of parameters expected for message id 22005 (3) does not match number of arguments received (2)   com.pivotal.gemfirexd.internal.shared.common.sanity.SanityManager.ASSERT(SanityManager.java:239)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.formatMessage(MessageUtil.java:245)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:151)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:191)   com.pivotal.gemfirexd.internal.shared.common.i18n.MessageUtil.getCompleteMessage(MessageUtil.java:107)   com.pivotal.gemfirexd.internal.client.am.SqlException.<init>(SqlException.java:184)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement$PossibleTypes.throw22005Exception(PreparedStatement.java:4007)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setLong(PreparedStatement.java:843)   com.pivotal.gemfirexd.internal.client.am.PreparedStatement.setObject(PreparedStatement.java:1688)   org.springframework.jdbc.core.StatementCreatorUtils.setValue(StatementCreatorUtils.java:402)   org.springframework.jdbc.core.StatementCreatorUtils.setParameterValueInternal(StatementCreatorUtils.java:235)   org.springframework.jdbc.core.StatementCreatorUtils.setParameterValue(StatementCreatorUtils.java:150)   org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.setValues(PreparedStatementCreatorFactory.java:300)   org.springframework.jdbc.core.PreparedStatementCreatorFactory$PreparedStatementCreatorImpl.createPreparedStatement(PreparedStatementCreatorFactory.java:252)   org.springframework.jdbc.core.JdbcTemplate.execute(JdbcTemplate.java:638)   org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:909)   org.springframework.jdbc.core.JdbcTemplate.update(JdbcTemplate.java:933)   org.springframework.jdbc.core.namedparam.NamedParameterJdbcTemplate.update(NamedParameterJdbcTemplate.java:313)   org.springframework.integration.jdbc.JdbcMessageHandler.executeUpdateQuery(JdbcMessageHandler.java:130)   org.springframework.integration.jdbc.JdbcMessageHandler.handleMessageInternal(JdbcMessageHandler.java:112)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78) 	... 372 more {code}",2
"Provide missing JARs to enable #xpath() SpEL
Spring XD should package *spring-integration-xml* JAR within distribution so we can invoke *#xpath()* SpEL from processors, e.g. using transformer:  {code}... | transform --expression='#xpath(payload, ""/*[name()=''Datasource'']/*[name()=''row'']/text()"" | ... {code} ",1
"Spring XD Admin UI does not show all the streams
From Spring XD Shell, running this command ""stream list"", we counted 30 streams, however Spring XD Admin UI shows only 20. When destroying some streams from Admin UI, the others that was not in the list start appearing. We have not reviewed if there is a configuration parameter that tells how many streams to show in the Admin UI.",5
"Upgrade grunt/node plugins
Upgrade in 1.0.x branch what was done in this commit on master.    https://github.com/spring-projects/spring-xd/commit/16062d771e23187a1d9e8d549abc646ff44e435b  ",1
"resourceManagerPort value not recognized when deploying container
Attempted to set the rmAddress port to a value other than 8032 by using the resourceManagerPort however the value was not recognized. I've attached the servers.yml.   {noformat} 2015-01-12 20:21:48,935 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskScheduler' has been explicitly defined. Therefore, a default ThreadPoolTaskScheduler will be created. 2015-01-12 20:21:48,940 INFO [ConfiguringBeanFactoryPostProcessor] - No bean named 'taskExecutor' has been explicitly defined. Therefore, a default SyncTaskExecutor will be created. 2015-01-12 20:21:50,461 INFO [SpringYarnConfiguration] - Enabling CLIENT for Yarn 2015-01-12 20:21:50,475 INFO [SpringYarnConfiguration] - We couldn't figure out if we could use existing configuration 2015-01-12 20:21:50,475 INFO [SpringYarnConfiguration] - Building configuration for bean 'yarnConfiguration' 2015-01-12 20:21:50,498 INFO [SpringYarnConfigBuilder] - Existing yarnConfiguration: null 2015-01-12 20:21:50,649 INFO [ConfigurationFactoryBean] - Overwriting fsUri=[file:///] with fsUri=[hdfs://10.111.172.160:9000] 2015-01-12 20:21:50,649 INFO [ConfigurationFactoryBean] - Overwriting rmAddress=[0.0.0.0:8032] with rmAddress=[10.111.172.160:8032] 2015-01-12 20:21:55,965 INFO [ConfigurationFactoryBean] - Executing with tokens: 2015-01-12 20:21:55,975 INFO [SpringYarnConfigBuilder] - Setting configuration for SpringYarnConfigs:  fs.defaultFS=hdfs://10.111.172.160:9000 yarn.resourcemanager.address=10.111.172.160:8032 Configuration: core-default.xml, core-site.xml, yarn-default.xml, yarn-site.xml, mapred-default.xml, mapred-site.xml {noformat}",3
"Update to Reactor 2.0 build snapshots
nan",1
"Remove all deprecated compile warnings
Run a clean gradle build to identify all warnings.",3
"Create sample application for RxJava
Create port of https://github.com/spring-projects/spring-xd-samples/tree/master/reactor-moving-average based on RxJava",2
"Create MessageConverter interface to allow user extensions
As a user, I'd like to have the option to extend the default message handling behavior for HTTP source-module so that I can override the settings via _servers.yml_ to control the default message size.    *Notes:*  The adapter currently has that hard-coded (1MB limit) in the HttpChunkAggregator. We will have to expose this property for overrides. [Related PR|https://github.com/spring-projects/spring-xd/pull/1367].",3
"Bump Spring Integration to 4.1.2; Spring AMQP to 1.4.2
nan",1
"XD Yarn deployment requires the ability to set permsize
When deploying XD using Java 7 the user must be able to set the permsize to a value larger than the default.   The reason this is required is that if we deploy a gemfire component more than 2 times or a kafka source & sink more than 2 times, stream deployment begins to fail.    The only exception that was captured was the following: {noformat} Exception in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor"" Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread ""ec2Test3_ip-10-146-213-31-1421176704238-e1786039_watcher_executor {noformat}  Logs are not available at this time.  ",3
"Web UI is not displayed
Web UI management interface does not display the stream  list data or deploy status  js ERROR： definitions.js:28 Uncaught TypeError: undefined is not a function  eg：http://120.27.44.69:9393/admin-ui/#/streams/definitions",3
"Update spring-data-hadoop version to 2.1.0.RC1
Update spring-data-hadoop version to 2.1.0.RC1. This also includes updating the following:    - adding hadoop26 (Apache Hadoop 2.6.0) as distro  - adding hdp22 (Hortonworks HDP 2.2) as distro  - set default distro to hadoop26  - update cdh5 to version 5.3.0  - remove older distros - hadoop24, hdp21  ",3
"Test recent Hadoop distro changes
Test basic functionality (hdfs sink, jdbchdfs job) on hadoop26, hdp22, cdh5, phd21    Test XD on YARN on hadoop26, hdp22, cdh5 and phd21  ",8
"KafkaMessageBusTests#testCompression failing
Intermittent. Reported on ubuntu and OS/x",3
"Add an ""xd-yarn info"" command to list admin servers and ports
As a user deploying XD on YARN I need a convenient way to get info like the admin port for my current deployment.    Best way, for now, would be to add an info command to the xd-yarn script.    With the latest changes the admin server runs on a random port when we deploy to YARN. In order for the user to connect they would have to query Zookeeper. This is inconvenient.",5
"Update PostgreSQL JDBC Driver Version
Update the supplied PostgreSQL JDBC Driver to the latest version (9.3-1102 - 2014-07-10), the current supplied version is from 2012.     In our particular use case the latest driver allows use of the JDBC connection.unwrap feature which gives access to the underlying connection from a pooled connection which in turn enables use of the postgres copyManager.copyIn functionality which can speed up batch inserts in a batch process.     See http://jdbc.postgresql.org/documentation/changelog.html   ",2
"Create a BroadcasterMessageHandler that uses a 'Serialized' Broadcaster
This is a parallel implementation to the RxJava     https://github.com/spring-projects/spring-xd/blob/master/spring-xd-rxjava/src/main/java/org/springframework/xd/rxjava/SubjectMessageHandler.java    That will allow multiple threads to broadcast an event but allow processing to occur one at a time on any thread.",2
"Backport XD-2411 to 1.0.x branch
This fix for RichGauge should go into the 1.0.x line.",1
"Mismatch between configuration class and script XML for location/script
The *org.springframework.xd.module.options.mixins.ScriptMixin* options class shipped with XD 1.0.3 refers to *script* rather than *location* however the XML configuration still references *$\{location\}* in the service activator:  {noformat} 	<service-activator output-channel=""output"" input-channel=""input""> 		<int-groovy:script location=""${location}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/> 	</service-activator> {noformat}  Creating a stream using the old *location* argument no longer works obviously:  {noformat} xd:>stream create myJobArchiveTrigger --definition ""tap:job:myJob.job > script --location=job-status.groovy --variables='tgtStatus=COMPLETED' > queue:job:archiveJob"" --deploy Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module script of type processor     location: option named 'location' is not supported {noformat}  Creating the same stream using *--script* reports success at the shell prompt but results in an error in the container/admin logs:  {noformat} Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'location' in string value ""${location}"" {noformat}  Working around this by overriding the XML setting in our deployment:  {noformat} 	<service-activator output-channel=""output"" input-channel=""input""> 		<int-groovy:script location=""${script}"" script-variable-generator=""variableGenerator"" refresh-check-delay=""60""/> 	</service-activator> {noformat}",1
"Create plugin module for RxJava based processors
As an developer, I'd like to have a similar approach to creating reactor based stream processor as with Spark and RxJava.  A plugin should allow a reactor processor module to specify the bare minimum to work, e.g. the processor class.    Explore how additional configuration can be achieved with well known module option commands.    ",3
"Change Grunt Build - Checkin Bower Artifacts
In order to decrease CI build issues, we should checkin bower dependencies.   See: http://addyosmani.com/blog/checking-in-front-end-dependencies/",2
"TwitterStream/TwitterSearch sources fail when deploying on Yarn
We're getting a CNF on org.apache.http.impl.client.HttpClients {noformat} 20:07:03,556 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.sink.file.1, type=CHILD_ADDED 20:07:03,557 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'file' for stream 'ec2Test3' 20:07:03,828 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@8d11c70 moduleName = 'file', moduleLabel = 'file', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map['binary' -> 'true', 'mode' -> 'REPLACE'], children = list[[empty]]] 20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/740c5f05-03f9-4b0f-9c3a-80022b594830/ec2Test3.source.twitterstream.1, type=CHILD_ADDED 20:07:04,456 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'twitterstream' for stream 'ec2Test3' 20:07:05,040 1.1.0.SNAP  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@3ec4f104 moduleName = 'twitterstream', moduleLabel = 'twitterstream', group = 'ec2Test3', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['consumerKey' -> '5ynZLmXyvxXzAlYHRlrb28U8n', 'accessToken' -> '2561860742-sfreUrr2jXwUPBk5eOL4Ow5GKy4Hyl12snKwfg5', 'accessTokenSecret' -> '481BGNZZDwdJ8rVw2hG9IryKuTZsv1cV1hiDpwdHt19xe', 'consumerSecret' -> 'C7ZQhJvy5RQm3QS6ruSkCriZZWtUMRbJbNeDCH7uYACWJPtBVi'], children = list[[empty]]] 20:07:05,871 1.1.0.SNAP  WARN DeploymentsPathChildrenCache-0 annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)   org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) 	... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)   org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267) 	... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)   org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)   sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)   sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)   sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)   java.lang.reflect.Constructor.newInstance(Constructor.java:526)   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:147) 	... 50 more Caused by: java.lang.ClassNotFoundException: org.apache.http.impl.client.HttpClients   java.net.URLClassLoader$1.run(URLClassLoader.java:366)   java.net.URLClassLoader$1.run(URLClassLoader.java:355)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:354)   java.lang.ClassLoader.loadClass(ClassLoader.java:425)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)   java.lang.ClassLoader.loadClass(ClassLoader.java:358) 	... 63 more 20:07:05,874 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 boot.SpringApplication - Application startup failed org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.integration.x.twitter.TwitterStreamChannelAdapter#0' defined in class path resource [config/twitterstream.xml]: Cannot resolve reference to bean 'twitterTemplate' while setting constructor argument; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:359)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)   org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'twitterTemplate' defined in class path resource [config/twitterstream.xml]: Bean instantiation via constructor failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:275)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351) 	... 39 more Caused by: org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.social.twitter.api.impl.TwitterTemplate]: Constructor threw exception; nested exception is java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.beans.BeanUtils.instantiateClass(BeanUtils.java:163)   org.springframework.beans.factory.support.SimpleInstantiationStrategy.instantiate(SimpleInstantiationStrategy.java:122)   org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:267) 	... 48 more Caused by: java.lang.NoClassDefFoundError: org/apache/http/impl/client/HttpClients   org.springframework.http.client.HttpComponentsClientHttpRequestFactory.<init>(HttpComponentsClientHttpRequestFactory.java:72)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator$1.<init>(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector$HttpComponentsClientRequestFactoryCreator.createRequestFactory(ClientHttpRequestFactorySelector.java:77)   org.springframework.social.support.ClientHttpRequestFactorySelector.getRequestFactory(ClientHttpRequestFactorySelector.java:52)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplateWithCulledMessageConverters(AbstractOAuth1ApiBinding.java:188)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.createRestTemplate(AbstractOAuth1ApiBinding.java:169)   org.springframework.social.oauth1.AbstractOAuth1ApiBinding.<init>(AbstractOAuth1ApiBinding.java:70)   org.springframework.social.twitter.api.impl.TwitterTemplate.<init>(TwitterTemplate.java:79)   sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)   sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)   sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)   java.lang.reflect.Constructor.newInstance(Constructor.java:526)   org.springframework.bean...",3
"Add support to 'track history' in message headers
As a user, I'd like to have an option to track history so that I get the visibility of stream name, module name etc. added as part of the message header.",3
"Windows build fails
This Hadoop scenario will not work in Windows. The scope is to *disable* the test for windows build.    org.springframework.batch.integration.x.RemoteFileToHadoopTaskletTests > testWrite FAILED      java.lang.IllegalStateException          Caused by: org.springframework.beans.factory.BeanCreationException              Caused by: java.lang.UnsatisfiedLinkError    org.springframework.batch.integration.x.RemoteFileToHadoopTests > testSimple FAILED      java.lang.IllegalStateException          Caused by: org.springframework.beans.factory.BeanCreationException              Caused by: java.lang.UnsatisfiedLinkError  Java HotSpot(TM) Client VM warning: ignoring option MaxPermSize=512m; support was removed in 8.0    3 tests completed, 2 failed  :spring-xd-extension-batch:test FAILED    FAILURE: Build failed with an exception.",1
"XD Gemfire modules fail to deploy in  Yarn
1 admin on slave1  1 container on slave2    Gemfire modules fail to deploy.  with the following exception:  Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy  This is because the modules require a XD_HOME environment variable and this is not set by the yarn deployment.    {noformat}  Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:211)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: null/modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:null/modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans$_run_closure1.doCall(beans:4)    beans$_run_closure1.doCall(beans)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.Closure.call(Closure.java:423)    groovy.lang.Closure.call(Closure.java:417)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)    groovy.lang.Closure.call(Closure.java:439)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans.run(beans:1)    groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 29 more  Caused by: java.io.FileNotFoundException: null/modules/common/gemfire-sink.groovy (No such file or directory)    java.io.FileInputStream.open(Native Method)    java.io.FileInputStream.<init>(FileInputStream.java:146)    java.io.FileInputStream.<init>(FileInputStream.java:101)    sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)    sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)    org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)    org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 79 more  {noformat}",3
"Error when listing Streams in admin-ui
As a user, I'm trying to list streams (>20) in admin-ui to use the pagination; however, I ended up with blank page and the server-side errored with _java.lang.IllegalStateException_.    Version: 1.1.0 SNAPSHOT (master build)  Distributed: 1 admin and 2 containers    *Steps to reproduce:*  1) Deploy the following streams.  stream create foo1 --definition ""time | log"" --deploy  stream create foo2 --definition ""time | log"" --deploy  stream create foo3 --definition ""time | log"" --deploy  stream create foo4 --definition ""time | log"" --deploy  stream create foo5 --definition ""time | log"" --deploy  stream create foo6 --definition ""time | log"" --deploy  stream create foo7 --definition ""time | log"" --deploy  stream create foo8 --definition ""time | log"" --deploy  stream create foo9 --definition ""time | log"" --deploy  stream create foo10 --definition ""time | log"" --deploy  stream create foo11 --definition ""time | log"" --deploy  stream create foo12 --definition ""time | log"" --deploy  stream create foo13 --definition ""time | log"" --deploy  stream create foo14 --definition ""time | log"" --deploy  stream create foo15 --definition ""time | log"" --deploy  stream create foo16 --definition ""time | log"" --deploy  stream create foo17 --definition ""time | log"" --deploy  stream create foo18 --definition ""time | log"" --deploy  stream create foo19 --definition ""time | log"" --deploy  stream create foo20 --definition ""time | log"" --deploy  stream create foo21 --definition ""time | log"" --deploy  stream create foo22 --definition ""time | log"" --deploy    2) Go to Streams tab in admin-ui to get a blank page and the following exception in admin logs.    *Error:*  16:55:19,107 1.1.0.SNAP ERROR http-nio-9393-exec-2 rest.RestControllerAdvice - Caught exception while handling a request  java.lang.IllegalStateException: Not all instances were looked at    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.xd.dirt.rest.XDController.enhanceWithDeployments(XDController.java:207)    org.springframework.xd.dirt.rest.XDController.listValues(XDController.java:178)    org.springframework.xd.dirt.rest.StreamsController.list(StreamsController.java:63)  ",1
"Job definition is deleted after restart the srping xd service in single node mode
Job definition is deleted after restart the srping xd service in single node mode  repro step: 1.start service as single node 2.create a batch module 3.create a job based on batch module 4.restart service  expect result: job definition is displayed on the job list  actual result: job list is empty, all job definitions are missed",2
"Missing Log Configuration for throughput-sampler
http://stackoverflow.com/questions/28019801/how-to-read-throughput-sampler-sink-values-in-spring-xd/28027544#28027544",1
"Use Kryo instance pooling to reduce instantiation overhead
https://github.com/EsotericSoftware/kryo#pooling-kryo-instances",1
"Add module properties files to yarn config directory
Currently any properties files located in the ${xd.config.home}/ directory are not included in the config directory provided by the yarn deployment. And thus modules are pulling props from the  spring-xd-yarn-1.1.0.BUILD-SNAPSHOT.zip file.   We need to include these property files in the config dir.  ",2
"Add Protobuf codec implementation
As a user, I'd like to have Google's [Protocol Buffer|https://code.google.com/p/protobuf/] codec option so that I can serialize/deserialize objects based on its native specifications.",5
"Add test coverage for 'complex objects' as payload
As a tester, I'd like to add test coverage for ""complex objects"" such protocol buffers, any object with nested variables or a tree of objects so that I can evaluate and document the performance characteristics.",8
"Ensure that metadata for Kafka message bus is propagated before producing/consuming
Currently, `ensureTopicCreated` will invoke the creation of the topic on the brokers, however, the calls is not blocking. So, before proceeding, we should make sure that the metadata is readable (therefore propagated)",3
"Create reactor module in spring-xd-modules project
nan",3
"Update Spring Batch to 3.0.3.RELEASE
nan",1
"When setting management.port only the admin is updated
When setting the management.port in the servers.yml all deployments should use the port specified.  Currently only admin is updated, the containers are still using 0.",2
"Add tests and refactor ZooKeeperStreamRepository
Looks like there is a bit of technical debt in *ZooKeeperStreamRepository*. Additionally there is not a single test for this class, yet. However, testability looks tricky.",8
"Add Kafka Native Metadata Store
nan",3
"Update documentation for Kafka sources  
Include new features added by using Spring Integration Kafka M3",1
"Add assertion text to Junit Tests
Discovered Junit test failures that do not provide an assertion message. Therefore the Junit report is rather useless.  2 Classes (Maybe we should check the entire code-base):  Class org.springframework.xd.shell.command.JobCommandWithHadoopTests testLaunchFtpHadoopJob  {code} java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.AbstractJobIntegrationTest.checkForJobInList(AbstractJobIntegrationTest.java:213)   org.springframework.xd.shell.command.JobCommandWithHadoopTests.testLaunchFtpHadoopJob(JobCommandWithHadoopTests.java:73)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {code}  Class org.springframework.xd.shell.command.HttpCommandTests testHttpPostUtfText {code} java.lang.AssertionError   org.junit.Assert.fail(Assert.java:86)   org.junit.Assert.assertTrue(Assert.java:41)   org.junit.Assert.assertTrue(Assert.java:52)   org.springframework.xd.shell.command.StreamCommandTemplate.verifyExists(StreamCommandTemplate.java:162)   org.springframework.xd.shell.command.StreamCommandTemplate.doCreate(StreamCommandTemplate.java:99)   org.springframework.xd.shell.command.StreamCommandTemplate.create(StreamCommandTemplate.java:65)   org.springframework.xd.shell.command.HttpCommandTests.testHttpPostUtfText(HttpCommandTests.java:97)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)   org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)   org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)   org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.junit.rules.ExternalResource$1.evaluate(ExternalResource.java:48)   org.junit.rules.TestWatcher$1.evaluate(TestWatcher.java:55)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:78)   org.junit.runners.BlockJUnit4ClassRunner.runChild(BlockJUnit4ClassRunner.java:57)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.junit.runners.Suite.runChild(Suite.java:128)   org.junit.runners.Suite.runChild(Suite.java:27)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.xd.test.AbstractExternalResourceTestSupport$1.evaluate(AbstractExternalResourceTestSupport.java:71)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:483)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)   java.lang.Thread.run(Thread.java:745) {code}",1
"Add more comprehensive tests for the simple consumer-based Kafka Message Bus
nan",3
"Add ZooKeeper timeout options to configuration file
The following timeout options should be added to our configuration file:    | session timeout | the number of milliseconds before the ZooKeeper session times out |  | connection timeout | the number of milliseconds before a connection to a ZooKeeper server times out |  | retry wait period | number of milliseconds to wait before attempting a connection after a failed connection |  | max retries | number of times to attempt a connection after a failed connection |    ",2
"Update deployment guide to include verbose gc
The deployment guide https://github.com/spring-projects/spring-xd/wiki/Deployment should have instructions on turning on verbose gc for production applications.    The gc log tends to be verbose so running it in development is not desirable. However having the gc log in production is very helpful for troubleshooting slow/unresponsive applications.",1
"PermGen errors after running for a long time
Leaving the runtime running (e.g. as singlenode) ends up in permgen errors",5
"Test Redis Sentinel setup and document recommended configuration
Configure Redis Cluster with Sentinal v 2.8.19.   Verify fail over, experiment with settings.  Useful reference https://code.flickr.net/2014/07/31/redis-sentinel-at-flickr/    All analytics test cases should be run as well as test that deploy streams that make use of redis analytics.   There might be some minor code changes required as mentioned in the flickr article.",5
"Add Ambari plugin (beta) to build and install Spring XD
As a developer, I'd like to use Ambari plugin so that I can provision, manage, and monitor Spring XD cluster using the same tool I use for Hadoop clusters.",5
"For time being checkin UI build artifacts
nan",1
"In ""ZooKeeperStreamRepository#findAllInRange()"" the boolean parameters are not supported
In *ZooKeeperStreamRepository#findAllInRange()* the parameters  * boolean fromInclusive * boolean toInclusive  Don't have any effect (implicitly true)  Are they needed? Do we need to support it?",2
"UI Step Execution Progress will show value > than 100% 
In cases where I re-run a job, and during the job execution the percentage complete will tally the total runtime of the current execution and all previous executions. See the attached image.",3
"Update 'partitionColumn' wiki to include mutual exclusiveness of 'sql' and 'tableName' options
As a user, I'd like to refer to the wiki so that I can create a job with 'partitions' that in turn expects _tableName_ and _columns_ be explicitly included in the job definition.     It is also beneficial to call-out _sql_ and _tableName_ metadata options are mutually exclusive. Following logic in _JdbcHdfsOptionsMetadata_ needs documented.    {code:java}  @AssertTrue(message = ""Use ('tableName' AND 'columns') when using partition column"")  boolean isPartitionedWithTableName() {  	if (StringUtils.hasText(partitionColumn)) {  		return StringUtils.hasText(tableName) && !StringUtils.hasText(sql);  	}  	else {  		return true;  	}  }  {code}    ",1
"Add support to either use 'sql' or tableName' options for partitioned jobs
As a user, I'd like to either use _sql_ or _tableName_ options so that I can build a partitioned job with _where_ clause and strict table-column combo respectively. ",5
"Shell processor is not thread safe
Multiple threads invoke the shell processor result in I/O errors and/or data corruption. send() and receive() should be synchronized. ",1
"The shell distribution zip is missing hadoop26 libraries
The spring-xd-[version]-shell.zip distribution zip doesn't include the lib/hadoop26 directory and libraries, so we get the following exception when starting the shell:    Exception in thread ""main"" java.lang.NoClassDefFoundError: org/apache/hadoop/conf/Configuration  ",1
"Acceptance tests updated to be able to test XD Yarn deployment
In order to run Acceptance tests in their current state there had to be * changes to the code  ** Set the location of the data node for the hdfs tests. (because the data nodes were no located with the master.) ** disable the copying of batch basic because we did not know the container location. * Had to configure tests by hand so that we could identify the: ** admin port (with new features we should be able to write code to find it.  Should be able to set it but we had a problem.  Possible yarn bug) ** JMX Port ( We could set it for the master but not the container this was a Yarn deployBug ) ** Where the build was deployed on the container node, so we could copy the batch-basic test.   ",8
"Create a CI Acceptance Tests build for XD Yarn deployment
nan",3
"Validate that topics used for storing offsets are compacted
nan",1
"Can't run WordCount example in hadoop kerberized cluster
Hey Guys,  Im trying to run WordCount example in kerberized cluster with the attached job configuration. The job upload the test file to the HDFS without problems but it fails in wordcount step. I am running the example on singlenode and  I configured the config/hadoop.properties file for shell and container with kerberos setting such as https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos.  The error log is attached.  Thanks in advance for the help. Regards",3
"Acceptance tests need to create or use an existing topic prior to executing test
nan",3
"Refactor ModuleFactory to remove direct spark dependency on XD dirt
Currently, the ModuleFactory needs to know about `SparkStreamingDriverModule` to create the spark streaming module. It is for this reason, the spring-xd-module has direct dependency on spark streaming. We need to refactor this code so that there is no direct dependency on spark streaming for spring-xd-module and subsequently spring-xd-dirt.",8
"servers.yaml has a typo that causes XD startup to fail when....
Line 295 has 2 dashes instead of 3.  There is no effect on XD unless the XD extensions block is uncommented.    I have been using the XD extensions in version 1.0.3 and have merged my servers.yaml with all of the new content in 1.1.0.M2.    The Admin JVM crahes without logging any exception and the container JVM crashes and logs the following:    /  ___|          (-)             \ \ / /  _  \  \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |  /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /  \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/        | |                  __/ |        |_|                 |___/  1.1.0.M2                         eXtreme Data      Started : ContainerServerApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    expected '<document start>', but found BlockMappingStart  in 'reader', line 303, column 1:      xd:      ^            at org.yaml.snakeyaml.parser.ParserImpl$ParseDocumentStart.produce(ParserImpl.java:225)          at org.yaml.snakeyaml.parser.ParserImpl.peekEvent(ParserImpl.java:158)          at org.yaml.snakeyaml.parser.ParserImpl.checkEvent(ParserImpl.java:143)          at org.yaml.snakeyaml.composer.Composer.checkNode(Composer.java:68)          at org.yaml.snakeyaml.constructor.BaseConstructor.checkData(BaseConstructor.java:93)          at org.yaml.snakeyaml.Yaml$1.hasNext(Yaml.java:498)          at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:152)          at org.springframework.beans.factory.config.YamlProcessor.process(YamlProcessor.java:137)          at org.springframework.boot.env.YamlPropertySourceLoader$Processor.process(YamlPropertySourceLoader.java:78)          at org.springframework.boot.env.YamlPropertySourceLoader.load(YamlPropertySourceLoader.java:50)          at org.springframework.boot.env.PropertySourcesLoader.load(PropertySourcesLoader.java:126)          at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.loadIntoGroup(ConfigFileApplicationListener.java:378)          at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:366)          at org.springframework.boot.context.config.ConfigFileApplicationListener$Loader.load(ConfigFileApplicationListener.java:336)          at org.springframework.boot.context.config.ConfigFileApplicationListener.addPropertySources(ConfigFileApplicationListener.java:173)          at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEnvironmentPreparedEvent(ConfigFileApplicationListener.java:144)          at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEnvironmentPreparedEvent(ConfigFileApplicationListener.java:137)          at org.springframework.boot.context.config.ConfigFileApplicationListener.onApplicationEvent(ConfigFileApplicationListener.java:126)          at org.springframework.context.event.SimpleApplicationEventMulticaster.invokeListener(SimpleApplicationEventMulticaster.java:151)          at org.springframework.context.event.SimpleApplicationEventMulticaster.multicastEvent(SimpleApplicationEventMulticaster.java:128)          at org.springframework.boot.context.event.EventPublishingRunListener.publishEvent(EventPublishingRunListener.java:100)          at org.springframework.boot.context.event.EventPublishingRunListener.environmentPrepared(EventPublishingRunListener.java:59)          at org.springframework.boot.SpringApplication.run(SpringApplication.java:286)          at org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)          at org.springframework.xd.dirt.server.ContainerBootstrapContext.<init>(ContainerBootstrapContext.java:48)          at org.springframework.xd.dirt.server.ContainerServerApplication.run(ContainerServerApplication.java:83)          at org.springframework.xd.dirt.server.ContainerServerApplication.main(ContainerServerApplication.java:72)        ",1
"XD should use same hadoop security keys as Spring for Apache Hadoop
For kerberos and other security related settings we use keys like 'spring.hadoop.userPrincipal' mentioned in https://github.com/spring-projects/spring-xd/wiki/Hadoop-Kerberos. However when we added boot config props to shdp, we used a sub keys like 'spring.hadoop.security.userPrincipal'.    It'd be good if we'd fix these to be same in both XD and SHDP not to cause confusion.",1
"Ensure that only bean definitions for the proper transport are loaded
Currently, the org.springframework.xd.dirt.server.SharedServerContextConfiguration will load  everything that matches the  `""classpath*:"" + ConfigLocations.XD_CONFIG_ROOT + ""bus/*.xml""` path.   In a normal (i.e. production) environment, there are no conflicts, since only one jar containing message bus definitions is ever on the class path.   However, during testing, *all* the projects containing bus definitions are on the class path, which leads to potential conflicts.",3
"We Need a KafkaSingleNodeStreamDeploymentIntegrationTests
See {{RedisSingleNodeStreamDeploymentIntegrationTests}} etc.",3
"Add Kafka-based implementation for AbstractSingleNodeStreamDeploymentIntegrationTests
nan",2
"Add Kafka-based implementation for AbstractDistributedTransportSingleNodeStreamDeploymentIntegrationTests
nan",2
"Spike: Research request/reply support to Kafka Message Bus
The scope is to research the available options to provide request/reply support for Kafka.     * Document findings  * POCs    Previous Desc:  The bindRequestor and bindReplier methods of the message bus need to be implemented.",5
"Document migration strategy for custom modules (from 1.0 to 1.1)
As a user, I'd like to migrate from 1.0 to 1.1 and be able to port my custom modules so that I can operationalize existing data pipelines and also take advantage of latest XD features.",2
"HdfsTest picks up data from a previous run.
If a stream foo has messages in its queue when it is destroyed and another stream named foo is created of similar structure those messages will be delivered to sink.  This is seen when twitterstream runs prior to hdfssink test.  The twitters stream data is written to hdfs instead of the trigger data that was intended. The solution is to give hdfstest its own unique name instead of the default ec2test3 name.",1
"Update com.jayway.jsonpath to latest version
Use latest version, might need to exclude version from other dependencies, e.g. SI, in build-common.gradle.",1
"Make deployment timeout configurable
Currently, ModuleDeploymentWriter uses default timeout 30s which can not be overridden. We need to make this configurable.",1
"Create a sample to invoke Pig script/job from XD
As a user, I'd like to refer to a Pig script/job sample so that I can use that as a reference to integrate Pig jobs in XD.",5
"Make max-messages-per-poll setting of the file source configurable
The max-messages-per-poll property of the poller used in the file source is not exposed and cannot be configured. I think it has the default value of 1 in this configuration:  https://github.com/spring-projects/spring-xd/blob/master/modules/source/file/config/file.xml#L18  As a result it is not possible to configure the file source to pick all new files available in a single poll.  This is a limitation in fast file ingestion scenarios.",1
"Update XD on YARN docs
The XD on YARN section of the docs needs to be updated with the ""xd-yarn admininfo"" command for detecting the ports used by admin servers.",1
"Disable Batch Job Tests for Kafka Message Bus
At this time Kafka Message bus does not support jobs but we still need to run acceptance tests for streams.  Thus we need to exclude Jobs from the acceptance tests when using Kafka Message Bus. ",3
"Add build support for XD in Windows
As a user, I'd like to build XD in Windows machine so that I can develop, test,  and contributed to OSS.",5
"Add test coverage for Windows in EC2
As a developer, I'd like to run acceptance test coverage in Windows so that I can evaluate XD functionalities.    The scope is to provision Windows image in EC2 and run acceptance test in the environment. Potentially also try to create this as CI build.",3
"Create Spark Streaming example
As a developer, I'd like to build _Spark Streaming_ as data processors in XD so that we can demonstrate some of the capabilities.    *Implement using:*  * Java / Java Lambdas  * Scala",8
"Update copyright message in PDF from 2014 to 2015
As a PM, I'd like to have the copyright message in the reference guide (PDF) updated to include 2015 instead of 2014. ",1
"Upgrade to SI Kafka GA release
As a developer, I'd like to upgrade to Kafka's SI GA release so that I can sync -up with the latest bits.     The scope is to backport Kafka XD changes to SI Kafka and then upgrade to the GA release.",5
"Upgrade to SHDP GA Release
As a developer, I'd like to upgrade to SHDP GA release so that I can sync -up with the latest bits. ",1
"Can't execute query on Hive
Hey Guys,  We are currently trying to connect Hive by spring-xd to create a table.  Unfortunatly we are not able to do it. We are using the attached job configuration (hive.xml) trying to connect by Hive Thrift Client with the following configuration:  <hadoop:hive-client-factory host=""hive_host"" port=""10000"" /> <hadoop:hive-tasklet id=""hive-script"">    <hadoop:script>      USE TESTING;      DROP TABLE IF EXITS testHiveBatchTable;       CREATE TABLE testHiveBatchTable (key int, value string);    </hadoop:script> </hadoop:hive-tasklet>  For Some reason spring XD is not finding the TTransportException class. The full log is in the singlenode_hivequery.log  file  attached. After that we tried uploading all the dependencies to the lib folder of the job, but now we are facing problems with log4j (full log is in singlenode_hivequery2.log attached) and we are unable to deploy the job in any of the two cases. Please,  Could you help us to solve this problem?   Thanks in advance.",3
"XD Requires a CI build for Windows Platform
We need the ability to have bamboo provision a Windows instance on EC2 and launch a XD build.   Capture the results of the XD Build and report back to Bamboo Success or failure. If the build is successful, shutdown the EC2 Windows instance.  Else leave it running so someone can diagnose the problem.",5
"Bump Spring AMQP to 1.4.3
When available",1
"Support rapid creation and deletion of streams
OS: Ubuntu Deployment Admin Server.  1 Container Transport Rabbit  * Using the shell execute the file.  ./bin/shell --cmdfile loop.txt   ** This should run successfully * Rerun the same script ./bin/shell --cmdfile loop.txt ** it states that the stream foo1 is already deployed.  ** Open shell app and destroy foo1 and run a stream list.  No streams will display ** Exit shell and rerun the file.   *** Another stream will fail to create stating  stream already exists.  * If you look at the modules deployed on the container some are still present. * To clear you have to shutdown the cluster and flush the xd directories on Zookeeper. * Note that if I shutdown the container the modules disappear.   ",8
"Add scala support for spark streaming module
As a scala developer, someone could easily deploy the spark streaming module developed using scala.    ",8
"Create a smple to invoke Hive query from XD
As a user, I'd like to refer to Hive sample so that I can use that as a reference to integrate Hive to query and analyze.",2
"Provide more options for the MongoDB Sink
See the SO question on the matter: http://stackoverflow.com/questions/28280206/how-can-i-use-authentication-in-mongo-sink",1
"Add support for Sentinel in Redis Sink
Currently, the Redis sink appears to be unable to write to a Redis instance if it is connected via Sentinel.  Given the following XD Container {{servers.yml}} configuration:    {noformat}  # Redis properties  spring:    redis:  #   port: 6379  #   host: localhost      sentinel:        master: spring-xd        nodes: 10.85.30.133:26379,10.85.30.134:26379,10.85.30.135:26379  {noformat}    a stream of {{time | redis --key=ticktock}} results in the following:    {noformat}  Created JedisPool to master at 10.85.30.130:6379  Caused by: org.springframework.messaging.MessageHandlingException: error occurred in message handler [org.springframework.integration.redis.outbound.RedisStoreWritingMessageHandler#0]; nested exception is org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool  Caused by: org.springframework.data.redis.RedisConnectionFailureException: Cannot get Jedis connection; nested exception is redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool      at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:140)      at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:229)      at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.getConnection(JedisConnectionFactory.java:57)  Caused by: redis.clients.jedis.exceptions.JedisConnectionException: Could not get a resource from the pool      at redis.clients.jedis.JedisPool.getResource(JedisPool.java:84)      at redis.clients.jedis.JedisPool.getResource(JedisPool.java:10)      at org.springframework.data.redis.connection.jedis.JedisConnectionFactory.fetchJedisConnector(JedisConnectionFactory.java:133)  Caused by: redis.clients.jedis.exceptions.JedisConnectionException: java.net.ConnectException: Connection refused      at redis.clients.jedis.Connection.connect(Connection.java:150)      at redis.clients.jedis.BinaryClient.connect(BinaryClient.java:71)      at redis.clients.jedis.BinaryJedis.connect(BinaryJedis.java:1783)      at redis.clients.jedis.JedisFactory.makeObject(JedisFactory.java:65)      at redis.clients.jedis.Connection.connect(Connection.java:144)  {noformat}    The parts that sticks out to me is the line  bq. {{Created JedisPool to master at 10.85.30.130:6379}}    The Sentinels aren't at {{.130}}, that's a Redis and the only way that the {{JedisPool}} could know about that host is to have connected to a Sentinel instance and requested the listing of Redis nodes managed by the Sentinel.  Notably, the Redis instance that the JedisPool connects to is actually responsive.    {noformat}  $: redis-cli -h 10.85.30.130 -p 6379  10.85.30.130:6379> ping  PONG  10.85.30.130:6379>   {noformat}    ",3
"Resolve classloading issues for custom Hadoop based batch jobs
There are several issues making it hard to impossible to create batch jobs that use Pig, Hive, HBase or other technologies supported by Spring for Apache Hadoop project. We need to make the corresponding dependencies available on the Hadoop classpath.",8
"Remove jline from xd-dirt classpath
Currently jline 2.11 gets added via zookeeper dependency, we need to remove this so we can have jline 1.0 fir Pig jobs in the hadoop depndencies    This jline version should remain for xd-shell classpath though",1
"Add dependencies needed for running a Pig job
nan",5
"Add dependencies needed for running a Hive job
nan",3
"Add dependencies needed for running a job using HBase
nan",3
"Document recommended 'ulimit' setting for XD
As a developer, I'd like to refer to wiki so that I can configure machines with recommended _ulimit_ setting for XD's distributed setup.    *Note:*  Recommended _ulimit_ setting is 10K under ""Troubleshooting"" (new) section    *Exception:* (reason to increase _ulimit_)  8:25:52,266 1.1.0.SNAP ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  java.lang.IllegalStateException: java.io.FileNotFoundException: /var/vcap/data/packages/springxd/ee02bd3482eeb620a65862fb54e1f23fcece8022.1-bd  a341640a5de2f922fd3db906ce504b85819c1e/spring-xd-1.1.0.BUILD-SNAPSHOT/xd/config/modules/modules.yml (Too many open files)",1
"http-client Improvement (userDefinedHeaderPrefix)
Currently, you cannot suppress (or change) the {{X-}} prefix on user-defined headers.  See http://stackoverflow.com/questions/28118990/passing-http-request-header-to-restapi-from-springxd-using-http-client-processor/28153291#28153291  Add $\{userDefinedHeaderPrefix\} property.",2
"Message conversion support for spark streaming module
The spark streaming module needs to support inputType (for both processor and sink module) and outputType (for processor module) so that message conversion can happen at the MessageBusReceiver and MessageBusSender.",5
"Set sourceCompatibility to JDK 1.7
Min JDK version for XD 1.1 is 7.  Change the sourceCompatibility to 1.7 but leave targetCompatibility at 1.6.   Changes are also needed in the mdule parent pom and gradle plugins.",1
"Module delete command sporadically fails on windows
When a user executes a module delete on a custom module it sporadically fails with the following exception below at the bottom of the description. Deployment: OS: Windows 8 or Windows Server 2012 R2 Java version Java 8 (build 25.31-b07, mixed mode) XD Deployment type. XD-Singlenode (embedded zookeeper)  Steps to reproduce: 1) build either the rss-feed-source or the payload-conversion samples from the spring-xd-samples 2) start xd-singlenode 3) start shell 4) from the shell execute module upload for the custom module i.e. module upload --file C:\project\spring-xd-samples\payloadconversion\build\libs\payload-conversion-1.0.0.BUILD-SNAPSHOT.jar --name myTupleProcessor --type processor 5) Verify that the module was uploaded by executing module info processor:myTupleProcessor 6) Execute module delete processor:myTupleProcessor  {noformat} 2015-02-18 14:48:43,908 1.1.0.RELEASE ERROR qtp752571350-38 rest.RestControllerA dvice - Caught exception while handling a request org.springframework.xd.dirt.module.DependencyException: Cannot delete module pro cessor:myTupleProcessor because it is used by [stream:test]         at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod uleDefinitionService.java:116)         at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont roller.java:155)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl. java:62)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAcces sorImpl.java:43)         at java.lang.reflect.Method.invoke(Method.java:483)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvok e(InvocableHandlerMethod.java:221)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeF orRequest(InvocableHandlerMethod.java:137)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt er.handle(AbstractHandlerMethodAdapter.java:85)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch erServlet.java:943)         at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche rServlet.java:877)         at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame workServlet.java:966)         at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe rvlet.java:890)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer vlet.java:842)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684 )         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1496)         at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf iguration.java:291)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna l(HiddenHttpMethodFilter.java:77)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter nal(HttpPutFormContentFilter.java:87)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter Internal(WebRequestTraceFilter.java:100)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi lterChainProxy.java:186)         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai nProxy.java:160)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java :499)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:137)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav a:557)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl er.java:231)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl er.java:1086)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java: 428)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle r.java:193)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle r.java:1020)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:135)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper .java:116)         at org.eclipse.jetty.server.Server.handle(Server.java:370)         at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac tHttpConnection.java:494)         at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra ctHttpConnection.java:971)         at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header Complete(AbstractHttpConnection.java:1033)         at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)         at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)          at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti on.java:82)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn dPoint.java:667)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd Point.java:52)         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo l.java:608)         at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool .java:543)         at java.lang.Thread.run(Thread.java:745) 2015-02-18 14:50:38,191 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@14b69ddf moduleName = 'http', modu leLabel = 'http', group = 'test', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map[[empty]], children = list[[em pty]]] 2015-02-18 14:50:38,380 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@7c2cd32 moduleName = 'myTupleProce ssor', moduleLabel = 'myTupleProcessor', group = 'test', sourceChannelName = [nu ll], sinkChannelName = [null], index = 1, type = processor, parameters = map['in putType' -> 'application/x-xd-tuple'], children = list[[empty]]] 2015-02-18 14:50:38,470 1.1.0.RELEASE  INFO main-EventThread server.DeploymentLi stener - Undeploying module [ModuleDescriptor@30ba1084 moduleName = 'log', modul eLabel = 'log', group = 'test', sourceChannelName = [null], sinkChannelName = [n ull], index = 2, type = sink, parameters = map[[empty]], children = list[[empty] ]] 2015-02-18 14:50:38,527 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.Initia lDeploymentListener - Path cache event: path=/deployments/streams/test, type=CHI LD_REMOVED 2015-02-18 14:50:38,528 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.source.http.1, type=CHILD_REMOVED 2015-02-18 14:50:38,530 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.processor.myTupleProcessor.1, type=CHILD_ REMOVED 2015-02-18 14:50:38,532 1.1.0.RELEASE  INFO DeploymentsPathChildrenCache-0 serve r.DeploymentListener - Path cache event: path=/deployments/modules/allocated/f66 35afd-7351-4ac3-baa3-3b98e74a38ca/test.sink.log.1, type=CHILD_REMOVED 2015-02-18 14:50:41,486 1.1.0.RELEASE  INFO LeaderSelector-0 server.DeploymentSu pervisor - Leadership canceled due to thread interrupt 2015-02-18 14:50:41,592 1.1.0.RELEASE  WARN NIOServerCxn.Factory:0.0.0.0/0.0.0.0 :5156 server.NIOServerCnxn - caught end of stream exception EndOfStreamException: Unable to read additional data from client sessionid 0x14b 9d2656c30000, likely client has closed socket         at org.apache.zookeeper.server.NIOServerCnxn.doIO(NIOServerCnxn.java:228 )         at org.apache.zookeeper.server.NIOServerCnxnFactory.run(NIOServerCnxnFac tory.java:208)         at java.lang.Thread.run(Thread.java:745) {noformat} ",3
"Update log4j properties to include DATE in the logs
As a user, I'd like to see the 'date' in logs so that I can troubleshoot issues that had occurred on a specific day and time.    Property that needs adjusted:  https://github.com/spring-projects/spring-xd/blob/master/config/xd-container-logger.properties#L11",1
"Fix #jsonPath evaluation following JsonPath version upgrade
nan",1
"Fix mapreduce job submission on Cloudera CDH5
Submitting jobs that submit YARN MR tasks on Cloudera 5.3.0    - job fails when submitting the YARN app         java.lang.NoClassDefFoundError: com/google/common/io/LimitInputStream    - this is from Guava and that class was removed starting with v. 15.0    - I can get around this by including guava-14.0.1.jar in lib/cdh5 (not sure if this breaks something else)  ",1
"Fix Sqoop job to allow for setting yarn.application.classpath
Running Sqoop job against non Apache Hadoop installation    - YARN app fails         Error: Could not find or load main class org.apache.hadoop.mapreduce.v2.app.MRAppMaster    - Need to be able to set yarn.application.classpath for any distro that doesn't use the Hadoop defult classpath (Cloudera, Hortonworks, Pivotal HD)",3
"Restrict entry filter in loading module artifacts
see https://github.com/spring-projects/spring-boot/issues/2454",1
"Upgrade to the latest Gradle 2.x Release
Gradle 2.x is required for the latest Sonar version (sonar.spring.io)    We may need to wait for a fix in Groovy itself (2.4.1) - Please see the following links for details:    * http://forums.gradle.org/gradle/topics/after_upgrade_gradle_to_2_0_version_the_maven_pom_not_support_build_property    * http://jira.codehaus.org/browse/GROOVY-7023    ",5
"Run Kafka tests with Kafka Server as separate process
As a developer, I'd like to run Kafka tests with Kafka Server as a separate running process so that I can improve build experience. ",3
"Spring XD module parent should use dependencies.properties for versioning
As a developer, I'd like the {{publish-maven.gradle}} script to use values for dependencies (e.g. Spring Boot and {{hadoop-common}}) from our central dependency list (in this case {{dependencies.properties}}) so that I don't have to update them manually anymore.",2
"Better approach to handle module execution framework
Currently, when the module doesn't need to go through message bus binding, the Module interface provides 'shouldBind()` method to return false.  The shouldBind() is being used in other place where ModuleTypeConversionPlugin is excluded for spark streaming modules.  We need a better approach to refactor this. Also, see the discussion here: https://github.com/spring-projects/spring-xd/pull/1438#discussion_r24150937",8
"Downgrade reactor based modules to reactor 1.x GA
Can revert part of the commit that went into upgrading to reactor 2.0    https://github.com/spring-projects/spring-xd/pull/1342/files  ",1
"Make Sqoop job and MapReduce samples work with Hortonworks HDP 2.2 single-node cluster 
Having problems testing against the Sandbox 2.2. We need to set the following properties:    yarn.application.classpath  yarn.app.mapreduce.am.command-opts  mapreduce.application.classpath  mapreduce.application.framework.path    ",5
"Kafka Tests should use an external broker
As a developer, I want to have to run Kafka tests on an external broker, so that I reduce the footprint of the build process. ",2
"Review and fix Sonar violations
As a developer, I'd like to review the current sonar violations so that I can fix the relevant and update the irrelevant ones as invalid.",3
"Remove spark and hadoop dependencies from custom module classpath
remove spark and hadoop requirements from spring-xd-module-parent and gradle module plugin",2
"Create Spark MLLib example
As a developer, I'd like to build _Spark_ batch job sample so that we can demonstrate some of the distributed data computation capabilities.",8
"Create Kafka data pipeline example
As a developer, I'd like to build data pipeline using _Kafka_ as as message bus in XD so that we can demonstrate some of the capabilities.  *Use case to consider:* * Log aggregation and analysis * Lambda architecture ** how to avoid code duplication ** how to eliminate tight coupling of business logic ** how Kafka can be used for reliable reprocessing  ",8
"Create Sqoop example
As a developer, I'd like to build batch sample using _Sqoop_ so that we can demonstrate some of the capabilities.  *Use cases to consider:* * JDBC to HDFS * HDFS to JDBC ",8
"Move documentation from wiki to main repo
As a consequence,   * change gradle script regarding generation of documentation  * remove pushGeneratedDocs task, etc  * remove link rewriting that is no longer needed ",8
"Add ability to add Custom Metrics/Controllers To Admin Context 
See original report here https://github.com/spring-projects/spring-xd/issues/1300  ""I've created a module with a custom Metric, Handler and Repository patterned after the AggregateCounter but then it appears that there doesn't seem to be a way to add anything to the Admin Context.  The diagram at https://github.com/spring-projects/spring-xd/wiki/Extending-XD shows the Plugin Context as a sibling to the Admin Context which seems to verify my fears.  It would be convenient to be able to add custom Metrics/Controllers/Repositories into the Admin Context so that they can be accessed through the same REST api as the other Metrics.""",5
"Improve Redis Bus Error Log Entry
{code}  logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'"",										context.getLastThrowable());  {code}    Should be:    {code}  logger.error(""Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:"" + name + '"",										context.getLastThrowable());  {code}    So the actual name is logged.  ",1
"Support creation of spring Message at spark processor implementation
Currently, when the spark streaming ModuleExecutor iterate over the RDD partitions, it converts all the items to spring Message. If the item itself is of Message type (the conversion happened at the spark streaming processor implementation), then this is not needed. We need to add a check to see if the item is of Message type.",1
"Spark streaming Module executor use getMessageBuilderFactory(beanFactory)
We need to use getMessageBuilderFactory(beanFactory) to initialize MessageBuilder in Spark Streaming module executor. Please see the discussion: https://github.com/spring-projects/spring-xd/pull/1454/files#r24367825 , ",2
"Investigate root cause of Spring XML parsing failures
The error below appears to be a concurrency issue related to multiple classloaders loading the same spring XML resource.  The root cause needs further investigation, but it causes intermittent test failures in JobCommandsTests.  see https://build.spring.io/browse/XD-JDK8-1375  java.lang.AssertionError: java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false, result=null, exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml]; nested exception is java.lang.NullPointerException: Inflater has been closed ] java.lang.AssertionError: Failure.  CommandResult = CommandResult [success=false, result=null, exception=org.springframework.xd.rest.client.impl.SpringXDException: Unexpected exception parsing XML document from file [/data/bamboo-home/xml-data/build-dir/XD-JDK8-JOB1/spring-xd-shell/build/resources/test/spring-xd/xd/modules/job/jobWithParameters/config/jobWithParameters.xml]; nested exception is java.lang.NullPointerException: Inflater has been closed ] ",5
"Kafka Tests shouldn't assume offset 0 
In `org.springframework.xd.dirt.stream.KafkaSingleNodeStreamDeploymentIntegrationTests#verifyOnDemandQueues`, when testing the queue partitions for content, the read is assumed to start at offset 0.    This is incorrect, because the topics may exist already, especially in a CI environment",1
"CI Environment Needs test resources updated to latest versions
Update Hadoop, Spark, Mongo, gemfire, and ubuntu to latest versions for both CI  and Utility instances.    ",3
"Embed local message bus in DIRT as default for singlenode
Currently all message bus implementations are removed from the runtime classpath and loaded on demand from the file system according to the transport setting. Custom module projects that include in container testing must install messagebus-local on the local file system. This is currently configured as a task for module build scripts. This is also a dependency for testing in the IDE and developers need to execute the build task or configure the messagebus manually. Embedding the local MB for the singlenode application (local is not a valid transport for distributed) eliminates this step.",2
"Replicate Storm examples in XD
As a field engineer, I'd like to have a comparison of Storm examples in Spring XD so that it is easy to relate from implementation standpoint. ",8
"Replicate Spark Streaming examples in XD
As a field engineer, I'd like to have a comparison of Spark Streaming examples in Spring XD so that it is easy to relate from implementation standpoint.  ",8
"Add Smart Grid demo to XD samples repo
As a PM, I'd like to have the Smart Grid demo (from s1-2014) ported into Spring XD samples repo.",8
"Create a Batch example to demonstrate JDBC->HDFS
As a developer, I'd like to create a example to demonstrate JDBC to HDFS data movement.",8
"Add nameExpression Property to File Sink
As a stream definer, when defining a stream ending with a file sink, I would like to have more flexibility for naming the file.    Add an alternative {{--nameExpression}} option, allowing complete control over the {{finename-generator-expression}} attribute.    See: http://stackoverflow.com/questions/28466477/issue-with-file-sink-and-filename-expression/28467069#28467069",1
"Add a separate --clean 'Admin' command to clean-up queues/topics
As a user, I'd like to clean up message bus resources associated with the stream so that when the stream is destroyed so does the coupled queues/topics.",3
"Invoke Rabbit REST-API to clean-up resources
As a user, I'd like to clean-up stale queues/topics associated with the stream so when the stream gets destroyed I can clean-up resources. ",3
"Frequent connection pool errors with multi-partitioned jdbchdfs jobs
I'm running a jdbchdfs job with 8 partitions and 2 containers. Some steps complete ok while some (3-4 on average) fail with a connection pool error (see below). This happens with a decent size table (1.8M rows).    I tried two different databases - Oracle 11g on a separate server and MySQL running locally where the XD containers where running. Same pattern with both databases.    {code}  2015-02-13 12:21:33,436 1.1.0.RELEASE ERROR inbound.files3.0-redis:queue-inbound-channel-adapter1 step.AbstractStep - Encountered an error executing step step1 in job files3  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'scopedTarget.itemReader' defined in file [/home/trisberg/Test/spring-xd-1.1.0.RELEASE/xd/modules/job/jdbchdfs/config/jdbchdfs.xml]: Invocation of init method failed; nested exception is org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$2.getObject(AbstractBeanFactory.java:342)    org.springframework.batch.core.scope.StepScope.get(StepScope.java:110)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:337)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.aop.target.SimpleBeanTargetSource.getTarget(SimpleBeanTargetSource.java:35)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:187)    com.sun.proxy.$Proxy90.open(Unknown Source)    org.springframework.batch.item.support.CompositeItemStream.open(CompositeItemStream.java:96)    org.springframework.batch.core.step.tasklet.TaskletStep.open(TaskletStep.java:310)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:195)    org.springframework.batch.integration.partition.StepExecutionRequestHandler.handle(StepExecutionRequestHandler.java:64)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.expression.spel.support.ReflectiveMethodExecutor.execute(ReflectiveMethodExecutor.java:112)    org.springframework.expression.spel.ast.MethodReference.getValueInternal(MethodReference.java:102)    org.springframework.expression.spel.ast.MethodReference.access$000(MethodReference.java:49)    org.springframework.expression.spel.ast.MethodReference$MethodValueRef.getValue(MethodReference.java:342)    org.springframework.expression.spel.ast.CompoundExpression.getValueInternal(CompoundExpression.java:88)    org.springframework.expression.spel.ast.SpelNodeImpl.getTypedValue(SpelNodeImpl.java:131)    org.springframework.expression.spel.standard.SpelExpression.getValue(SpelExpression.java:330)    org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:164)    org.springframework.integration.util.MessagingMethodInvokerHelper.processInternal(MessagingMethodInvokerHelper.java:276)    org.springframework.integration.util.MessagingMethodInvokerHelper.process(MessagingMethodInvokerHelper.java:142)    org.springframework.integration.handler.MethodInvokingMessageProcessor.processMessage(MethodInvokingMessageProcessor.java:75)    org.springframework.integration.handler.ServiceActivatingHandler.handleRequestMessage(ServiceActivatingHandler.java:71)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)    org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy94.handleMessage(Unknown Source)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    sun.reflect.GeneratedMethodAccessor69.invoke(Unknown Source)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)    org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)    org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)    org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)    org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)    org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)    org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)    com.sun.proxy.$Proxy91.send(Unknown Source)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)    org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)    org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.jdbc.support.MetaDataAccessException: Could not get Connection for extracting meta data; nested exception is org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:302)    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:329)    org.springframework.batch.support.DatabaseType.fromMetaData(DatabaseType.java:95)    org.springframework.xd.jdbc.NamedColumnJdbcItemReaderFactory.afterPropertiesSet(NamedColumnJdbcItemReaderFactory.java:101)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 90 more  Caused by: org.springframework.jdbc.CannotGetJdbcConnectionException: Could not get JDBC Connection; nested exception is java.sql.SQLException: Failed to validate a newly established connection.    org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:80)    org.springframework.jdbc.support.JdbcUtils.extractDatabaseMetaData(JdbcUtils.java:289)  	... 95 more  Caused by: java.sql.SQLException: Failed to validate a newly established connection.    org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:802)    org.apache.tomcat.jdbc.pool.ConnectionPool.borrowConnection(ConnectionPool.java:617)    org.apache.tomcat.jdbc.pool.ConnectionPool.getConnection(ConnectionPool.java:186)    org.apache.tomcat.jdbc.pool.DataSourceProxy.getConnection(DataSourceProxy.java:127)    org.springframework.jdbc.datasource.DataSourceUtils.doGetConnection(DataSourceUtils.java:111)    org.springframework.jdbc.datasource.DataSourceUtils.getConnection(DataSourceUtils.java:77)  	... 96 more  {code}",5
"Remove requirement for executionId to display step execution in shell
When viewing a job's step execution via the shell, the user is required to provide both the job execution id and the step execution id.  Since the job repository is backed by a database and the step execution id is unique across jobs, the step execution id should be enough.",2
"Partitioned job throws: java.lang.RuntimeException: Could not serialize lambda
Running a partitioned jdbchdfs job with 12 partitions and 3 xd-containers. Some steps fail with the jdbc connection pool exception XD-2720. I also sometimes see a serialization exception. This results in the partitioner never getting the status for some of the steps, so it keeps running until it times out even though all steps are either complete of failed.    {code}  2015-02-13 13:18:36,294 1.1.0.RELEASE ERROR inbound.files4.0-redis:queue-inbound-channel-adapter1 redis.RedisMessageBus$1 - Failed to deliver message; retries exhausted; message sent to queue 'ERRORS:name'  org.springframework.messaging.MessageHandlingException: error occurred in message handler [files4.0.bridge.handler]; nested exception is com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda  Serialization trace:  stepExecutions (org.springframework.batch.core.JobExecution)  jobExecution (org.springframework.batch.core.StepExecution)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:84)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:267)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1$1.doWithRetry(RedisMessageBus.java:263)    org.springframework.retry.support.RetryTemplate.doExecute(RetryTemplate.java:263)    org.springframework.retry.support.RetryTemplate.execute(RetryTemplate.java:168)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$1.doSend(RedisMessageBus.java:263)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.popMessageAndSend(RedisQueueMessageDrivenEndpoint.java:220)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint.access$300(RedisQueueMessageDrivenEndpoint.java:50)    org.springframework.integration.redis.inbound.RedisQueueMessageDrivenEndpoint$ListenerTask.run(RedisQueueMessageDrivenEndpoint.java:314)    org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)    java.lang.Thread.run(Thread.java:745)  Caused by: com.esotericsoftware.kryo.KryoException: java.lang.RuntimeException: Could not serialize lambda  Serialization trace:  stepExecutions (org.springframework.batch.core.JobExecution)  jobExecution (org.springframework.batch.core.StepExecution)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:125)    com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)    com.esotericsoftware.kryo.serializers.FieldSerializer.read(FieldSerializer.java:528)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:682)    org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.doDeserialize(PojoCodec.java:41)    org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec$1.execute(AbstractKryoMultiTypeCodec.java:63)    com.esotericsoftware.kryo.pool.KryoPoolQueueImpl.run(KryoPoolQueueImpl.java:43)    org.springframework.xd.dirt.integration.bus.serializer.kryo.AbstractKryoMultiTypeCodec.deserialize(AbstractKryoMultiTypeCodec.java:60)    org.springframework.xd.dirt.integration.bus.serializer.kryo.PojoCodec.deserialize(PojoCodec.java:30)    org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:72)    org.springframework.xd.dirt.integration.bus.serializer.CompositeCodec.deserialize(CompositeCodec.java:78)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:588)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayload(MessageBusSupport.java:573)    org.springframework.xd.dirt.integration.bus.MessageBusSupport.deserializePayloadIfNecessary(MessageBusSupport.java:556)    org.springframework.xd.dirt.integration.redis.RedisMessageBus.access$1000(RedisMessageBus.java:68)    org.springframework.xd.dirt.integration.redis.RedisMessageBus$ReceivingHandler.handleRequestMessage(RedisMessageBus.java:465)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:99)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)  	... 21 more  Caused by: java.lang.RuntimeException: Could not serialize lambda    com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:52)    com.esotericsoftware.kryo.Kryo.readClassAndObject(Kryo.java:786)    com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:116)    com.esotericsoftware.kryo.serializers.CollectionSerializer.read(CollectionSerializer.java:22)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:704)    com.esotericsoftware.kryo.serializers.ObjectField.read(ObjectField.java:106)  	... 40 more  Caused by: java.lang.ArrayIndexOutOfBoundsException: -2    java.util.ArrayList.elementData(ArrayList.java:418)    java.util.ArrayList.get(ArrayList.java:431)    com.esotericsoftware.kryo.util.MapReferenceResolver.getReadObject(MapReferenceResolver.java:42)    com.esotericsoftware.kryo.Kryo.readReferenceOrNull(Kryo.java:830)    com.esotericsoftware.kryo.Kryo.readObject(Kryo.java:680)    com.esotericsoftware.kryo.serializers.ClosureSerializer.read(ClosureSerializer.java:49)  	... 45 more  {code} ",5
"Increase the partitionResultsTimeout
The partitionResultsTimeout is set to 300000 as default (5min). This is way to short for long running steps. We should increase this default.",1
"Add support to edit deployed/undeployed stream
As a user, I'd like to have the option of editing the deployed/undeployed stream so that I don't have to destroy to just change any deployment property.",8
"http does not report failure to bind to port
Stumbled upon this while having Hadoop daemons running, but simple way to repoduce:  {noformat} nc -lp 9000  stream create foo --definition ""http | log"" --deploy ==> all seems ok  http post --data hello ==> Error 500, rightfully so {noformat}",3
"Allow deletion of all metrics of a kind
To be added in AbstractMetricsController, as well as the various shell commands (""counter all delete"", etc...)",5
"Spark streaming integration with kafka message does not respect offsetStoreTopic config option
The property ""xd.messagebus.kafka.offsetStoreTopic"" was added to Kafka message bus which is not updated to Spark streaming message bus properties that will be transferred to spark cluster for streaming module deployment.   We also need a better approach to re-use the message bus properties so that we don't have to update the properties in Connection Property Names.",3
"Spark streaming processor module: Dispatcher has no subscribers
The spark streaming processor module emits the following exception when there are more messages in the RDD partitions:    015-02-17 12:45:02,026 1.2.0.SNAP ERROR Executor task launch worker-2 executor.Executor - Exception in task 0.0 in stage 56.0 (TID 142)  org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)    org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)    org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)    org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)    org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)    org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)    org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)    org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)    org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)    org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)    org.apache.spark.scheduler.Task.run(Task.scala:56)    org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 17 more  2015-02-17 12:45:02,032 1.2.0.SNAP  WARN task-result-getter-1 scheduler.TaskSetManager - Lost task 0.0 in stage 56.0 (TID 142, localhost): org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'output'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.xd.dirt.plugins.spark.streaming.MessageBusSender.send(MessageBusSender.java:105)    org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:80)    org.springframework.xd.spark.streaming.java.ModuleExecutor$1$1.call(ModuleExecutor.java:55)    org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)    org.apache.spark.api.java.JavaRDDLike$$anonfun$foreachPartition$1.apply(JavaRDDLike.scala:195)    org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)    org.apache.spark.rdd.RDD$$anonfun$foreachPartition$1.apply(RDD.scala:790)    org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)    org.apache.spark.SparkContext$$anonfun$runJob$4.apply(SparkContext.scala:1353)    org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:61)    org.apache.spark.scheduler.Task.run(Task.scala:56)    org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:200)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 17 more  ",3
"Update payload-conversion demo to latest module spec
Upload payload conversion demo such that a user can use the module upload feature against the sample.",3
"Add support to include deployment manifest from file
As a user, I'd like to include the deployment manifest from the file so that I don't have spend time typing as ""inline properties"".",3
"Temp files for stream create not being cleaned
During testing for Spring XD for PivotalCF we create, deploy, use, undeploy and destroy many streams. Each stream generates {{tmp}} directories (I think 2, one for source, one for sink) in the xd-admin VM's {{/tmp}} directory, e.g.    {noformat}  dummy-module4635787551932601017sinkredis  dummy-module252960009195893204sourcehttp  {noformat}    These {{tmp}} directories are not being cleared up, so our system has hit the inode limit of 32768 files for a volume:    {noformat}  Filesystem     Inodes IUsed  IFree IUse% Mounted on  /dev/loop0      32768 32768      0  100% /tmp  {noformat}    This causes a Java {{IOException}}, the immediately relevant part of which appears to be:    {noformat}  [Caught] exception while handling a request  Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  [java.lang.RuntimeException] java.io.IOException: No space left on device  Feb 18 09:06:06 10.85.30.142-2 xd-admin-partition-default_az_guid-0:  []    at org.springframework.xd.module.ModuleDefinitions.dummy(ModuleDefinitions.java:81)  {noformat}    This causes the test system to fail entirely.",3
"Move $XD_HOME/modules/processor/scripts out of the way
Since the refactoring of the module registry that does not ""look inside"" a module, it can't know that the scripts directory is not a module.  Everything that is a direct child of source, processor, sink, job should be a module archive. Everything else supporting that should be moved out, e.g. in modules/common",2
"Custom Modules can't be found wen using xd.customModule.home on windows 
XD can not find the custom modules directory after Setting the xd.customModule.home in the windows environment   Deployment * xd-singlenode (embedded zookeeper) * Java 8 * Windows 8 or Windows Server 2012 r2  Steps to reproduce:  1) Start xd-singlenode 2) Start Shell 3) Build either the payload-conversion or rss-feed-source from the spring-xd-samples 4) use the shell to execute a module upload for the custom module (rss-feed-source, payload-conversion) 5) verify it uploaded xd:>module info processor:myTupleProcessor 6) stop xd single node 7) From the command line execute set xd.customModule.home=[path to your custom modules] i.e. C:\project\spring-xd-1.1.0.RELEASE\xd\custom-modules 8) restart xd-singlenode 9) execute module info processor:myTupleProcessor 10) you will get the following error {noformat} Command failed org.springframework.xd.rest.client.impl.SpringXDException: Could not find module with name 'myTupleProcessor' and type 'processor' {noformat}",3
"Create first-cut on reference architectures for domain specific use-cases
As a field engineer, I'd like to have reference architectures built on Spring XD so that I can use that as reference building POCs. The scope is to get the raw domain specific ideas captured as first step.  ",8
"Make local message bus properties configurable
Currently, the local message bus has couple of properties ""queueSize"" and ""polling"". But these properties can not be configurable via servers.yml.  Also, the property prefix needs to align with other message bus properties.",1
"Revert XD specific support for JsonPath 1.2
Thanks to INT-3624, we don't need our specific class anymore",1
"Add support for global wiretap config
As a user, I'd like to have an optional _trace_ as inline deployment properties for _stream_ so that I can declare which _module_ in the stream needs to be traced for logging or notifications. This gives the flexibility to track the stage progress between individual modules.  *Example:*  {code:xml} xd:> stream create foo ""http | log""  xd:> stream deploy foo --properties ""module.http.trace,module.log.trace""  (or)  xd:> stream deploy foo --properties ""module.*.trace"" {code}  Wildcard wiretap config: http://docs.spring.io/spring-integration/reference/html/messaging-channels-section.html#channel-global-wiretap",8
"Add arbitrary ""side channels"" to track module progress
As a user, I'd like to have an optional  arbitrary ""side channels"" created so that when creating a module channels other than the primary stream channels (input, output) could be added to the bus (i.e. creating a tap channel *within* a flow). The optional ""side channels"" can be used to trace/track module progress.",8
"Add a Sqoop example
nan",3
"HDFS StoreMessageHandlers are not very resilient
There are cases where hdfs-outbound-channel-adapter (from spring-xd-hadoop module) will keep a broken datawriter's stream open.  For example if the underlying HDFS stream throws a RemoteException (ie. some hadoop error occurred) there's no mitigation. Subsequent writes will always fail.  The MessageHandler could potentially try to close and re-open the stream or trigger a rollover strategy to occur (creating a new stream).",10
"Redis sink should default to using spring.redis configuration in servers.yml
The configuration for the redis sink must be provided for explicitly instead of falling back to values defined in servers.yml.  The default behavior configuration should be address in a manner consistent with the default behavior of module config for rabbit source/sink, jdbc sink....",1
"Prep for DEBS Challenge
As a developer, I'd like to study the taxi trips based on a stream of trip reports from New York City so that I can evaluate event-based systems in the context of real-time analytics using Spring XD.    [Challenge Details|http://www.debs2015.org/call-grand-challenge.html]",8
"Improve acceptance testing coverage
The scope is to address the sub-tasks linked with this story.  ",5
"Placeholder for Spring XD Lab
nan",8
"Spark Streaming Acceptance Tests
nan",5
"JDBC Source Acceptance Tests
nan",3
"Document test scenarios for performance testing
As a developer, I'd like to benchmark Rabbit performance so that I can use the results as reference to setup XD cluster.",8
"Implement Reliable spark streaming receiver 
The spark streaming message bus receiver isn't reliable yet. The receiver needs to handle data loss in case of worker node that has it running.    We currently handle the driver failure automatically by re-deploying spark streaming module. But, this is about the data loss when the worker node dies.    Please see the documents here:    https://databricks.com/blog/2015/01/15/improved-driver-fault-tolerance-and-zero-data-loss-in-spark-streaming.html    http://spark.apache.org/docs/latest/streaming-custom-receivers.html",3
"Placeholder for Lattice/Diego POC #1
nan",8
"Placeholder for Lattice/Diego POC #2
nan",8
"JDBC | FILE throws ConverterNotFoundException when split=0
I am trying to create a simple JDBC|FILE stream with Split=0 at the jdbc source. following is the DSL  stream create --name test --definition ""jdbc --fixedDelay=5 --split=0 --query='select * from top_movie_companies'|file --dir=/tmp --suffix=xd --name=test"" --deploy  It throws  org.springframework.core.convert.ConverterNotFoundException: No converter found capable of converting from type java.util.ArrayList<?> to type java.lang.String   org.springframework.integration.util.AbstractExpressionEvaluator.evaluateExpression(AbstractExpressionEvaluator.java:138)  It works fine when I use LOG sink instead of FILE.   I am assuming that if LOG sink works with JDBC then file should be similar. The converter should be registered out of the box.  It could be something basic I am missing as I'm relatively new to XD.",1
"SqoopTasklet not using hadoop configuration
Hey Guys,    I'm trying to use a SqoopTasklet but for some reason it is not getting the hadoop configuration. In the attached sqoop job configuration using the sqooprunner class directly works without problems but the SqoopTasklet is not getting the correct configuration throwing kerberos authentication problems (see singlenode.log).  Could please you guys help me to solve this problem?    Thanks in advance.  Regards,",8
"Allow to install new XD modules from maven coordinates
Currently new modules can be installed via the module upload command, but for this to work one needs to  build the artifacts beforehand.    It would be great to have support for installing new XD modules from maven coordinates (e.g. from a public or   controlled maven repository).  With this one would make it easy to consume community modules without much hassle.    This could also serve as some kind of starting ground for some ""special solution packages"" that provides support  for, c.f. natural language processing (via a bunch of jars that contain the modules for language detection, entity detection, sentiment analysis, topic clustering) etc. that could be consumed via some kind of .bom (bill of materials) dependency like:    module install ""pivotal:toolkits:nlp""",8
"ClassLoading interaction issue between MessageBus and modules
See discussion at http://stackoverflow.com/questions/28551506/spring-xd-jms-message-bus-with-jms-sink",8
"Scala processor module executor trims messages
How to reproduce:    1. Run xd-singlenode (for which setting the Spark master URL to 'local' is a requirement). Use more than 1 worker thread. e.g. {{local[4]}}    2. Deploy the word-count example    3. Create a stream  {{stream create spark-streaming-word-count --definition ""http | word-count | log"" --deploy}}    4. Send data  {{xd:>http post --data ""a b c d e f g""}}    {{xd:>http post --data ""a b c""}}    5.Observe the result    2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (e,1)  2015-02-24 15:12:46,018 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (d,1)  2015-02-24 15:12:46,019 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1)  2015-02-24 15:12:46,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (g,1)  2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-1 sink.spark-streaming-word-count - (a,1)  2015-02-24 15:13:40,020 1.2.0.SNAP  INFO Executor task launch worker-2 sink.spark-streaming-word-count - (b,1)  2015-02-24 15:13:40,021 1.2.0.SNAP  INFO Executor task launch worker-3 sink.spark-streaming-word-count - (c,1)    (the last three results are coming from the second invocation))    Note: there seems to be a correlation between the number of values emitted and the number of workers, as, in all the attempts, there aren't more values emitted than the number of workers.",5
"Large number of required options in jdbc sink definition
I'd like to use the following command to define a stream in our Spring XD for PivotalCF test environment:    {code}  stream create --name test --definition ""http --port=9999 | jdbc --username=spring-xd --password=spring-xd --driverClassName=org.postgresql.Driver --url=jdbc:postgresql://1.2.3.4:5432/spring-xd""  {code}    I have to add the following options to the definition to make it work (otherwise I get exceptions and a failed deploy):    {code}  -validationQuery='' --validatorClassName='#{null}' --connectionProperties='' --initSQL='' --jdbcInterceptors='' --initializerScript=''   {code}    Given that they're empty anyway it seems like some or all of these should not be necessary.    _Notes_  * The validatorClassName cannot be '' like the others, it needs the null.  * Without initSQL='' stream creation fails because it can't find init_db.sql (a file I don't have in my environment), even though it won't be run anyway.",5
"Return description for each module in the JSON response
As a developer, I'd like to have the high-level description for each of the modules so that I can use the description (presumably what is captured in javadoc for the module definition) to understand the purpose of the module itself.  ",3
"Add module description to the JSON response
As  a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition). ",3
"LocalMessageBus PubSub Needs a Bounded Task Exectutor
Since 1.1, {{PubSub}} channels in the {{LocalMessageBus}} run on a {{CachedThreadPoolExecutor}}.    For high volume environments, where back-pressure might occur on a {{topic:}} thread we could overwhelm the system with threads.    Add a local bus configuration to limit the thread pool used for PubSubs and queue tasks where there are no threads available.    It would be a bus-wide setting.",1
"""http post"" in CLI gives IllegalArgumentException
In xd-shell the command: {code} http post {code} gives the following output: {code} Command failed java.lang.IllegalArgumentException: One of 'file' or 'data' must be set {code}  I believe the UI should suppress the exception (just removing ' java.lang.IllegalArgumentException') would suffice).",1
"Register only known classes with Kryo in PojoCodec
Currently PojoCodec calls kryo.register(Class<?> type) on every ser/deser invocation. This fails with 1.1 because instances are pooled and a different instance may be used to serialize and deserialize.  See https://github.com/EsotericSoftware/kryo#registration.  The fix is to not register classes on the fly. Classes serialized by PojoCodec will not be registered by default. This will work but is less efficient. XD should provide an easy way to register types known to be serialized on the MessageBus (passed between modules)",5
"Update RHEL/CentOS yum/rpm installation instructions
As a build manager, I'd like to have Spring XD RPMs published in spring.io repository so that users can directly download the bits without having to go through appsuite repo or the EULA.     *Location for 1.1.0 RELEASE:*  http://repo.spring.io/libs-release-local/org/springframework/xd/spring-xd/1.1.0.RELEASE/",2
"Create RabbitMQ environment and record baseline results.
# Setup Environment   ## Create 1.1.0 XD cluster with 1 admin and 3 containers  ## Create 3 node RabbitMQ Cluster  ## Associate Each XD Container to a single Rabbit Node.  ## All EC2 instances in the same placement group  # Execute the following streams  {noformat}  stream create q1 --definition ""load-generator --messageCount=2000000 > queue:q1""   stream deploy q1 --properties ""module.load-generator.criteria=groups.contains('one')""  stream create q2 --definition ""load-generator --messageCount=4000000 > queue:q2""   stream deploy q2 --properties ""module.load-generator.criteria=groups.contains('two')""  stream create q3 --definition ""load-generator --messageCount=4000000 > queue:q3""   stream deploy q3 --properties ""module.load-generator.criteria=groups.contains('three')""  stream create q4 --definition ""load-generator --messageCount=4000000 > queue:q4""   stream deploy q4 --properties ""module.load-generator.criteria=groups.contains('one')""  stream create q5 --definition ""load-generator --messageCount=4000000 > queue:q5""   stream deploy q5 --properties ""module.load-generator.criteria=groups.contains('two')""  stream create q6 --definition ""load-generator --messageCount=4000000 > queue:q6""   stream deploy q6 --properties ""module.load-generator.criteria=groups.contains('three')""  {noformat}  # use the following rabbitmq perf tests to retrieve benchmark rates  {noformat}  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q1 -p -x 0 -y 2 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q1.txt &  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q2 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q2.txt &  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q3 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q3.txt &  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q4 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx1.compute-1.amazonaws.com >q4.txt &  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q5 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx2.compute-1.amazonaws.com >q5.txt &  ./runjava.sh com.rabbitmq.examples.PerfTest -u xdbus.queue:q6 -p -x 0 -y 1 -q 500 -z 120 -h amqp://xx3.compute-1.amazonaws.com >q6.txt &  {noformat}  # Reach out to SME's to identify proper configuration",3
"Fix failing KafkaSingleNodeStreamDeploymentIntegrationTests.verifyOnDemandQueues()
Test fails in CI when the topic used by the test had its initial segment removed during cleanup.",1
"Spike: Research Zookeeper-based mechanism for partitioned job management
The current implementation of partitioned job management is entirely based on message exchange over the message bus, in a request reply scenario.  This creates challenges when it comes to using certain types of transports, as well as acknowledging crashes.   To that effect, the option of using a different partitioned job coordination strategy, that relies on a distributed computing coordination mechanism such as ZooKeeper should be investigated. ",8
"Add metadata for description of a module (itself)
As a user, I'd like to have the description for each of the modules so that I can use it to understand the module purpose and it's capabilities (presumably what is captured in javadoc for the module definition).",8
"JMS Source Does Not Expose `acknowledge`
Since the message-driven adapter uses a {{DMLC}}, the default behavior is to lose messages on exceptions (with the DMLC, the message is ack'd before the listener is invoked).    In order to provide recovery of such situations, the source needs to expose {{acknowledge}} so it can be set to {{transacted}}.    Or, perhaps, given that we don't expose complex configuration, the source should use a {{SimpleMessageListenerContainer}} instead (where the ack is sent after the listener is successfully invoked).  ",1
"Inconsistent Handling of Inherited servers.yml Properties
Some modules inherit {{application.yml}} / {{servers.yml}} via a properties file in {{/config/modules}} ; others have the values defined in the {{...OptionsMetadata}} classes.  Switch all modules to use the latter technique for consistency.",3
"Inconsistent API in AbstractSingleNodeNamedChannelSink 
In [AbstractSingleNodeNamedChannelSink|https://github.com/spring-projects/spring-xd/blob/6bd17162c8a6da0f09f6f8809f694a060c71ecc0/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/test/sink/AbstractSingleNodeNamedChannelSink.java] the receive() and receivePayload() methods  are non-blocking.    Methods without timeout parameter are usually blocking and return the first message delivered to the channel (e.g. org.springframework.integration.channel.AbstractPollableChannel#receive()).     Integration tests based on spring-xd-test dependency and embedded xd-singlenode are asynchronous. This makes AbstractSingleNodeNamedChannelSink receive method return null in all invocations because test thread is progressing faster than container can process the message in the background.    Would it be possible to make receive methods behave like in AbstractPollableChannel?",1
"Access to LocalMessageBus internal state
A LocalMessageBus in singlenode mode has several internal properties that would be useful to monitor at runtime for example via JMX: queueSize, current size of executor's queue (and others). All fields are currently write-only so it's hard to access them from custom code too. Public getters would be useful as well as an MBean exposed to JMX.",5
"spring-xd-dirt is not providing all $XD_HOME/lib libraries
Spring XD is packaging a spring-xd-dirt dependency which aims to provide runtime libraries.    spring-xd-drit-1.1.0.RELEASE is not providing all libraries from $XD_HOME/lib. See spring-xd-dirt-vs-lib.xlsx attachment generated with ""ls  $XD_HOME/lib"" and ""mvn dependency:list"" on a module with spring-xd-module-parent parent:  - 100+ JARs are not provided  - some are provided in different versions  - some are provided but not available in $XD_HOME/lib    This forces us to add and maintain missing dependencies in our own module parent e.g. to use commons-lang3 in our code which is present in $XD_HOME/lib but is not provided by spring-xd-dirt.    Why there are so many differences between $XD_HOME/lib and spring-xd-dirt?",2
"No validation for module packaging during module upload
One can upload a module which doesn't contain ""config"" package with module configuration artifacts (e.g. XML, groovy, properties etc.) using the ""module upload"" command in Spring XD shell. During stream deployment this will result in a cryptic exception:  {code}Mar 02, 2015 10:45:48 PM org.springframework.shell.core.SimpleExecutionStrategy invoke SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: Multiple top level module resources found :file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/jms-activemq.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-container-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/jms-hornetq.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-singlenode-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/xd-admin-logger.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/httpSSL.properties],file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/config/hadoop.properties]{code}  Root cause is most likely the module ClassLoader setup which delegates to parent ClassLoader which in turn scans $XD_HOME/config directory and discovers a number of properties files.  It would nice if Spring XD would validate the module during ""module upload"" command and prevent uploading of invalid modules.",2
"spring-xd-module-parent creates resources outside of target folder
Custom modules that use  {code} <groupId>org.springframework.xd</groupId> <artifactId>spring-xd-module-parent</artifactId> <version>1.1.0.RELEASE</version> {code}  as a parent will get a ""lib"" directory created in the module root source directory. This forces us to add additional ignores in version control system.  Following Maven convention all build files should be created under ""target"" folder so ""lib"" folder should be created as ""target/lib"".",1
"Update to SHDP 2.1.1 for fixing hdfs store writer to recover after error writing to hdfs
The hdfs sink doesn't recover after error writing to hdfs.  Steps to reproduce -  create a stream using hdfs sink with a small rollover:  {code} xd:>stream create --name errtest --definition ""time | hdfs --rollover=50"" --deploy  {code}  stop the datanode(s) and wait for an exception like:  {code} 2015-03-03 10:41:57,832 1.1.0.RELEASE ERROR task-scheduler-3 handler.LoggingHandler - org.springframework.messaging.MessageHandlingException: failed to write Message payload to HDFS; nested exception is org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.   org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)   org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)   org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)   org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)   org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)   org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)   java.security.AccessController.doPrivileged(Native Method)   javax.security.auth.Subject.doAs(Subject.java:415)   org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)   org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)    org.springframework.xd.integration.hadoop.outbound.HdfsStoreMessageHandler.handleMessageInternal(HdfsStoreMessageHandler.java:129)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   sun.reflect.GeneratedMethodAccessor86.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.SimpleMessageHandlerMetrics.handleMessage(SimpleMessageHandlerMetrics.java:107)   org.springframework.integration.monitor.SimpleMessageHandlerMetrics.invoke(SimpleMessageHandlerMetrics.java:87)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy136.handleMessage(Unknown Source)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)   org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)   org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy125.send(Unknown Source)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)   org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)   org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)   org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)   org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)   org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)   org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)   org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)   org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)   org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)   sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:317)   org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:190)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:157)   org.springframework.integration.monitor.DirectChannelMetrics.monitorSend(DirectChannelMetrics.java:114)   org.springframework.integration.monitor.DirectChannelMetrics.doInvoke(DirectChannelMetrics.java:98)   org.springframework.integration.monitor.DirectChannelMetrics.invoke(DirectChannelMetrics.java:92)   org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:179)   org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:207)   com.sun.proxy.$Proxy137.send(Unknown Source)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)   org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)   org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)   org.springframework.integration.endpoint.SourcePollingChannelAdapter.handleMessage(SourcePollingChannelAdapter.java:130)   org.springframework.integration.endpoint.AbstractPollingEndpoint.doPoll(AbstractPollingEndpoint.java:219)   org.springframework.integration.endpoint.AbstractPollingEndpoint.access$000(AbstractPollingEndpoint.java:55)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:149)   org.springframework.integration.endpoint.AbstractPollingEndpoint$1.call(AbstractPollingEndpoint.java:146)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller$1.run(AbstractPollingEndpoint.java:298)   org.springframework.integration.util.ErrorHandlingTaskExecutor$1.run(ErrorHandlingTaskExecutor.java:52)   org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)   org.springframework.integration.util.ErrorHandlingTaskExecutor.execute(ErrorHandlingTaskExecutor.java:49)   org.springframework.integration.endpoint.AbstractPollingEndpoint$Poller.run(AbstractPollingEndpoint.java:292)   org.springframework.scheduling.support.DelegatingErrorHandlingRunnable.run(DelegatingErrorHandlingRunnable.java:54)   org.springframework.scheduling.concurrent.ReschedulingRunnable.run(ReschedulingRunnable.java:81)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: org.apache.hadoop.ipc.RemoteException(java.io.IOException): File /xd/errtest/errtest-7.txt.tmp could only be replicated to 0 nodes instead of minReplication (=1).  There are 1 datanode(s) running and 1 node(s) are excluded in this operation.   org.apache.hadoop.hdfs.server.blockmanagement.BlockManager.chooseTarget4NewBlock(BlockManager.java:1549)   org.apache.hadoop.hdfs.server.namenode.FSNamesystem.getAdditionalBlock(FSNamesystem.java:3200)   org.apache.hadoop.hdfs.server.namenode.NameNodeRpcServer.addBlock(NameNodeRpcServer.java:641)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolServerSideTranslatorPB.addBlock(ClientNamenodeProtocolServerSideTranslatorPB.java:482)   org.apache.hadoop.hdfs.protocol.proto.ClientNamenodeProtocolProtos$ClientNamenodeProtocol$2.callBlockingMethod(ClientNamenodeProtocolProtos.java)   org.apache.hadoop.ipc.ProtobufRpcEngine$Server$ProtoBufRpcInvoker.call(ProtobufRpcEngine.java:619)   org.apache.hadoop.ipc.RPC$Server.call(RPC.java:962)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2039)   org.apache.hadoop.ipc.Server$Handler$1.run(Server.java:2035)   java.security.AccessController.doPrivileged(Native Method)   javax.security.auth.Subject.doAs(Subject.java:415)   org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1628)   org.apache.hadoop.ipc.Server$Handler.run(Server.java:2033)    org.apache.hadoop.ipc.Client.call(Client.java:1468)   org.apache.hadoop.ipc.Client.call(Client.java:1399)   org.apache.hadoop.ipc.ProtobufRpcEngine$Invoker.invoke(ProtobufRpcEngine.java:232)   com.sun.proxy.$Proxy134.addBlock(Unknown Source)   org.apache.hadoop.hdfs.protocolPB.ClientNamenodeProtocolTranslatorPB.addBlock(ClientNamenodeProtocolTranslatorPB.java:399)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.apache.hadoop.io.retry.RetryInvocationHandler.invokeMethod(RetryInvocationHandler.java:187)   org.apache.hadoop.io.retry.RetryInvocationHandler.invoke(RetryInvocationHandler.java:102)   com.sun.proxy.$Proxy135.addBlock(Unknown Source)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.locateFollowingBlock(DFSOutputStream.java:1532)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.nextBlockOutputStream(DFSOutputStream.java:1349)   org.apache.hadoop.hdfs.DFSOutputStream$DataStreamer.run(DFSOutputStream.java:588) {code}  start the datanode(s) again, the sink never recovers and has to be undeployed and redeployed. ",5
"Upgrade to SHDP 2.1.2 GA release
As a developer, I'd like to upgrade to SHDP 2.1.2 GA so that I can sync-up with latest features.",1
"Reproduce baseline numbers for Kafka
As a developer, I'd like to bench Kafka as message bus using in-built perf-testing producer/consumer utilities so that I can use that as a foundation to build XD use-cases and measure performance.     I'd like to reproduce baseline performance metrics as identified by the Kafka [engineering team|https://engineering.linkedin.com/kafka/benchmarking-apache-kafka-2-million-writes-second-three-cheap-machines].",8
"Document trigger source
nan",1
"Document the changes to Message Headers in 1.1
As a developer, I'd like to document the changes to message headers so that users can refer to the troubleshooting section if there are any serialization errors when reusing the 1.0 batch-jobs in 1.1 release.    Perhaps this could be part of [troubleshooting|https://github.com/spring-projects/spring-xd/wiki/Deployment#troubleshooting] section in our wiki.",1
"Fix error handling in jdbchdfs job 
The jdbchdfs job keeps the output stream open in case of error writing to HDFS. We should improve this and close it plus throw an exception.    We should also make sure the step is marked as failed instead of complete when an exception is thrown in the writer.",3
"Unable to define port on RabbitMQ streams
The documentation for RabbitMQ says to use the --address option to specify a port. We've tried --address=1.2.3.4:5678 (and also --port=5678 just in case) but have been unable to get a successful deployment. Running the same stream definition on a default port (i.e. without specifying a port) does work.",2
"Not possible to create a RabbitMQ to RabbitMQ stream
We get the following error when trying a rabbit to rabbit stream (definition as shown in the error):  {code} [STREAM TEST] WARN  Failure during end to end test org.springframework.xd.rest.client.impl.SpringXDException: XD143E:(pos 141): Label 'rabbit' should be unique but module 'rabbit' (at position 0) and module 'rabbit' (at position 1) both use it rabbit --queues=cxablknzdhvpotpo-source --addresses=10.85.30.129 --username=bef4412739e7d7fe929e --password=b8ace17e56456b7753a2 --vhost=/ | rabbit --exchange=cxablknzdhvpotpo-sink --addresses=10.85.30.129 --username=bef4412739e7d7fe929e --password=b8ace17e56456b7753a2 --vhost=/                                                                                                                                              ^ {code}",3
"PostgreSQL server.yml options ignored
{{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. These values are not being retrieved, and hence have to be manually added to each stream definition.  * {{url}} * {{username}} * {{password}} * {{driverClassName}} * {{validationQuery}}  (cf XD-2675, XD-2741)",2
"RabbitMQ server.yml options ignored
{{p-spring-xd}} defines values for the following parameters in {{servers.yml}}. These values are not being retrieved, and hence have to be manually added to each stream definition. * {{addresses}} * {{username}} * {{password}} * {{virtual_host}}  (cf XD-2675, XD-2741)",2
"Research EC2 infrastructure required for Kafka performance tests
As a developer, I'd like to research and Identify the EC2 infrastructure required  so that I can run performance tests on Kafka.  ",3
"Identify the Kafka configuration for Kafka performance tests
As a developer, I'd like to identify the Kafka configurations so that I could setup infrastructure to perform performance testing.  ",3
"Create EC2 AMI image for performance testing
As a developer, I'd like to create EC2 AMI with the necessary packages so that I can run the Kafka Perf tests.",2
"Add load generator source
As a developer, I'd like to add load generator _source_ module so that I could use it for performance testing use-cases.   ",3
"Add throughput receiving sink
As a developer, I'd like to add load receiving _sink_ module so that I can measure received throughput",3
"module delete on windows throws exception
used module upload for processor:payload-conversion (from XD samples) All worked well until I tried to delete the module. customModule in servers.yml was set to: xd:   customModule:     home: file://c:/project/mymodulehome  StackTrace: {noformat} 2015-03-06 01:54:33,460 1.1.0.RELEASE ERROR qtp1891077689-37 rest.RestController Advice - Caught exception while handling a request java.lang.IllegalArgumentException: Could not delete module 'processor:payload-c onversion'         at org.springframework.util.Assert.isTrue(Assert.java:65)         at org.springframework.xd.dirt.module.ModuleDefinitionService.delete(Mod uleDefinitionService.java:121)         at org.springframework.xd.dirt.rest.ModulesController.delete(ModulesCont roller.java:155)         at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)         at sun.reflect.NativeMethodAccessorImpl.invoke(Unknown Source)         at sun.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source)         at java.lang.reflect.Method.invoke(Unknown Source)         at org.springframework.web.method.support.InvocableHandlerMethod.doInvok e(InvocableHandlerMethod.java:221)         at org.springframework.web.method.support.InvocableHandlerMethod.invokeF orRequest(InvocableHandlerMethod.java:137)         at org.springframework.web.servlet.mvc.method.annotation.ServletInvocabl eHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)         at org.springframework.web.servlet.mvc.method.annotation.RequestMappingH andlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)         at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapt er.handle(AbstractHandlerMethodAdapter.java:85)         at org.springframework.web.servlet.DispatcherServlet.doDispatch(Dispatch erServlet.java:943)         at org.springframework.web.servlet.DispatcherServlet.doService(Dispatche rServlet.java:877)         at org.springframework.web.servlet.FrameworkServlet.processRequest(Frame workServlet.java:966)         at org.springframework.web.servlet.FrameworkServlet.doDelete(FrameworkSe rvlet.java:890)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:761)         at org.springframework.web.servlet.FrameworkServlet.service(FrameworkSer vlet.java:842)         at javax.servlet.http.HttpServlet.service(HttpServlet.java:848)         at org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684 )         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1496)         at org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConf iguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConf iguration.java:291)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInterna l(HiddenHttpMethodFilter.java:77)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInter nal(HttpPutFormContentFilter.java:87)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilter Internal(WebRequestTraceFilter.java:100)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.security.web.FilterChainProxy.doFilterInternal(Fi lterChainProxy.java:186)         at org.springframework.security.web.FilterChainProxy.doFilter(FilterChai nProxy.java:160)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfig uration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)         at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerR equestFilter.java:107)         at org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(Servlet Handler.java:1467)         at org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java :499)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:137)         at org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.jav a:557)         at org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandl er.java:231)         at org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandl er.java:1086)         at org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java: 428)         at org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandle r.java:193)         at org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandle r.java:1020)         at org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.j ava:135)         at org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper .java:116)         at org.eclipse.jetty.server.Server.handle(Server.java:370)         at org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(Abstrac tHttpConnection.java:494)         at org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(Abstra ctHttpConnection.java:971)         at org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.header Complete(AbstractHttpConnection.java:1033)         at org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)         at org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)          at org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnecti on.java:82)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEn dPoint.java:667)         at org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEnd Point.java:52)         at org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPoo l.java:608)         at org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool .java:543)         at java.lang.Thread.run(Unknown Source)  {noformat}",3
"Rabbit source and sink mappedRequestHeaders should include all headers by default
Currently it is necessary to specify mappedRequestHeaders=*  on the rabbit sink, otherwise no headers are mapped to AMQP.  This should be the default behavior.",1
"Complete CI setup for Windows
As a build manager, I'd like to schedule CI builds for windows so that I can verify XD runtime features/functionality.    The scope is to isolate the remaining test failures; perhaps, experiment with new AMI images until we have a solid infrastructure to fix the failing tests.",1
"Automate provisioning story for XD
nan",8
"Fix offset management for Kafka source
As a developer, I'd like to fix the offset management with Kafka _source_ module so that I can efficiently perform fetch operation from the given offsets.",8
"Add a MongoDB source
As a developer, I'd like to add a mongodb source using an xml and a property file supporting mixing in of parameters so that I can use this module to ingest data from Mongo.",5
"Measure performance baseline for a simple stream
As a developer, I'd like to measure performance numbers for a simple stream so that I can characterize the overall throughput.  ",8
"Create ""gh-pages"" to organize samples, links and tutorials
As a PM, I'd like to have a static _gh_pages_ to organize the collateral such as samples, tutorials, links, perf. benchmarks and ref. architectures so that it's easy for anyone to quickly get up and running on XD.",8
"Lattice Design Spike
As a developer, I'd like to continue Lattice/Diego POC so that I can identify the scope, risks, and the overall design for a pluggable SPI in XD runtime.",5
"Redis and In-memory offset storage profiles for the kafka source have wrong definitions
nan",1
"Expose bean settings as configuration options to the Kafka source and bus
nan",5
"Add support for time/sequence-size windowed offset updates
nan",2
"Updated XD-EC2 XD deployment for 1.2
Mask out all properties for XD-EC2",3
"Migrate wiki documentation and the chores
As a developer, I'd like to migrate the wiki to project repo so that it can be tagged with the code and versioned etc. ",8
"Custom User Configuration file for Jobs
Allow users to submit a configuration file as part of the job definition.  The configuration file should contain all job definition parameters as well as customer parameters that can be reference during runtime.  Thanks, Buelent  ",5
"Module options are not trimmed
Spring XD 1.1 container will throw following exception:   {code}  java.lang.IllegalStateException: Can't find class used for type of option 'myField': String     org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.makeSimpleModuleOptions(DefaultModuleOptionsMetadataResolver.java:147)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolveNormalMetadata(DefaultModuleOptionsMetadataResolver.java:202)    org.springframework.xd.module.options.DefaultModuleOptionsMetadataResolver.resolve(DefaultModuleOptionsMetadataResolver.java:164)    org.springframework.xd.module.options.DelegatingModuleOptionsMetadataResolver.resolve(DelegatingModuleOptionsMetadataResolver.java:44)    org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver.resolve(EnvironmentAwareModuleOptionsMetadataResolver.java:127)    org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:174)    org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:96)  	...  {code}    when module properties have a trailing whitespace character in type property (in example below there is a trailing space in options.myField.type value):    {code}  options.myField.description = this is my field  options.myField.type = String   {code}    Can the property values be trimmed before comparing to DefaultModuleOptionsMetadataResolver#SHORT_CLASSNAMES map  to avoid this problem?",1
"Add support to include ""namenode"" address from a config file
As a user, I'd like to add the Hadoop _namenode_ specifics in a config file so that I don't have to incur the hassle of pointing to the _namenode_ location every time I open a new DSL session, but it is automatically configured. ",3
"Module count not respected when label is used
{code}  xd:> stream create test --definition ""http | t1:transform --expression=payload | log""  xd:>stream deploy test --properties module.t1.count=2  Deployed stream 'test'  xd:>runtime modules    Module Id            Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status    -------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------    test.processor.t1.1  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=1, consumer.count=1, sequence=1}  deployed    test.sink.log.1      f6bb3189-9c0e-44e8-962b-025e2288ffe3  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed    test.source.http.1   f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=1, count=1, sequence=1}                                         deployed  {code}    *************************************  Works fine without the label:  *************************************  {code}  xd:>stream destroy test  Destroyed stream 'test'  xd:>stream create test --definition ""http | transform --expression=payload | log""  Created new stream 'test'  xd:>stream deploy test --properties module.transform.count=2  Deployed stream 'test'  xd:>runtime modules    Module Id                   Container Id                          Options                                                                                                                                                                                            Deployment Properties                                                                       Unit status    --------------------------  ------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  ------------------------------------------------------------------------------------------  -----------    test.processor.transform.1  f6bb3189-9c0e-44e8-962b-025e2288ffe3  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=1, producer.next.module.count=1, count=2, consumer.count=2, sequence=1}  deployed    test.processor.transform.2  393d3af0-68e8-49b2-8601-da063cfbf98a  {valid=true, expression=payload}                                                                                                                                                                   {consumer.sequence=2, producer.next.module.count=1, count=2, consumer.count=2, sequence=2}  deployed    test.sink.log.1             393d3af0-68e8-49b2-8601-da063cfbf98a  {name=test, expression=payload, level=INFO}                                                                                                                                                        {consumer.sequence=1, count=1, consumer.count=1, sequence=1}                                deployed    test.source.http.1          f6bb3189-9c0e-44e8-962b-025e2288ffe3  {sslPropertiesLocation=classpath:httpSSL.properties, maxContentLength=1048576, port=9000, messageConverterClass=org.springframework.integration.x.http.NettyInboundMessageConverter, https=false}  {producer.next.module.count=2, count=1, sequence=1}                                         deployed  {code}",3
"Fix gradle build inconsistencies and leftovers
The build has some inconsistencies that should be taken care of.  Amongst the one I know:    * The UI project is always getting cleaned, for no apparent reason (there might have been one before), thus triggering a rebuild of everything downstream, most notably DIRT  * The “exec"" task is not used anymore  * Lots of projects are getting the boot plugin applied to them. I'm not sure 100% what that plugin does, but we don't need the repackage bit for example.",3
"Setting active profiles drops contiainer/admin profile
When setting an active property via SPRING_PROFILES_ACTIVE environment variable the profile set ContainerServerApplication or AdminServerApplication is ignored.  ConfigFileApplicationListener in spring boot has an if else in the load method which skips adding the additional properties added to the StandardEnvironment if the environment variable exists.  This could be a bug for Spring Boot, but I wasn't sure if the mutual exclusion was intentional.  Additionally it would be nice to know when this feature is included in spring xd if it is a spring boot bug.",1
"jdbdhdfs job definition parameter 'partitionResultsTimeout' issues
The 'partitionResultsTimeout' parameter for jdbchdfs job definition cannot be set for the master step if the job has a partition definition.  The partitionResultsTimeout is set for the individual partition steps only. The master steps fails after the default timeout.",5
"partition jobs (jdbchdfs) are running in sequence
The jdbchdfs jobs that are partitioned are running in sequence rather than in parallel. Our expectation with partition jobs is that they run in parallel.  Job configuration is:  jdbchdfs --driverClassName='oracle.jdbc.OracleDriver' --url='jdbc:oracle:thin:@=**********' --username='=**********' --password=********** --validationQuery='SELECT CURRENT_TIMESTAMP FROM DUAL' --tableName='HZ_ORGANIZATION_PROFILES' --columns='ORGANIZATION_PROFILE_ID, ..., VERSION_NUMBER' --partitions=10 --partitionColumn='ORGANIZATION_PROFILE_ID' --directory='/ingest/source/oracle11i/ar/hz_organization_profiles' --fileName=hz_organization_profiles --fileExtension=csv --delimiter=| --commitInterval=10000 --rollover=262144000 --dateFormat=yyyy-mmm-dd --partitionResultsTimeout=1800000 --testOnBorrow=false ",5
"deployed modules are not redeployed properly once the container come back online
Deployed component s are not deployed to the containers that failed and restarted.   We have 3 containers and 3 jobs where all jobs are deployed evenly, one job per container. However, when two of the containers fail and come back up, we end up with 3 jobs on 1 container.  See attached document for detail.  ",5
"Batch Job deployment screen only show 10 items...
The Batch Jobs Deployment screen  ('http://*****************:9393/admin-ui/#/jobs/deployments') UI screen is only showing 10 items without pagination and prohibiting users from launching their deployed jobs from the UI.  The jobs can only be launched via the RESTApi call  In release 1.0.3 the deployment page has not pagination but grows beyond 10 entries.",5
"Investigate running Camus as a batch job
Similar to Sqoop where we move data from RDBMS to HDFS we should look at integrating with Camus to load data from Kafka to HDFS.",5
"RabbitMQ Dead Letter for TAP not deleted
If automatic binding of dead letter is enabled for rabbit mq and taps are deployed, anytime the tap is undeployed, the dead letter for that tap still remains.  The tap uses a unique name and the queue for that is automatically deleted, but the dead letter queue for it is not.  This problem becomes worse when containers are running in yarn and may not live for long periods of time.  Many dead letter queues for taps can become overwhelming.",3
"Improve the performance of jdbchdfs batch job
As a user, I'd like to use a _jdbchdfs_ batch job as a passthrough (without chunk processing) so that I don't have to incur the batch read/write overhead.",2
"Add 'about section' to module description.
It should be possible to configure a (short) description for a module that is display above the module options  via {{module info --name ....}}.  The description could contain a few lines describing the core functionality and potentially hyperlinks  to additional information for a module.  This information should be exposed via the REST interface as well.  Currently only the module options are printed.",5
"Classpath issues with gemfire-json-server sink
The GemFire client for SpringXD is throwing java.lang.NoClassDefFoundError for the class com/gemstone/gemfire/cache/client/internal/PingOp after a Stream sinking to gemfire-json-server is destroyed.    Issue starts after destroying a stream, which makes me think we might be unloading the jar files from the classpath while still keeping a connection to the gemfire server.    Steps to reproduce:    1) Create a region in Gemfire to test    e.g.: gfsh>create region --name=Stocks --type=REPLICATE  Member  | Status  ------- | -------------------------------------  server1 | Region ""/Stocks"" created on ""server1""      2) Create a simple stream in Spring XD that writes to that region in gemfire-json-server. Deploy it for single node and let it run for a few seconds.      e.g.:    XD$ stream create streamx --definition ""trigger --fixedDelay=3 | http-client --url='''https://query.yahooapis.com/v1/public/yql?q=select * from yahoo.finance.quote where symbol in (\""MSFT\"")&format=json&env=store://datatables.org/alltableswithkeys''' --httpMethod=GET | splitter --expression=#jsonPath(payload,'$.query.results.quote') | gemfire-json-server --useLocator=true --host=localhost --port=10334 --regionName=Stocks --keyExpression=payload.getField('Symbol')"" --deploy      3)  Destroy the stream    e.g.:  XD$  stream destroy streamx    3)  Wait a few seconds and check the xd-singlenode output.. you'll see the exception as following:    [error 2015/03/13 11:04:52.437 PDT  <poolTimer-client-pool-14> tid=0x15a] Unexpected error in pool task <com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask@635c9341>  java.lang.NoClassDefFoundError: com/gemstone/gemfire/cache/client/internal/PingOp    com.gemstone.gemfire.cache.client.internal.LiveServerPinger$PingTask.run2(LiveServerPinger.java:83)    com.gemstone.gemfire.cache.client.internal.PoolImpl$PoolTask.run(PoolImpl.java:1197)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)    java.util.concurrent.FutureTask.runAndReset(FutureTask.java:308)    com.gemstone.gemfire.internal.ScheduledThreadPoolExecutorWithKeepAlive$DelegatingScheduledFuture.run(ScheduledThreadPoolExecutorWithKeepAlive.java:252)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)",3
"upgrade to io.projectreactor breaks generated POMS
./gradlew install fails for spring-xd-extension-batch and spring-xd-extension-reactor. The first case is a simple update to gradle/build-extensions.gradle. The 2nd causes several compilation errors that are not trivial for a Reactor noob.  ",2
"Broken ""Deployment"" link in docs
Please see ""Deployment"" link on http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/#_module_deployment page.     !broken-link-deployment.png!    The link is broken and redirects to http://docs.spring.io/autorepo/docs/spring-xd/1.1.0.RELEASE/reference/html/Deployment which is a 404.",1
"Composing transformer and gemfire-json-server leads to FileNotFoundException during deployment
Composing ""transform"" and ""gemfire-json-server"" modules leads to FileNotFoundException during stream deployment when:  - xd-admin and xd-container are started as system services (after installing from RPM).   - xd-singelonde is started outside of $XD_HOME/bin directory e.g. {code}  $ cd ""$XD_HOME""  $ bin/xd-singelonde  {code}    but it's fully working and exception is *not* thrown when:  - xd-singlenode script is started from within ""$XD_HOME/bin directory {code}  $ cd ""$XD_HOME/bin""  $ ./xd-singelonde  {code}    Then using the XD Shell:    {code}  $ xd-shell  > module compose --name ""cm-gem-sink"" --definition ""transform --outputType='application/json' | gemfire-json-server --regionName=timeRegion --keyExpression=payload.getField('location')""  > stream create --name ""cm-test-gem"" --definition ""tail --name='/tmp/time.json' | cm-gem-sink""   > stream deploy --name ""cm-test-gem""  {code}    Stream deployment will result in following exception    {code}  [2015-03-11 16:38:10.918] boot - 17402  INFO [DeploymentsPathChildrenCache-0] --- DeploymentListener: Deploying module [ModuleDescriptor@2095e9f9 moduleName = 'tail', moduleLabel = 'tail', group = 'cm-test-gem', sourceChannelName = [null], sinkChannelName = [null], index = 0, type = source, parameters = map['name' -> '/tmp/time.json'], children = list[[empty]]]  2015-03-11 16:38:11,263 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'cm-test-gem': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: file [/opt/spring-xd/spring-xd-1.1.0.RELEASE/xd/modules/sink/gemfire-json-server/config/gemfire-json-server.groovy]; nested exception is org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:178)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:138)    org.springframework.boot.BeanDefinitionLoader.load(BeanDefinitionLoader.java:127)    org.springframework.boot.SpringApplication.load(SpringApplication.java:620)    org.springframework.boot.SpringApplication.run(SpringApplication.java:315)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)    org.springframework.xd.module.core.CompositeModule.initialize(CompositeModule.java:105)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.beans.factory.parsing.BeanDefinitionParsingException: Configuration problem: Error evaluating Groovy script: ../modules/common/gemfire-sink.groovy (No such file or directory)  Offending resource: URL [file:../modules/common/gemfire-sink.groovy]; nested exception is java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:247)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:202)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:181)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:217)    org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.importBeans(GroovyBeanDefinitionReader.java:337)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:368)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans$_run_closure1.doCall(beans:4)    beans$_run_closure1.doCall(beans)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    org.codehaus.groovy.runtime.metaclass.ClosureMetaClass.invokeMethod(ClosureMetaClass.java:278)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.Closure.call(Closure.java:423)    groovy.lang.Closure.call(Closure.java:417)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.invokeBeanDefiningClosure(GroovyBeanDefinitionReader.java:426)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader$1.call(GroovyBeanDefinitionReader.java:223)    groovy.lang.Closure.call(Closure.java:439)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:606)    org.codehaus.groovy.reflection.CachedMethod.invoke(CachedMethod.java:90)    groovy.lang.MetaMethod.doMethodInvoke(MetaMethod.java:324)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1207)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    groovy.lang.MetaClassImpl.invokePropertyOrMissing(MetaClassImpl.java:1253)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1209)    groovy.lang.MetaClassImpl.invokeMethod(MetaClassImpl.java:1016)    org.codehaus.groovy.runtime.callsite.PogoMetaClassSite.callCurrent(PogoMetaClassSite.java:66)    org.codehaus.groovy.runtime.callsite.CallSiteArray.defaultCallCurrent(CallSiteArray.java:49)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:133)    org.codehaus.groovy.runtime.callsite.AbstractCallSite.callCurrent(AbstractCallSite.java:141)    beans.run(beans:1)    groovy.lang.GroovyShell.evaluate(GroovyShell.java:649)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 30 more  Caused by: java.io.FileNotFoundException: ../modules/common/gemfire-sink.groovy (No such file or directory)    java.io.FileInputStream.open(Native Method)    java.io.FileInputStream.<init>(FileInputStream.java:146)    java.io.FileInputStream.<init>(FileInputStream.java:101)    sun.net.www.protocol.file.FileURLConnection.connect(FileURLConnection.java:90)    sun.net.www.protocol.file.FileURLConnection.getInputStream(FileURLConnection.java:188)    org.springframework.core.io.UrlResource.getInputStream(UrlResource.java:168)    org.springframework.core.io.support.EncodedResource.getReader(EncodedResource.java:132)    org.springframework.beans.factory.groovy.GroovyBeanDefinitionReader.loadBeanDefinitions(GroovyBeanDefinitionReader.java:243)  	... 80 more  {code}    Exporting XD_HOME as a global variable seems to have no effect on this behavior.",2
"Refactor job-launcher to not depend on execution context
As a developer, I'd like to decouple execution context from job launch lifecycle so that we can avoid CL and serialization errors.     This fix needs to be formally applied in Spring Batch itself. XD will upgrade to Batch release in order to inherit this functionality; hence, the current workaround with XD-2486 needs reafctored. ",5
"Improve ItemWriter in OOTB jdbchdfs to use DataStoreWriter
The current jdbchdfs job does not take advantage of all the features available to write into HDFS provided by Spring Hadoop's DataStoreWriter implementations, such as partitioning.  Update the jdbchdfs job to use <int-hadoop:store-writer/> (similar to the HDFS Sink) inside a new ItemWriter implementation  ",3
"Composite Modules should inherit ""xd.*"" properties
Currently when modules are composed to a single application context, properties are not inherited.    https://github.com/spring-projects/spring-xd/wiki/Modules#placeholders-available-to-all-modules    ",2
"hdfs sink loses messages/data when container killed
Scenario running a ""rabbit | hdfs"" stream and killing the xd-container while stream is running.  Looks like the messages get's acked before the data is flushed to hdfs.  This results in some data lost due to data either in tmp file or cached in the dfs client.  Reference: VESC-387",5
"SCS - Verify/Fix AbstractKryoMultitypeCodec implementation
This apparently is not tested or used internally, but I expect it to fail having tried a similar approach to derive the class of a generic type in a different situation. This method does not always work due to type erasure http://stackoverflow.com/questions/3403909/get-generic-type-of-class-at-runtime.  We need to verify if this is working, if not fix it. The API may require it, so possibly UnsupportedOperationException...     {code}  /**     * Infers the type from this class's generic type argument     * @param kryo     * @param input     * @return   */  protected T doDeserialize(Kryo kryo, Input input) {  	Class<T> type = (Class<T>) (  				(ParameterizedType) this.getClass().getGenericSuperclass()).getActualTypeArguments()[0];  		return doDeserialize(kryo, input, type);  }  {code}",1
"Remove Reactor Stream processor from ref docs to spring-xd-modules
Not going to integrate with Reactor for stream processing.",1
"Enable @Value, etc in Module Options Metadata
A placeholder to investigate what can be done with Spring configuration in Module Options Metadata classes to simplify/enhance property configuration.  With @Configuration modules, these may now be beans in the module context. ",3
"XD distributed tests are broken
There are test failures running XD distributed tests.     It looks like all the test failures are related to NPE on DeploymentProperties format:    java.lang.NullPointerException    org.springframework.xd.rest.domain.support.DeploymentPropertiesFormat.formatDeploymentProperties(DeploymentPropertiesFormat.java:72)    org.springframework.xd.rest.client.impl.JobTemplate.deploy(JobTemplate.java:71)    org.springframework.xd.distributed.test.JobStateTests.testJobStateTransition(JobStateTests.java:83)",1
"Add the Dependencies Required to Use #xpath in Streams
Thanks to Gary I found this little gem of documentation to be able to use xpath expression in XD. Only hiccup is that I had to also add the spring-xml.jar to the classpath (otherwise it is missing XPathException class).     http://stackoverflow.com/questions/29110757/spring-xd-work-with-xml-payload",1
"Create gradle task to check that all projects have descriptions
This keeps coming up as an issue that prevents us from publishing to maven central.",2
"Refactor Deployment related classes in XD DIRT
This is an improvement ticket to address refactoring of XD dirt classes especially XD admin(zk, deployment related) and container.",8
"Add support to create custom jobs using Java Config
As a developer, I'd like to create a custom job module using Java Config so that I don't have to deal with XML configurations. While deploying/launching the following job, I get the error attached below.    {code:xml}  job create --name CDK_Global --definition ""customBatchJob"" --deploy  module upload --type job --name customBatchJob --file /Users/mminella/Documents/IntelliJWorkspace/CustomBatchModule/build/libs/CustomBatchModule-1.1.0.RELEASE.jar  job launch --name CDK_Global  {code}    *Error:*  I'm getting an exception that the job doesn't exist asking if it's deployed",5
"Document MongoDB source
nan",1
"Make doc generation part of the standard build
Following the recent move of the doco to the main repo, it makes sense to have the doc generation be part of the ""main"" build, at an early stage, as an incentive for developers to push doc changes as soon as they change the code.    ",2
"XD on Lattice POC
As a developer, I'd like to continue XD-on-Lattice/Diego PoC, and will be focused on the design of a pluggable SPI, so it is more generally applicable than Lattice, with the Receptor API being just one implementation option. ",8
"xd-admin broken for HDFS module registry
nan",1
"XD-Admin fails to start
When starting xd-admin getting the following exception:  {noformat}  2015-03-20 14:25:53,904 1.2.0.SNAP  WARN main annotation.AnnotationConfigApplicationContext - Exception encountered during context initialization - cancelling refresh attempt  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)    org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)    org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)    org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 22 more  Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    java.lang.Class.forName0(Native Method)    java.lang.Class.forName(Class.java:190)    org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)    org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)    org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 25 more  Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:425)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:358)  	... 32 more  2015-03-20 14:25:53,911 1.2.0.SNAP ERROR main boot.SpringApplication - Application startup failed  org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:313)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:122)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveManagedList(BeanDefinitionValueResolver.java:382)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:157)    org.springframework.beans.factory.support.ConstructorResolver.resolveConstructorArguments(ConstructorResolver.java:648)    org.springframework.beans.factory.support.ConstructorResolver.autowireConstructor(ConstructorResolver.java:140)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.autowireConstructor(AbstractAutowireCapableBeanFactory.java:1131)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBeanInstance(AbstractAutowireCapableBeanFactory.java:1034)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:504)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)    org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)    org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)    org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)    org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:762)    org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:129)    org.springframework.xd.dirt.server.AdminServerApplication.run(AdminServerApplication.java:89)    org.springframework.xd.dirt.server.AdminServerApplication.main(AdminServerApplication.java:73)  Caused by: org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1566)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:539)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)    org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveInnerBean(BeanDefinitionValueResolver.java:299)  	... 22 more  Caused by: java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream    java.lang.Class.forName0(Native Method)    java.lang.Class.forName(Class.java:190)    org.springframework.xd.dirt.module.ExtendedResource.<clinit>(ExtendedResource.java:47)    org.springframework.xd.dirt.module.WritableResourceModuleRegistry.afterPropertiesSet(WritableResourceModuleRegistry.java:123)    org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean.afterPropertiesSet(CustomModuleRegistryFactoryBean.java:70)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.invokeInitMethods(AbstractAutowireCapableBeanFactory.java:1625)    org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.initializeBean(AbstractAutowireCapableBeanFactory.java:1562)  	... 25 more  Caused by: java.lang.ClassNotFoundException: org.apache.hadoop.fs.FSDataInputStream    java.net.URLClassLoader$1.run(URLClassLoader.java:366)    java.net.URLClassLoader$1.run(URLClassLoader.java:355)    java.security.AccessController.doPrivileged(Native Method)    java.net.URLClassLoader.findClass(URLClassLoader.java:354)    java.lang.ClassLoader.loadClass(ClassLoader.java:425)    sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)    java.lang.ClassLoader.loadClass(ClassLoader.java:358)  	... 32 more  2015-03-20 14:25:53,915 1.2.0.SNAP ERROR main server.AdminServerApplication - Error creating bean with name 'moduleRegistry' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Cannot create inner bean 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' of type [org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean] while setting constructor argument with key [1]; nested exception is org.springframework.beans.factory.BeanCreationException: Error creating bean with name 'org.springframework.xd.dirt.module.CustomModuleRegistryFactoryBean#175e137b' defined in class path resource [META-INF/spring-xd/internal/repositories.xml]: Invocation of init method failed; nested exception is java.lang.NoClassDefFoundError: org/apache/hadoop/fs/FSDataInputStream  {noformat}    Reproduced Locally (mac) and on EC2.  xd-singlenode works fine.  Commit: 4673b5ab97",3
"Update all the module documentation to include ""shortDescription""
As a developer, I'd like to update all the module docs to also include _shortDescription_ so that it's available for users to learn more about the module.",2
"Add support to host/read python script from HDFS
As a developer, I'd like to host/read Python script (file) from HDFS, so I can use the shell processor in XD (on CF) to delegate data science functionality to Py runtime and receive the feedback back in XD.",8
"Research how to accommodate dynamic partitions when scaling containers
As a developer, I'd like to rebalance partitions as we scale the containers, so I don't have to bring down the running stream/job to reestablish dynamic partitions.",8
"Investigate job event listeners when the job is created as java config
When the job module is configured using java config, there seems to be some issue with the way out of the box job event listeners are created.    Please see the discussion here:    https://github.com/spring-projects/spring-xd/pull/1506",3
"Kafka source should not try to decode payloads as Strings
Currently, the Kafka source uses a StringDecoder by default - which is an invalid assumption if the payload is not the result of String conversion.     ",2
"Ability to configure encoders and decoders for the Kafka source, sink and bus
As a Spring XD user, I want to have the ability to customize the encoders and decoders used by the Kafka source, sink and bus, so that I can customize data formats and choose the most appropriate strategy",5
"Create a POC for gpfdist sink
As a user, I'd like to have the OOTB _gpfdist_ sink module, so I can use this module to do ultra fast data movement from various sources into GPDB/HAWQ.",8
"Add support for admin-ui and Flo integration 
As a developer, I'd like to setup UI infrastructure, so I can integrate admin_ui and Flo.",5
"Harmonize poller configuration
See conversation at https://github.com/spring-projects/spring-xd/pull/1509  Several source modules leverage a poller, with `fixedDelay` being a common name for one of the options.  There is actually PeriodicTriggerMixin available, which should be applied to all modules, to make sure configuration is harmonized.  See https://github.com/spring-projects/spring-xd/pull/1384/files  At the time of writing: {noformat} grep -r '<poller' . --include='*.xml' | grep -v build ./modules/source/file/config/file.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS""/> ./modules/source/jdbc/config/jdbc.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS""> ./modules/source/mail/config/mail.xml:			<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS""> ./modules/source/sftp/config/sftp.xml:		<poller fixed-delay=""${fixedDelay}"" time-unit=""SECONDS"" /> ./modules/source/time/config/time.xml:		<poller trigger=""fixedDelayTrigger"" /> {noformat} ",1
"SqoopRunner should use resource manager scheduler option
In SqoopRunner we manually set rm address, fs address and yarn classpath. YarnConfiguration.RM_SCHEDULER_ADDRESS is also needed for appmaster to function properly.  Current workaround is to use config values which gets imported automatically: {code} spring:     hadoop:         config:             yarn.resourcemanager.scheduler.address: <host>:8030 {code} ",1
"Design and budget Perf Env for XD on RackSpace
Provide design for how we are going to run XD and Kafka on Rackspace.  This includes the base design for the Kafka Perf tests environment.  This will be used to provide a budget for the cloud resources  for the performance environment.  ",3
"Create a POC for end-to-end Kafka use-case
As a developer, I'd like to create a end-to-end Kafka use-case, so I can study, demonstrate, and verify kafka + xd play that's built for scale and performance.",3
"Create a File source to efficiently read files
As a developer, I'd like to use an efficient approach to read files, so I don't have to read line-by-line and keep it in-memory in order to consume/write the file content.     Would the _tasklet_ approach be better as opposed to transmitting data via message bus (as streams)? ",5
"Module loading error handling improvement
Modules are loaded in the container as such (in DeploymentListener):  {code} try { 	module = (ModuleType.job.toString().equals(moduleType)) ? 			deployJobModule(client, unitName, moduleLabel, properties) : 			deployStreamModule(client, unitName, moduleType, moduleLabel, properties); 	if (module == null) { 		status = new ModuleDeploymentStatus(container, moduleSequence, key, ModuleDeploymentStatus.State.failed, 				""Module deployment returned null""); 	} 	else { 		status = new ModuleDeploymentStatus(container, moduleSequence, key, 				ModuleDeploymentStatus.State.deployed, null); 	} } catch (Exception e) { 	status = new ModuleDeploymentStatus(container, moduleSequence, key, ModuleDeploymentStatus.State.failed, 			ZooKeeperUtils.getStackTrace(e)); 	logger.error(""Exception deploying module"", e); }  try { 	writeModuleMetadata(client, module, path); 	client.setData().forPath(status.buildPath(), ZooKeeperUtils.mapToBytes(status.toMap())); } catch (KeeperException.NoNodeException e) { 	logger.warn(""During deployment of module {} of type {} for {} with sequence number {},"" + 					""an undeployment request was detected; this module will be undeployed."", moduleLabel, 			moduleType, unitName, moduleSequence); 	if (logger.isTraceEnabled()) { 		logger.trace(""Path "" + path + "" was removed"", e); 	} } {code}  The problem is if an {{Error}} is thrown, such as {{NoClassDefFoundError}} or {{NoSuchMethodError}}. We need to make a best effort when writing the deployment status to prevent the supervisor from timing out waiting for a status.",2
"Create a gpload batch job
As a developer, I'd like to create a _gpload_ tasklet, so I can ingest data from various sources into GPDB in an efficient manner.",5
"XD admin ZK distributed queue consumer initialization issue
The ZK distributed queue consumer is initialized even before the module, stream, job deployment requests path cache are started. This could lead to issue when the consumer start processing the requests before the cache are initialized.    On such scenario, the following exception could be thrown:    2015-03-23 21:00:25,919 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000002  org.springframework.xd.dirt.server.admin.deployment.DeploymentException: dataSender          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:70)          at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)          at org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)          at org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)          at org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)          at org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)          at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)          at java.util.concurrent.FutureTask.run(FutureTask.java:262)          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)          at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)          at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)          at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)          at java.lang.Thread.run(Thread.java:745)  Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.          at org.springframework.util.Assert.notNull(Assert.java:112)          at org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)          at org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161)",1
"Launching XD admin fails with ZK holding existing stream data
Following exception is thrown when starting XD admin withe ZK holding the stream data:    2015-03-23 17:21:13,831 1.2.0.SNAP ERROR LeaderSelector-0 leader.LeaderSelector - The leader threw an exception  java.lang.NullPointerException  at com.fasterxml.jackson.core.JsonFactory.createParser(JsonFactory.java:822)  at com.fasterxml.jackson.databind.ObjectReader.readValue(ObjectReader.java:896)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:157)  at org.springframework.xd.dirt.stream.zookeeper.ZooKeeperStreamDefinitionRepository.findOne(ZooKeeperStreamDefinitionRepository.java:56)  at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.lookupStream(StreamConfigParser.java:654)  at org.springframework.xd.dirt.stream.dsl.ChannelNode.resolve(ChannelNode.java:144)  at org.springframework.xd.dirt.stream.dsl.SourceChannelNode.resolve(SourceChannelNode.java:54)  at org.springframework.xd.dirt.stream.dsl.StreamNode.resolve(StreamNode.java:125)  at org.springframework.xd.dirt.stream.dsl.StreamConfigParser.parse(StreamConfigParser.java:110)  at org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:121)  at org.springframework.xd.dirt.stream.StreamFactory.createStream(StreamFactory.java:84)  at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentLoader.loadStream(DeploymentLoader.java:101)  at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.recalculateStreamStates(DefaultDeploymentStateRecalculator.java:96)  at org.springframework.xd.dirt.server.admin.deployment.zk.DefaultDeploymentStateRecalculator.onSupervisorElected(DefaultDeploymentStateRecalculator.java:182)  at org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentSupervisor$LeaderListener.takeLeadership(DeploymentSupervisor.java:468)  at org.apache.curator.framework.recipes.leader.LeaderSelector$WrappedListener.takeLeadership(LeaderSelector.java:536)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWork(LeaderSelector.java:398)  at org.apache.curator.framework.recipes.leader.LeaderSelector.doWorkLoop(LeaderSelector.java:443)  at org.apache.curator.framework.recipes.leader.LeaderSelector.access$100(LeaderSelector.java:63)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:244)  at org.apache.curator.framework.recipes.leader.LeaderSelector$2.call(LeaderSelector.java:238)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)  at java.util.concurrent.FutureTask.run(FutureTask.java:262)  at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)  at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)  at java.lang.Thread.run(Thread.java:745)",5
"Basic security makes xd-shell throw 403 Forbidden error
After enabling admin endpoint security in servers.yml using basic authentication and single user  {code}  spring:    profiles: admin  security:    basic:      enabled: true # false to disable security settings (default)      realm: SpringXD    user: # valid only if security.basic.enabled=true      name: myadmin      password: myadmin  {code}    Spring XD UI is secured however xd-shell commands are resulting in a 403 error:    {code}  server-unknown:>admin config server --uri http://localhost:9393 --username myadmin --password myadmin  Successfully targeted http://localhost:9393  xd:>admin config info    -------------  -------------------------------------------    Credentials    [username='myadmin, password=****']    Result         Successfully targeted http://localhost:9393    Target         http://localhost:9393    Timezone used  Greenwich Mean Time (UTC 0:00)    -------------  -------------------------------------------  xd:>stream list  Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden  xd:>stream create --name ""t1"" --definition ""time | log""  Command failed org.springframework.web.client.HttpClientErrorException: 403 Forbidden  {code}    This can be fixed by adding configuration explained in ""File based authentication"" docs section:    {code}  xd:    security:      authentication:        file:          enabled: true          users:              myadmin: myadmin, ROLE_VIEW, ROLE_ADMIN, ROLE_CREATE  {code}    Following is the problem:  # Configuration explained in ""Single user authentication"" chapter should work out of the box without additional role setup  # Docs should be more clear on authorization",2
"deploy-working-dir is set to to root directory when container is started as service
When Spring XD is started as a service using {{service spring-xd-container start}} the deploy-working-dir in GemFire module is resolved to the top-most directory (on Linux ""/""). This directory is not writable by spring-xd user under which the process is executed.  When a stream using GemFire is created e.g. {{stream create --name gfTest --definition ""time | gemfire-json-server ...}} following exception will be thrown:  {code} [error 2015/03/24 15:55:20.798 GMT  <DeploymentsPathChildrenCache-0> tid=0x34] Error when attempting to deploy JAR files on load. java.io.IOException: Unable to write to deploy directory   com.gemstone.gemfire.internal.JarDeployer.verifyWritableDeployDirectory(JarDeployer.java:589)   com.gemstone.gemfire.internal.JarDeployer.loadPreviouslyDeployedJars(JarDeployer.java:68)   com.gemstone.gemfire.internal.cache.GemFireCacheImpl.init(GemFireCacheImpl.java:839)   com.gemstone.gemfire.internal.cache.GemFireCacheImpl.create(GemFireCacheImpl.java:620)   com.gemstone.gemfire.cache.client.ClientCacheFactory.basicCreate(ClientCacheFactory.java:207)   com.gemstone.gemfire.cache.client.ClientCacheFactory.create(ClientCacheFactory.java:162)   org.springframework.data.gemfire.client.ClientCacheFactoryBean.createCache(ClientCacheFactoryBean.java:93)   org.springframework.data.gemfire.CacheFactoryBean.init(CacheFactoryBean.java:271)   org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java:455)   org.springframework.data.gemfire.CacheFactoryBean.getObject(CacheFactoryBean.java:77)   org.springframework.beans.factory.support.FactoryBeanRegistrySupport.doGetObjectFromFactoryBean(FactoryBeanRegistrySupport.java:168)   org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getObjectFromFactoryBean(FactoryBeanRegistrySupport.java:103)   org.springframework.beans.factory.support.AbstractBeanFactory.getObjectForBeanInstance(AbstractBeanFactory.java:1517)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:251)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveReference(BeanDefinitionValueResolver.java:351)   org.springframework.beans.factory.support.BeanDefinitionValueResolver.resolveValueIfNecessary(BeanDefinitionValueResolver.java:108)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.applyPropertyValues(AbstractAutowireCapableBeanFactory.java:1469)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.populateBean(AbstractAutowireCapableBeanFactory.java:1214)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.doCreateBean(AbstractAutowireCapableBeanFactory.java:537)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.createBean(AbstractAutowireCapableBeanFactory.java:476)   org.springframework.beans.factory.support.AbstractBeanFactory$1.getObject(AbstractBeanFactory.java:303)   org.springframework.beans.factory.support.DefaultSingletonBeanRegistry.getSingleton(DefaultSingletonBeanRegistry.java:230)   org.springframework.beans.factory.support.AbstractBeanFactory.doGetBean(AbstractBeanFactory.java:299)   org.springframework.beans.factory.support.AbstractBeanFactory.getBean(AbstractBeanFactory.java:194)   org.springframework.beans.factory.support.DefaultListableBeanFactory.preInstantiateSingletons(DefaultListableBeanFactory.java:743)   org.springframework.context.support.AbstractApplicationContext.finishBeanFactoryInitialization(AbstractApplicationContext.java:757)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:480)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) {code}  deploy-working-dir should be set to a directory which writable by spring-xd user (maybe java.io.tmpdir?).",1
"Remove Spark/Hadoop dependencies from root classpath
As a developer, I'd like to remove Hadoop dependencies from root classpath, so we don't have to incur the penalty of classloading unnecessary libraries at the startup time.    The goal is to at least try and decouple for situations when HDFS is not used for module registry. ",8
"Add dynamic classpath support for modules
As a developer, I'd like to add support for dynamic classpath for modules, so we can have the flexibility to load the right dependencies either based on module options (0) or via other properties such as including the dependencies from a specific location (1).     (0):  {code}  /lib/*.jar:lib/${distro}/*.jar  {code}    (1):  {code}  ${xd.home}/lib/hadoop/${distro}/*.jar  {code}    *Example:*  {code}  http | hdfs --distro=PHD22    http | myCustomModule --classpath=/my/funky/dir    http | jpa --provider=eclipse    jpa:  /config/  /lib/something-that-is-common.jar      /eclipse/eclipse-link-3.2.jar      /hibernate/hibernate-core-5.0.jar    module.classpath = /lib/*.jar:/lib/${provider}/*.jar  {code}",5
"UI: Deploy Stream - Return key does not submit form
*http://localhost:9393/admin-ui/#/streams/definitions/test/deploy*",1
"remove ModuleDefinitions.dummy()
This method should be replaced with a utility method in a test support class so that it is only available in a testing context.  ",2
"Admin leader election issue when using different management port
When the admin is started with the different management port (default is the same as that of admin http port), then the leadership is requested when the management context is setup. The leadership election should happen only using the Admin server application context.  With this, the following exception is thrown when deployment requests are handled:  2015-03-24 21:48:26,340 1.2.0.SNAP ERROR DeploymentSupervisor-0 queue.DistributedQueue - Exception processing queue item: queue-0000000004 org.springframework.xd.dirt.server.admin.deployment.DeploymentException: testStream   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:164)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeploy(AbstractInstancePersistingDeployer.java:83)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployAll(AbstractInstancePersistingDeployer.java:109)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.deleteAll(AbstractInstancePersistingDeployer.java:117)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.processDeploymentMessage(DeploymentMessageConsumer.java:115)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:73)   org.springframework.xd.dirt.server.admin.deployment.zk.DeploymentMessageConsumer.consumeMessage(DeploymentMessageConsumer.java:43)   org.apache.curator.framework.recipes.queue.DistributedQueue.processMessageBytes(DistributedQueue.java:678)   org.apache.curator.framework.recipes.queue.DistributedQueue.processNormally(DistributedQueue.java:712)   org.apache.curator.framework.recipes.queue.DistributedQueue.access$300(DistributedQueue.java:65)   org.apache.curator.framework.recipes.queue.DistributedQueue$5.run(DistributedQueue.java:629)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$201(ScheduledThreadPoolExecutor.java:178)   java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:292)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: java.lang.IllegalArgumentException: Module deployment request path cache shouldn't be null.   org.springframework.util.Assert.notNull(Assert.java:112)   org.springframework.xd.dirt.server.admin.deployment.zk.ZKDeploymentHandler.undeploy(ZKDeploymentHandler.java:81)   org.springframework.xd.dirt.stream.AbstractInstancePersistingDeployer.undeployResource(AbstractInstancePersistingDeployer.java:161) 	... 17 more",1
"UI: Provide place holder text if tables don't have items
Provide place holder text if tables don't have items. E.g.:  ""No definitions found""  ",2
"When Scheduling a Job I cannot provide Job parameters
Add the ability to provide job parameters when scheduling jobs",4
"JavaConfiguredModule should throw an exception when no @Configuration class is present 
I had a custom module with a typo:  base_packages=base_packages=com.acme.config    The module deploys without error but the stream hangs since the channels, etc. are not found in the stream plugin. Very hard to debug. ",2
"Message Bus: Shut down Kafka Consumers completely before unbinding
This causes the following exception to be thrown in the log (without functional adverse effects)    org.springframework.messaging.MessageDeliveryException: Dispatcher has no subscribers for channel 'unknown.channel.name'.; nested exception is org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:81)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.endpoint.MessageProducerSupport.sendMessage(MessageProducerSupport.java:101)    org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter.access$300(KafkaMessageDrivenChannelAdapter.java:43)    org.springframework.integration.kafka.inbound.KafkaMessageDrivenChannelAdapter$AutoAcknowledgingChannelForwardingMessageListener.doOnMessage(KafkaMessageDrivenChannelAdapter.java:172)    org.springframework.integration.kafka.listener.AbstractDecodingMessageListener.onMessage(AbstractDecodingMessageListener.java:50)    org.springframework.integration.kafka.listener.QueueingMessageListenerInvoker.run(QueueingMessageListenerInvoker.java:121)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)    java.lang.Thread.run(Thread.java:745)  Caused by: org.springframework.integration.MessageDispatchingException: Dispatcher has no subscribers    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:107)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)  	... 13 more    ",2
"Admin UI does not show all containers
We have 3 reported incidents so, still working on reproducing the issue.    1) You start multiple ""nodes"" but the admin-ui does not show all of them but logs do  2) By restarting the ""missing"" nodes they eventually show up in the Admin UI    ",5
"STS Gradle Import Missing Dependencies without Enabling Scala
Dirt errors after {{cleanEclipse eclipse}} - same problem after a complete gradle reimport.  Manually adding the spring-xd-spark-streaming project to the xd-dirt classpath didn't help.  {code} Description	Resource	Path	Location	Type The import org.springframework.xd.spark cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 33	Java Problem The import org.springframework.xd.module.ModuleType is never used	ModuleDeploymentTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins	line 33	Java Problem The import org.springframework.batch.core.configuration.xml.JobParserJobFactoryBean is never used	BatchJobRegistryBeanPostProcessor.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/job	line 31	Java Problem The value of the field KafkaMessageBusTests.embeddedHeadersMessageConverter is not used	KafkaMessageBusTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/bus/kafka	line 56	Java Problem SparkStreamingSupport cannot be resolved	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 68	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingContainerFilter.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/spark	line 75	Java Problem SparkMessageSender cannot be resolved to a type	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 38	Java Problem The import org.springframework.beans.factory.annotation.Value is never used	MessageBusClassLoaderFactory.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/server	line 27	Java Problem The import org.springframework.xd.spark cannot be resolved	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 28	Java Problem The method send(Message) of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 104	Java Problem The method start() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem The method isRunning() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 123	Java Problem The method stop() of type MessageBusSender must override or implement a supertype method	MessageBusSender.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 109	Java Problem The import org.springframework.xd.dirt.plugins.job.support.JobLaunchingJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 37	Java Problem Resource leak: 'cache' is never closed	TestKafkaCluster.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/integration/kafka	line 116	Java Problem The value of the field StreamDeployer.parser is not used	StreamDeployer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream	line 42	Java Problem The import org.springframework.batch.core.repository.support.SimpleJobRepository is never used	RuntimeBatchConfigurer.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/batch	line 31	Java Problem The method endPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 555	Java Problem The method startPos(Iterable<Token>) from the type StreamConfigParser is never used locally	StreamConfigParser.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/stream/dsl	line 546	Java Problem The expression of type AbstractInstancePersistingDeployer<D,I> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 268	Java Problem The expression of type AbstractInstancePersistingDeployer<D,I> is already an instance of type AbstractInstancePersistingDeployer	XDController.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/rest	line 217	Java Problem Resource leak: 'context' is never closed	SparkStreamingChannel.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 45	Java Problem The value of the field StreamConfigParserTests.zooKeeperConnection is not used	StreamConfigParserTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/stream/dsl	line 63	Java Problem The value of the field JobPluginTests.deploymentProperties is not used	JobPluginTests.java	/spring-xd-dirt/src/test/java/org/springframework/xd/dirt/plugins/job	line 94	Java Problem The import org.springframework.xd.spark cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 41	Java Problem SparkStreamingSupport cannot be resolved	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 68	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 79	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 81	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 97	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 99	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 100	Java Problem The value of the field ModuleTypeConversionPlugin.logger is not used	ModuleTypeConversionPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/stream	line 45	Java Problem SparkStreamingSupport cannot be resolved to a variable	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 82	Java Problem SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 87	Java Problem The method getComponent(Class<SparkStreamingSupport>) from the type Module refers to the missing type SparkStreamingSupport	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem SparkStreamingSupport cannot be resolved to a type	SparkStreamingPlugin.java	/spring-xd-dirt/src/main/java/org/springframework/xd/dirt/plugins/spark/streaming	line 90	Java Problem  {code}",3
"Support Partitioned Batch Jobs with a LocalMessageBus
Initial support for partitioned batch jobs (initially tested with a local bus) had an {{ExecutorChannel}} in the job context to enable multiple partitions to run. Otherwise, with a local bus, only one partition would run at a time.    When further work was done to support other buses, this was removed and the bus was used to control partition concurrency.    The {{LocalMessageBus}} was changed to use an unbounded task executor; this was wrong because now all partitions ran at once.    Further changes to the local bus changed the task executor to be pooled, but with default properties that mean only one thread is used.    Further, the pool configuration is bus-wide so you can't use that configuration to select the concurrency for an individual job.    The bottom line is that the local bus is not suitable for partitioned batch jobs; it was not anticipated that it would be used for this scenario. With 1.0.x too many partitions run (all); with 1.1.x only one thread runs (by default).    In the local bus, we need to use a configurable, dedicated, bounded task executor for each batch job. ",5
"Error when creating job from UI with security
As a user, I logged in with ROLE_CREATE and I get an error while trying job creation from admin_ui. I can create job from the shell successfully. Trying the same workflow with ROLE_ADMIN results with the same error as well. I don't see anything in the admin/container logs about the error itself. ",1
"Shell: Strange behavior when not logged in
If not properly logged-in you will see errors like this one: ""Command 'module list' was found but is not currently available (type 'help' then ENTER to learn about this command)""  It should possible state something like: ""You don't have the credentials to execute the respective command. Please ensure that you are properly authenticated and have the necessary security roles.""",3
"Shell: Improve Login/Authentication Capabilities
Currently the shell does not automatically detect whether authentication for the targeted admin server is necessary.   Upon start, or change of the admin server URL, the shell should check the requirements, and if necessary prompt the user to provide credentials.   There is also a REST endpoint that could be used for that:  {code} http://localhost:9393/security/info {code}  See also XD-2870 for reference. ",5
"Able to bypass authorization checks by appending "".json"" or "".xml""
How to reproduce:    1) Enable security  2) Use a user that has the following role only: ""ROLE_CREATE""  3) Make a normal REST call:    {code}  http://localhost:9393/runtime/containers  {code}    yields the *desired response*:    {code}      {         ""timestamp"": ""2015-03-26T16:51:17.010Z"",         ""status"": 403,         ""error"": ""Forbidden"",         ""message"": ""Access is denied"",         ""path"": ""/runtime/containers""      }  {code}    Now try:    {code}  http://localhost:9393/runtime/containers.json  {code}    This produces:    {code}          {         ""links"":         [             {                 ""rel"": ""self"",                 ""href"": ""http://localhost:9393/runtime/containers{?page,size,sort}""             }         ],         ""content"":         [             {                 ""containerId"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1"",                 ""groups"": """",                 ""deploymentSize"": 0,                 ""deployedModules"":                 [                 ],                 ""messageRates"": null,                 ""attributes"":                 {                     ""ip"": ""10.0.1.119"",                     ""host"": ""INTEGRATION.local"",                     ""groups"": """",                     ""pid"": ""52686"",                     ""id"": ""86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                 },                 ""links"":                 [                     {                         ""rel"": ""self"",                         ""href"": ""http://localhost:9393/runtime/containers/86eea5aa-b18e-41c5-a3f5-42dfa10713c1""                     }                 ]             }         ],         ""page"":         {             ""size"": 20,             ""totalElements"": 1,             ""totalPages"": 1,             ""number"": 0         }      }  {code}",3
"Creating Streams sporadically using Kafka as a message bus throws TopicNotFound exception
XD Version Spring XD 1.1.1.Release  1 Admin on own (on-metal) Rackspace machine  2 Containers each having own (on-metal) rackspace machine  1 zookeeper node collocated with admin    While executing XD performance testing on Rackspace using Kafka as a transport we occasionally get the following exception:  {noformat}  2015-03-26 18:36:30,677 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Path cache event: path=/deployments/modules/allocated/4c3c9ccf-44db-4772-87c2-70c63b82c3aa/foo3.sink.throughput.1, type=CHILD_ADDED  2015-03-26 18:36:30,685 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module 'throughput' for stream 'foo3'  2015-03-26 18:36:30,820 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@19f0b0a6 moduleName = 'throughput', moduleLabel = 'throughput', group = 'foo3', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = sink, parameters = map[[empty]], children = list[[empty]]]  2015-03-26 18:36:31,372 1.1.1.RELEASE ERROR DeploymentsPathChildrenCache-0 server.DeploymentListener - Exception deploying module  org.springframework.integration.kafka.core.TopicNotFoundException: No topic named 'foo3.0' found    org.springframework.integration.kafka.core.DefaultConnectionFactory.getPartitions(DefaultConnectionFactory.java:209)    org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.createKafkaConsumer(KafkaMessageBus.java:640)    org.springframework.xd.dirt.integration.kafka.KafkaMessageBus.bindConsumer(KafkaMessageBus.java:454)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindMessageConsumer(AbstractMessageBusBinderPlugin.java:275)    org.springframework.xd.dirt.plugins.AbstractMessageBusBinderPlugin.bindConsumerAndProducers(AbstractMessageBusBinderPlugin.java:158)    org.springframework.xd.dirt.plugins.stream.StreamPlugin.postProcessModule(StreamPlugin.java:73)    org.springframework.xd.dirt.module.ModuleDeployer.postProcessModule(ModuleDeployer.java:238)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:218)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)    org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)    org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)    org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  {noformat}    stream used to create the exception:  stream create foo4 --definition ""load-generator --messageSize=1000 --messageCount=10000000 | throughput"" --deploy    After failed deployment.  I destroy the stream and recreate it and it works fine.",3
"Improve the enforcement of meta-properties being set in build.gradle
Last Sync Errors: Invalid POM: /org/springframework/xd/spring-xd-module-parent/1.1.1.RELEASE/spring-xd-module-parent-1.1.1.RELEASE.pom: Developer information missing Invalid POM: /org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE/spring-xd-module-plugin-1.1.1.RELEASE.pom: Project name missing, Project description missing, Project URL missing, License information missing, SCM URL missing, Developer information missing Missing: no javadoc jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Missing: no sources jar found in folder '/org/springframework/xd/spring-xd-module-plugin/1.1.1.RELEASE' Dropping existing partial staging repository.",5
"XD Shell support for accessing HA namenode
We need a convenient way for the shell to access a HA namenode",3
"Update Documentation Link
{code}  _____                           __   _______ /  ___|          (-)             \ \ / /  _  \ \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |  `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | | /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ / \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/       | |                  __/ |       |_|                 |___/ 1.1.1.RELEASE                    eXtreme Data   Started : ContainerServerApplication Documentation: https://github.com/spring-projects/spring-xd/wiki {code}  This should probably be changed to:  Documentation: http://docs.spring.io/spring-xd/docs/1.1.1.RELEASE/reference/html/  ",1
"Refactor deployment interfaces/class hierarchy
As a pre-requisite for XD-2835 and a continuation of XD-2671, split apart the concepts of repository and deployment. This will affect the {{ResourceDeployer}} interface and the classes that implement it.",8
"Using a newer version of a spring-xd dependency is ignored in packaging 
When creating a new module with a dependeny which has a newer version than the one Spring-xd uses (in my example I use Jedis 2.6.1 and Spring-xd uses Jedis 2.5.2) the packaging ignores the dependency.  Using the solution of spring-boot-maven-plugin, doesn't help because it will only include what you explicitly add to the include section (transitive dependencies are not included)",3
"Add support for explicit partition count configuration for Kafka bus
As a developer, I'd like to add support for explicit partition count configuration, so I can use this option to cleverly route the payload to the intended consumer (module).",5
"Add support for dynamic partition subscription for Kafka source
As a developer, I'd like to add support for dynamic partition subscription for the Kafka source module, so I can consume the payload from dynamic partitions.",5
"Identify and fix dependency conflicts in DIRT CP
As a developer, I need to investigate the differences in dependency versions, so when I create/deploy custom modules in XD, I don't run into CP/CL issues.",1
"Provide an option for hdfs sink to use ""Syncable"" writes
As a user, I'd like to have an option to have the hdfs sink use ""Syncable"" writes to provide better resiliency in the case of sink/container failures. I'm willing to accept the performance penalty if I choose this option. ",3
"Provide an option for hdfs sink to not use tmp extension
As a user, I'd like to have an option to have the hdfs sink not use a temporary inUseSuffix like .tmp. Instead we should write using the filename specified directly. This could be useful if we use ""Syncable"" writes and the sink fails while the file is open. Without this new option the user would have to explicitly rename the file.",5
"Document dynamic classpath feature
nan",3
"Only ship relevant modules files
The current build ships everything that is found in the modules directory, including build artifacts such as build/ or IDEA *.iml files.    Restrict the build to only include config/, lib/ at the moment.",1
"Stream data from fitbit API which uses Oauth to HDFS 
I am using the XD shell to create a stream that pulls from an Oauth source to HDFS as my sink. Does Spring XD have some standard approach to this? Here were some thoughts   1.Use http source with mappedRequestHeaders.(Not sure how to pass the OAuth here) 2.Create HttpOutboundGateway that will execute a GET request. 3.Code a new twitter like source and build the source code. ",1
"Have a version of GET /modules that returns full info
Similar to the DetailedModuleDefinitionResource that is returned when querying a single module, but would be returned when listing (provided a ?full flag has been turned on)",3
"Add a gradle/maven target to upload the custom module jar
As a user, I'd like to also have the capability to upload the custom module through maven/gradle targets, so I can automate the installation of custom module fragments.",2
"Add support for custom module versioning 
As a user, I'd like to have the option to version the custom modules, so I can evolve the custom module fragments in increments and be able to roll-out upgrades seamlessly.",5
"Add support to ready files line by line
As a user, I'd like to have the option to read the file line by line, so I get the optional OOTB optimum file reading experience.",8
"Provide an --override option to the module upload command
When uploading a new version of a module the admin container if there is already an existing module, the behavior should be to delete the existing contents of the module directory and replace it with that of the new upload jar.    This would be an optional parameter.",3
"Add support for PHD 3.0 
As a developer, I'd like to certify Spring XD against PHD 3.0, so I can synchronize with the latest ODP based bits. ",3
"Properly render defaults for ""module info"" that use \n \t etc.
Characters line \t, \n, etc. should be either escaped, or rendered as human readable variants in module info (eg <newline>)",2
"UX enhancements for trigger source
Add early validation for cron expression Ease validation of maxOne/atLeastOne mutually exclusive options",2
"Password for Sqoop Job definition is in the open
While creation sqoop and providing the password for the sqoop jobs the guid does not mask the password with a '*********'.",5
"Add support to capture errors/stacktrace via DLQ
As a user, I'd like to have the configuration option to use an alternative DLQ, so I can publish the message this time with additional headers, including one that contains the exception (and stack trace).  ",3
"Add support to consume database changes as event streams
As a user, I'd like to have the OOTB module to consume database changes as event streams, so I can incrementally synchronize with real-time DB updates with various destinations such as Brokers, Hadoop, DB, etc. ",8
"XD Shell should be configurable for accessing secure cluster
There doesn't seem to be a way to configure the XD shell for accessing a kerberos secured cluster.  Tried this: >hadoop config props set --property hadoop.security.authorization=true >hadoop config props set --property hadoop.http.authentication.type=kerberos  still getting: >hadoop fs ls /xd Hadoop configuration changed, re-initializing shell... ls: SIMPLE authentication is not enabled.  Available:[TOKEN, KERBEROS] ",5
"Improve HA support for Rabbit
As a developer, I would like to connect to the broker that hosts the Rabbit queue, so I can connect to a Rabbit cluster that's setup for HA/FT. Perhaps consider having this feature natively supported in spring amqp itself.",3
"Upgrade to latest Gemfire release
As a developer, I'd like to synchronize with the latest Gemfire version (8.1?), so I can leverage the latest Gemfire features and as well support updated BDS stack.    This effort in XD depends on Spring Data Gosling GA release, which in turn depends on Gemfire 8.1 release timelines. ",2
"Add support to deploy stream in a single container
As a developer, I'd like to deploy a stream in the same container, so all modules are colocated within the container. Perhaps also consider building leader election within modules in order to automatically failover the application (stream) from one container to another. ",8
"Upgrade to latest SI release 
As a developer, I'd like to upgrade to SI milestone/GA release, so I can synchronize with JMX improvements.      This is dependent on SI Milestone and GA release timelines.",1
"Upgrade to 1.1.2 SIK release
As a developer, I'd like to upgrade to SI Kafka release, so I can synchronize with latest improvements and bug fixes.  ",1
"Upgrade to Boot 1.2.3 release
As a user, I'd like to upgrade to Spring Boot 1.2.3 release, do I can leverage the latest improvements and bug fixes.    We should also sync-up the following dependency updates to [synchronize with Boot|https://github.com/spring-projects/spring-boot/blob/master/spring-boot-dependencies/pom.xml]:  {code}  <logback.version>1.1.3</logback.version>  <jackson.version>2.5.1</jackson.version>  <gemfire.version>8.0.0</gemfire.version>  <h2.version>1.4.185</h2.version>  <javax-mail.version>1.5.3</javax-mail.version>  <undertow.version>1.2.3.Final</undertow.version>  <joda-time.version>2.7</joda-time.version>  <nekohtml.version>1.9.21</nekohtml.version>  <activemq.version>5.11.1</activemq.version>  <antlr2.version>2.7.7</antlr2.version>  <commons-dbcp2.version>2.0.1</commons-dbcp2.version>  <tomcat.version>8.0.21</tomcat.version>  <aspectj.version>1.8.5</aspectj.version>  <groovy.version>2.4.3</groovy.version>  <crashub.version>1.3.1</crashub.version>  <jetty.version>9.2.9.v20150224</jetty.version>  <elasticsearch.version>1.4.4</elasticsearch.version>  <flyway.version>3.2.1</flyway.version>  <freemarker.version>2.3.22</freemarker.version>  <jdom2.version>2.0.6</jdom2.version>  <liquibase.version>3.3.2</liquibase.version>  <mockito.version>1.10.19</mockito.version>  mongodb.version>2.13.0</mongodb.version>  <slf4j.version>1.7.11</slf4j.version>  <spring-cloud-connectors.version>1.1.1.RELEASE</spring-cloud-connectors.version>  <spring-security.version>4.0.1.RELEASE</spring-security.version>  <jedis.version>2.6.2</jedis.version>  <spring-ws.version>2.2.1.RELEASE</spring-ws.version>  {code}",1
"Complete remaining work for the DEBS challenge
As a developer, I'd like to complete the remaining work with DEBS challenge, so I can submit by the deadline.",2
"Create a new CI build to verify 'install' target
As a developer, I'd like to add a new CI build to include _install_ target, so I can verify the target expectations, as it is often time consuming to verify it in the development environment.",2
"Create a reference architecture for high throughput RT analytics using XD and Kafka
As a developer, I'd like to have the XD + Kafka POC published in samples repo, so I can include it as reference architecture for the XD blog.",5
"Acceptance Tests needs to wait for JobDefinitionResources to be populated 
After the Introduction to XD-2861 the acquisition of JobResources takes more time.  We have to introduce a pause to wait for getJobDefinitionResource to be populated. ",5
"Produce Kafka Baseline numbers on Rackspace
nan",5
"Revisit benchmark matrix for Sqoop vs. jdbshdfs jobs
As a developer, I'd like to revisit performance benchmarks with new improvements, so I can verify the optimizations around _jdbchdfs_.",1
"Improve performance of TupleBuilder 
As a developer, I'd like to bench test cases around {{TupleBuilder}}, so I can identify the bottlenecks and tune for performance optimizations. ",8
"Simplify GPDB UX around parameters for the Sqoop job
As a developer, I'd like to have a simplified UX around parameters for GPDB, so I don't have to escape each parameter. The scope is also to test the Sqoop job with SQLServer and GPDB to identify the UX differences.",8
"Create a pluggable runtime SPI
As a developer, I'd like to migrate module deployment from the ""repository"" abstraction (used for stream/job definitions), so I can create it as a pluggable runtime SPI.",8
"Create Boot based ModuleRunner
As a developer, I'd like to build isolated Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without the hard requirement for running _xd-containers_.",8
"Create a Java client for Receptor
As a developer, I'd like to create a [java client|https://github.com/markfisher/receptor-client] for Receptor, so I can interact with Diego runtime via Receptor API calls from XD. ",8
"Refactor stream/job definition repository
As a developer, I'd like to refactor stream/job definition repository, so I can decouple from module deployment concerns.",8
"Define pluggable runtime SPI
As a developer, I'd like to define pluggable runtime SPI, so I have the option to choose the implementation based on deployment targets such as CF, on-prem, Mesos etc.",5
"Create persistent stream repository
As a developer, I'd like to create persistent repository for streams, so I could leverage the persisted metadata and reestablish the streaming pipe under failure conditions.",5
"Dynamic router should allow to discard messages
Currently dynamic router sink has to return a valid queue name. This is problematic when the message should be discarded as part of the routing process. In this case one have to define a stream with {{filter | router}} steps where part of the SpEL is duplicated between {{filter}} and {{router}} modules.    Instead the dynamic router should allow to return null to discard the message and stop further processing. Spring Integration is already providing {{resolution-required}} attribute on {{<router/>}}. ",2
"Clarify the use of escape quotes for properties in the Sqoop job
As a developer, I'd like to add documentation on escape quotes, so when someone using Sqoop job can double escape {{\\\\N}} instead of sending quotes {{'\N'}} to successfully submit the job.",1
"Upgrade Spark version to 1.3.1
As a Spring XD user, I'd like to create streaming pipelines, so I can take advantage of latest specs from both XD and Spark/Spark Streaming.",3
"Not able to connect a pubsub channel to spark streaming module
If a spark streaming module is setup to connect to a pub/sub channel (a topic or a tap channel), then it doesn't bind to it.    For instance, if I have a stream ""ingest"" with a definition ""http | log"" and want to create another stream as,  ""tap:stream:ingest > spark-processor | count"" then this stream doesn't work.",3
"Ability to tap spark streaming processor output
We need to support adding a tap stream that connects to spark streaming processor module's output channel.",3
"Remove usage of dummy() MD in spring-xd-module
This creates a dependency cycle that eclipse can't handle (doesn't discern between scope like IDEA does).  I believe we can get rid of dummy() in tests that are in spring-xd-module  ",2
"module info for a composite should display original definition
nan",3
"Can't use Apache Velocity in custom modules
Creating a custom processor module with Apache Velocity (org.apache.velocity:velocity:1.7) as dependency results in {{java.lang.ClassNotFoundException}} during stream deployment:  {code} 2015-04-08 17:35:32,595 1.1.1.RELEASE  INFO DeploymentsPathChildrenCache-0 server.DeploymentListener - Deploying module [ModuleDescriptor@144d1f50 moduleName = 'custom-velocity-processor', moduleLabel = 'custom-velocity-processor', group = 'velocity-stream', sourceChannelName = [null], sinkChannelName = [null], index = 1, type = processor, parameters = map[[empty]], children = list[[empty]]] 2015-04-08 17:35:32,768 1.1.1.RELEASE  WARN DeploymentsPathChildrenCache-0 support.DefaultListableBeanFactory - FactoryBean threw exception from getObjectType, despite the contract saying that it should return null if the type of its object cannot be determined yet java.lang.NoClassDefFoundError: org/apache/velocity/app/VelocityEngine   org.springframework.ui.velocity.VelocityEngineFactoryBean.getObjectType(VelocityEngineFactoryBean.java:69)   org.springframework.beans.factory.support.FactoryBeanRegistrySupport.getTypeForFactoryBean(FactoryBeanRegistrySupport.java:66)   org.springframework.beans.factory.support.AbstractAutowireCapableBeanFactory.getTypeForFactoryBean(AbstractAutowireCapableBeanFactory.java:795)   org.springframework.beans.factory.support.AbstractBeanFactory.isTypeMatch(AbstractBeanFactory.java:542)   org.springframework.beans.factory.support.DefaultListableBeanFactory.doGetBeanNamesForType(DefaultListableBeanFactory.java:436)   org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:404)   org.springframework.beans.factory.support.DefaultListableBeanFactory.getBeanNamesForType(DefaultListableBeanFactory.java:398)   org.springframework.integration.jmx.config.JmxIntegrationConfigurationInitializer.registerMBeanExporterHelperIfNecessary(JmxIntegrationConfigurationInitializer.java:42)   org.springframework.integration.jmx.config.JmxIntegrationConfigurationInitializer.initialize(JmxIntegrationConfigurationInitializer.java:38)   org.springframework.integration.config.IntegrationConfigurationBeanFactoryPostProcessor.postProcessBeanFactory(IntegrationConfigurationBeanFactoryPostProcessor.java:48)   org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)   org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:177)   org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:606)   org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:462)   org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)   org.springframework.boot.SpringApplication.run(SpringApplication.java:321)   org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)   org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)   org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)   org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)   org.springframework.xd.dirt.server.DeploymentListener.deployModule(DeploymentListener.java:363)   org.springframework.xd.dirt.server.DeploymentListener.deployStreamModule(DeploymentListener.java:332)   org.springframework.xd.dirt.server.DeploymentListener.onChildAdded(DeploymentListener.java:179)   org.springframework.xd.dirt.server.DeploymentListener.childEvent(DeploymentListener.java:147)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)   org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)   org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)   com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)   org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)   org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)   org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)   org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)   java.util.concurrent.FutureTask.run(FutureTask.java:262)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) Caused by: java.lang.ClassNotFoundException: org.apache.velocity.app.VelocityEngine   java.net.URLClassLoader$1.run(URLClassLoader.java:366)   java.net.URLClassLoader$1.run(URLClassLoader.java:355)   java.security.AccessController.doPrivileged(Native Method)   java.net.URLClassLoader.findClass(URLClassLoader.java:354)   java.lang.ClassLoader.loadClass(ClassLoader.java:425)   sun.misc.Launcher$AppClassLoader.loadClass(Launcher.java:308)   java.lang.ClassLoader.loadClass(ClassLoader.java:358) 	... 39 more {code}  Attached is module source code. Executing commands in {{xd-shell-commands.cmd}} file is enough to trigger the exception.  Everything works when velocity jar is placed in {{$XD_HOME/lib}} and excluded from the processor module.",1
"Document the use of nested jobs with example
As a developer, I'd like to document how to nest batch jobs and workflows in XD, so it will be easy for end-users to use it as reference. ",1
"Add configurable HADOOP_USER_NAME support
As a developer, I'd like to configure HADOOP_USER_NAME environment variable to implement and run-as-user for kerberos secured clusters. This would need some additional work in SHDP.",5
"Login page is missing style info when secured
If the admin UI is secured, the login page is displayed without any styles.",1
"yarn/mapred application class path broke.
When copying those xml files to spring xd conf, spring xd doesn't pickup those classpath correctly. those classpath contains ${stack.name}, ${stack.version}. Those were processed correctly inside phd3/hdp, but not in spring xd. ",3
"Parameterize import options for Sqoop
As a user, I'd like to parameterize all Import Options, so I can eliminate the need for {{—args}} option since it gets confusing.",2
"Parameterize codegen options
As a user, I'd like to parameterize CodeGen Options, so I can generate code on the fly as needed.     ",5
"Parameterize Merge Options
As a user, I'd like to parameterize Merge Options, so I can incrementally consume the delta with the help of megastore.   ",5
"Add timeout for Sqoop jobs
As a user, I'd like to have an option to specify _timeout_, so I can expect the job to not run forever if it is in hung state.",3
"xd-admin silently fails if servers.yml is invalid
for example:  {code} xd:   transport: rabbit    messagebus: #    local: #      queueSize:                   2147483647 #      polling:                     1000 #      executor: #        corePoolSize:              0 #        maxPoolSize:               200 #        queueSize:                 2147483647 #        keepAliveSeconds:          60     rabbit: #      compressionLevel:            1             # bus-level property, applies only when 'compress=true' for a stream module             # See java.util.zip.Deflater; 1=BEST_SPEED, 9=BEST_COMPRESSION, ...       default: #        ackMode:                   AUTO             # Valid: AUTO (container acks), NONE (broker acks), MANUAL (consumer acks).             # Upper case only.             # Note: MANUAL requires specialized code in the consuming module and is unlikely to be             # used in an XD application. For more information, see             # http://docs.spring.io/spring-integration/reference/html/amqp.html#amqp-inbound-ack #        autoBindDLQ:               false #        backOffInitialInterval:    1000 #        backOffMaxInterval:        10000 #        backOffMultiplier:         2.0 #        batchBufferLimit:          10000         batchingEnabled:           true #        batchSize:                 100 #        batchTimeout:              5000 #        compress:                  false #        concurrency:               1 #        deliveryMode:              PERSISTENT #        maxAttempts:               3 #        maxConcurrency:            1 #        prefix:                    xdbus.             # prefix for queue/exchange names so policies (ha, dle etc.) can be applied #        prefetch:                  1 #        replyHeaderPatterns:       STANDARD_REPLY_HEADERS,* #        requestHeaderPatterns:     STANDARD_REQUEST_HEADERS,* #        requeue:                   true #        transacted:                false #        txSize:                    1  #    redis: #      headers:             # comman-delimited list of additional (string-valued) header names to transport #      default:             # default bus properties, if not specified at the module level #        backOffInitialInterval:    1000 #        backOffMaxInterval:        10000 #        backOffMultiplier:         2.0 #        concurrency:               1 #        maxAttempts:               3 #   kafka: #      brokers:                                 localhost:9092 #      zkAddress:                               localhost:2181 #      numOfKafkaPartitionsForCountEqualsZero:  10 #      socketBufferSize:                        2097152 #      offsetStoreTopic:                        SpringXdOffsets #      offsetStoreSegmentSize:                  25000000 #      offsetStoreRetentionTime:                60000 #      offsetStoreRequiredAcks:                 1 #      offsetStoreMaxFetchSize:                 1048576 #      offsetStoreBatchSize:                    200 #      offsetStoreBatchEnabled:                 false #      offsetStoreBatchTime:                    1000 #      offsetUpdateTimeWindow:                  10000 #      offsetUpdateCount:                       0 #      offsetUpdateShutdownTimeout:             2000       default:         batchingEnabled:           true {code}",2
"Sqoop - Unable to create job using MERGE command
As a user, I need to use XD Sqoop module to support the merge command.  Currently, the SqoopRunner createFinalArguments method forces the requirement for connect, username and password options which are not valid for the merge option. A check of the module type to not force these options being assigned to sqoop arg list would be preferred",5
"Force and validate information on OOTB modules
In line with the checks we do for options documentation.  Currently made more complicated than it should because of rogue folders (such as scripts/ and analytics-pmml/ in the registry)",2
"Failure to get message rates for modules with labels.
Start XD distributed XD with specified management port and  xd:    messageRateMonitoring:      enabled: true  in servers.yml  to gather stats.    Create stream {{file | log}}, deploy it, navigate to Containers tab in Admin UI. Rates are shown correctly.  Create stream {{MYFILE: file | log}}, deploy it, navigate to Containers tab in Admin UI - none of the message rates are shown. Open browser dev tools console and note 500 error response.    spring-xd-dirt -> ContainersController lines 109-112 creates request to get message rates for modules.   Typical request:  {{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=log.*,component=*,name=input/MeanSendRate}}    Typical response:  {code:json}  {""request"":{""mbean"":""xd.str4:component=*,module=log.1,name=input"",""attribute"":""MeanSendRate"",""type"":""read""},""value"":{""xd.str4:component=MessageChannel,module=log.1,name=input"":{""MeanSendRate"":0.0}},""timestamp"":1428675070,""status"":200}  {code}    For file module with label `MYFILE` the request is:  {{http://192.168.0.10:9292/management/jolokia/read/xd.str4:module=MYFILE.*,component=*,name=output/MeanSendRate}}    Response:  {code:json}  {""mbean"":""xd.str4:component=*,module=MYFILE.1,name=output"",""attribute"":""MeanSendRate"",""type"":""read""},""stacktrace"":""javax.management.InstanceNotFoundException: No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes\n\tat org.jolokia.handler.ReadHandler.searchMBeans(ReadHandler.java:160)\n\tat org.jolokia.handler.ReadHandler.fetchAttributesForMBeanPattern(ReadHandler.java:126)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:116)\n\tat org.jolokia.handler.ReadHandler.doHandleRequest(ReadHandler.java:37)\n\tat org.jolokia.handler.JsonRequestHandler.handleRequest(JsonRequestHandler.java:160)\n\tat org.jolokia.backend.MBeanServerHandler.dispatchRequest(MBeanServerHandler.java:97)\n\tat org.jolokia.backend.LocalRequestDispatcher.dispatchRequest(LocalRequestDispatcher.java:98)\n\tat org.jolokia.backend.BackendManager.callRequestDispatcher(BackendManager.java:411)\n\tat org.jolokia.backend.BackendManager.handleRequest(BackendManager.java:158)\n\tat org.jolokia.http.HttpRequestHandler.executeRequest(HttpRequestHandler.java:197)\n\tat org.jolokia.http.HttpRequestHandler.handleGetRequest(HttpRequestHandler.java:86)\n\tat org.jolokia.http.AgentServlet$4.handleRequest(AgentServlet.java:435)\n\tat org.jolokia.http.AgentServlet.handleSecurely(AgentServlet.java:320)\n\tat org.jolokia.http.AgentServlet.handle(AgentServlet.java:291)\n\tat org.jolokia.http.AgentServlet.doGet(AgentServlet.java:252)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.springframework.web.servlet.mvc.ServletWrappingController.handleRequestInternal(ServletWrappingController.java:158)\n\tat org.springframework.web.servlet.mvc.AbstractController.handleRequest(AbstractController.java:146)\n\tat org.springframework.boot.actuate.endpoint.mvc.JolokiaMvcEndpoint.handle(JolokiaMvcEndpoint.java:130)\n\tat sun.reflect.GeneratedMethodAccessor82.invoke(Unknown Source)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:483)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)\n\tat org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)\n\tat org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)\n\tat org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)\n\tat org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)\n\tat org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)\n\tat org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)\n\tat org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)\n\tat org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:735)\n\tat org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)\n\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:848)\n\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)\n\tat org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)\n\tat org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)\n\tat org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)\n\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)\n\tat org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)\n\tat org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)\n\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)\n\tat org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)\n\tat org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)\n\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)\n\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)\n\tat org.eclipse.jetty.server.Server.handle(Server.java:370)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)\n\tat org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)\n\tat org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)\n\tat org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)\n\tat org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)\n\tat org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)\n\tat org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)\n\tat org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)\n\tat java.lang.Thread.run(Thread.java:744)\n"",""error_type"":""javax.management.InstanceNotFoundException"",""error"":""javax.management.InstanceNotFoundException : No MBean with pattern xd.str4:module=MYFILE.1,component=*,name=output found for reading attributes"",""status"":404}  {code}    This reponse results in JSONException in the ContainersController because it's missing 'value' property.    The module id is somewhat problematic in the request: {{xd.str4:module=log.*}} index is {{\*}} but should be index within the stream, also node type (source/sink/processor) is missing. Therefore, stream {{mail | mail}} is suffering from the same problem.    Would be nice to have some sort of a bulk request to query more than one module for input/output message rates, such that I could get all message rates for modules in the stream.",3
"Add ftp source to default source modules
It would be nice to have a simple ftp source. I have to do it for one of my projects. Same as XD-2139 but for source modules.",2
"SQL Script Processor
As a users I would to be able to execute SQL Statement/Script via a Processor or Job statement.",3
"twittersearch stream returns duplicate tweets
The twittersearch source module picks up the same tweet in successive iterations of the REST request. The reason for this is that the since_id value being set at the end of each iteration is the last item in the list of tweets, but not the latest value of tweet id.  Steps to reproduce:  Created a stream using below definition  stream create --name twittersearchspring --definition ""twittersearch --consumerKey=<key> --consumerSecret=<secret> --query='spring' | tweet-transformer | file"" --deploy  tweet-transformer referred here is used from the spring-xd-samples repo and is logging the tweet ID being transformed https://github.com/spring-projects/spring-xd-samples/tree/master/tweet-transformer-processor  Below is the log  __________ 2015-04-14 15:47:22,154 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Deployment status for stream 'twittersearchspring': DeploymentStatus{state=deployed} 2015-04-14 15:47:22,158 1.1.0.RELEASE  INFO DeploymentSupervisor-0 server.StreamDeploymentListener - Stream Stream{name='twittersearchspring'} deployment attempt complete 2015-04-14 15:47:24,301 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:24,312 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:24,315 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:24,318 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:24,320 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:24,325 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:24,340 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:24,342 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:24,343 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:24,344 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884737307549696 2015-04-14 15:47:24,346 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884734723702784 2015-04-14 15:47:24,348 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884730059771905 2015-04-14 15:47:24,356 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884729225125888 2015-04-14 15:47:24,358 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884725802405888 2015-04-14 15:47:24,359 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884724938481665 2015-04-14 15:47:26,465 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884724938481665 2015-04-14 15:47:26,865 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:26,867 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:26,869 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:26,871 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:26,872 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:26,878 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:26,880 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:26,882 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:26,884 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752536911873 2015-04-14 15:47:26,886 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884751219986432 2015-04-14 15:47:26,887 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884750620258305 2015-04-14 15:47:26,889 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884749974147072 2015-04-14 15:47:26,890 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884743338917888 2015-04-14 15:47:26,900 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884741493272577 2015-04-14 15:47:26,903 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884739387719680 2015-04-14 15:47:29,004 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884739387719680 2015-04-14 15:47:29,369 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884782945611776 2015-04-14 15:47:29,371 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884781305663488 2015-04-14 15:47:29,374 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884779506311169 2015-04-14 15:47:29,376 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884775895072768 2015-04-14 15:47:29,377 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771893739520 2015-04-14 15:47:29,379 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884771717578753 2015-04-14 15:47:29,384 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884769138081792 2015-04-14 15:47:29,386 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766608916481 2015-04-14 15:47:29,388 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884766072025089 2015-04-14 15:47:29,389 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884765707116544 2015-04-14 15:47:29,390 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884764394299392 2015-04-14 15:47:29,391 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884761366003712 2015-04-14 15:47:29,395 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884759381966849 2015-04-14 15:47:29,399 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884756488032256 2015-04-14 15:47:29,401 1.1.0.RELEASE  INFO twitterSource-1-1 transformer.TweetTransformer - Transforming tweet with id : 587884752591544320 2015-04-14 15:47:31,502 1.1.0.RELEASE DEBUG twitterSource-1-1 twitter.TwitterSearchChannelAdapter - Search uri:https://api.twitter.com/1.1/search/tweets.json?q=spring&since_id=587884752591544320  __________  Notice that tweet ID 587884752591544320 is picked up in second iteration as well although it was picked in the first.   The issue can be fixed in the doSendLine method of  TwitterSearchChannelAdapter.java where this.sinceId is being set to the last value of id. Instead, the statuses map can be sorted on ID, and the highest ID can be set for sinceId.",2
"Externalized RowMapper<Tuple> from the NamedColumnJdbcItemReader
As a user I want to be able to provide my own RowMapper<Tuple> implementation to enrich the jdbc data.   My use case requires me to add timestamp field and a delete flag field to records before they get written to HDFS. To do it, I have to implement a ItemReaderFactory and perhaps extend NameColumnJdbcItemReader. This is to override the afterPropertySet method to change the default implementation.  Otherwise I have to write my own Processor that can add these fields to Tuples, and since tuples are immutable I would have to recreate the tuples with additional fields in the processor. For large load this could be big overhead.  I would love to know any other technique to implement such a use case.",1
"Allow direct binding even for module.count != 0
nan",2
"Add support for expressions and dynamically evaluate at runtime
As a user, I'd like to have the ability to use expressions, so I can dynamically name directories/files based on the timestamp or other intermediate data point.",5
"Document how to specify custom-modules location via Environment variable.
It is possible to specify the location of custom modules via the environment variable {{XD_CUSTOMMODULE_HOME}} which is provided by Spring Boot property key derivation mechanism (in this case derived from {{xd.customModule.home}}).  This allows a user to specify a custom modules location that survives a complete wipe of spring-xd installations.",1
"Error Message for ""Missing Job Description"" needs to be updated
When using the rest interface to create a Job with an empty description, used to generate the following exception, ""Definition can not be empty"".   Now generates ""XD112E:(pos 0): Unexpectedly ran out of input^"".   The correct error should be, ""definition cannot be blank or null""    ",2
"SingleNode Logging for AMQP Listener Container is too Narrow (ERROR)
See https://gopivotal-com.socialcast.com/messages/24095632  However, it was set to ERROR last year to ""reduce log noise"".  I would prefer to elevate to at least WARN in XD and address the ""noise"" issue in Spring AMQP.",1
"Move decision logic for directBinding out of bus to deployer
As the decision for directBinding may become more complicated (see eg XD-2946), move the *decision* part out of the bus, leaving only the *application* there (leveraging a pre-computed property, such as directBind=true).  The computation of that property is to be moved at the deployer level",3
"Escape delimited characters in jdbchdfs job
As as user I want to be able to escape delimiter character. Currently I cannot use this job oob to create CSVs that are usable in Hive/HAWQ because of unescaped delimiters.  ",1
"Get rid of SparkStreamingDriverModule
Code that is in there could be moved to the SparkStreamingModule.    Then, as part of a later refactoring, that plugin should be made part of the module (and loaded by the module classloader)",3
"Refactor MessageBus to avoid unnecessary use of MessageBuilder  
As a developer, I'd like to refactor the programmatic means by which the MessageBus transforms the Message so throughput performance can be optimized.  ",5
"Revisit the requirement for ID and Timestamp attributes in Tuple
As a developer, I'd like revisit the design to determine the necessity for _ID_ and _TimeStamp_ attributes in {{Tuple}}, so I can refactor in order to improve performance throughput.",1
"Create samples and document Kryo optimization guidelines
As a developer, I'd like to document the Kryo optimization guidelines, so the end-users can refer to it while tuning to improve performance.",3
"Upgrade to Kafka 0.8.2
As a developer, I'd like to upgrade to Kafka 0.8.2, so I can leverage the latest features in order to test the performance characteristics.",8
"Create a new load-generator for Tuple
As a developer, I'd like to create a Tuple _load-generator_, so I can use it to measure {{Tuple}} based payload performance. ",3
"Add a new load generator to produce serialized payloads
As a developer, I'd like to create a new _load-generator_, so I can use it to measure highly optimized (kryo serialized) payload to measure the performance differences. ",3
"Benchmark against Kafka 0.8.2 release
As a developer, I'd like to rerun _baseline_, _Tuple_, and _Serialized_ payloads, so I can compare the differences in performance between 0.8.1 and 0.8.2 Kafka releases.     Note:  1.1.1 > Benched against 0.8.1   1.2 > Benched against 0.8.2     ",8
"Document performance benchmark results
As a developer, I'd like to document performance benchmark results along with the infrastructure specifics, so I can publish the blog for customers/users to use it as a reference while setting up Spring XD cluster.",8
"Spike: Come up with a design for stateful stream processing
As a developer, I'd like to study the state management requirements, so I can brainstorm and identify the design to natively add _stateful_ stream processing support in XD. ",8
"Integrate with Spring Data repository
As a developer, I'd like to integrate with Spring Data repository that's backed by Kafka _changelog_, so I can leverage the benefits of local data affinity (off-heap) in order to run stateful stream processing logic. ",8
"Add support to flush offset management 
As a developer, I'd like to add support to _flush_ offsets intelligently, so I can reliably process streams based on successful message acknowledgements from the module-producer. ",8
"Add support to flush local state
As a developer, I'd like to add support to _flush_ state intelligently, so I can reliably process streams based on successful message acknowledgements from the module-producer. ",8
"InfluxDB as an analytics backend
nan",3
"Add a CoAP source module
As a developer, I'd like to have the option of CoAP source module, so I can consume data using bandwidth efficient protocol that fits in constrained embedded environment.",3
"Standardize XD logging to align with Spring Boot
In XD today we use  commons-logging or slf4j  APIs bound to log4j at runtime (configured with log4j.properties).      Boot uses slf4j APIs backed by logback. This causes some build incompatibilities building a component that depends on spring-xd-dirt and spring-boot, requiring specific dependency exclusions.  In order to simplify building and troubleshooting log dependencies, XD should standardize on   slf4j APIs (replace any commons-logging Loggers with Slf4j). This is internal only, and would not impact users who are used to seeing log4j.properties. An additional step is to replace log4j with logback. This change would be visible to end users but will provide us greater affinity with boot and improve the developer experience. If we make this change it should go into 1.2 GA.    ",8
"Document the use of properties file as deployment manifest
As a user, I'd like to refer to the documentation to configure the properties file, so I can use it as recommended to represent the deployment manifest.",1
"STS - Spring XD Imported with Compilation Error
Cannot import Spring XD into STS without compilation errors in class:    *org.springframework.xd.dirt.rest.ModulesController#list*    Error is in:    {code}  return assembler.toResource(page, detailed ? detailedAssembler: simpleAssembler);  {code}    {code}  The method toResource(Page<ModuleDefinition>, Link) in the type PagedResourcesAssembler<ModuleDefinition> is not applicable for the arguments (Page<ModuleDefinition>, (detailed ? detailedAssembler : simpleAssembler))  {code}    Seems to be an STS specific issue.",3
"Run the sqoop job against secured cluster
As a user, I'd like to run the sqoop jobs against secured hdfs cluster, so I can restrict access to only authorized users. ",3
"Getting stuck on hive error.
In Hadoop, while creating Table in hive i am getting stuck in below error  15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=Driver.run from=org.apache.hadoop.hive.ql.Driver> 15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=TimeToSubmit from=org.apache.hadoop.hive.ql.Driver> 15/04/21 12:35:34 INFO log.PerfLogger: <PERFLOG method=acquireReadWriteLocks from=org.apache.hadoop.hive.ql.Driver> 15/04/21 12:35:34 INFO lockmgr.DummyTxnManager: Creating lock manager of type org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager 15/04/21 12:35:34 INFO zookeeper.ZooKeeper: Initiating client connection, connectString=dkhc3013.dcsg.com:2181,dkhc3010.dcsg.com:2181,dkhc3011.dcsg.com:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@5b9e1cd4 15/04/21 12:35:34 DEBUG lockmgr.DummyTxnManager: Adding /incoming/mkt/gcdb.etl_master_account_pref to list of lock inputs 15/04/21 12:35:34 DEBUG lockmgr.DummyTxnManager: Adding database:mkt_incoming to list of lock outputs   After restart the zookeeper service i am able to successfully run the query,  But after some time again facing the same issue/error, I am stuck on the same error.  is there any solution to overcome this issue, or any tuning i can do for resolve this issue.  Please suggest on this.",2
"Incorrect message bus is used at runtime
For some reason, the message bus is bound to incorrect transport (different from what is set as XD_TRANSPORT) at runtime.    This is from the container log:  2015-04-21 13:42:12,331 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: rabbit  ...  2015-04-21 13:42:35,144 1.2.0.SNAP  INFO RedisMessageListenerContainer-4 sink.a2 - test",3
"Allow ""--path=..."" configuration in HTTP channel adapter
Currently, each HTTP stream channel uses its own port, which is a limitation if we want to use large numbers of HTTP streams with fine granularity. It would be nice to (additionally) use URI paths to identify HTTP channels, allowing to re-use a single HTTP port for multiple channels in XD.  Example usage:  stream create --name s1 --definition ""http --port=9495 --path=/foo  | log"" --deploy  For a PoC implementation, see: https://github.com/spring-projects/spring-xd/pull/1538",1
"Routing json arrays
When i create following stream i am able to route json messages. But if i send same message as an array its not working. Is it possible to do something about it?  stream create --name reference-data-import --definition ""rabbit --outputType=text/plain | router --expression=#jsonPath(payload,'$.REJECTED').contains('true')?'queue:Rejected':'queue:Accepted'"" --deploy  ",1
"Submit java receptor client for CF incubation
As a user, I'd like to use the Java receptor client, so I can interact with Diego runtime using the Java receptor REST APIs.",8
"Create Boot based ModuleRunner (phase 2)
As a user, I'd like to use Boot-based {{ModuleRunner}} for use in container-managed environments, so I can run XD without _xd-containers_.    Scope:  * Complete the remaining deployment properties work",8
"Add polling twitter source 
i've created a source module for polling a twitter timeline using the spring integration twitter inbound adapter. I've placed my api keys in the modules.yml file and verified that they are picked up by the twitterstream and twitterseach modules that come with SpringXD. However, they are not picked up by my custom module. I viewed the source for both the stream and and the search and i feel my project is near identical in configuration. Am i missing something or are these properties somehow special for just the two twitter sources that come with SpringXD?  I'd like to get this working and commit it to the project.",1
"Shell processor cannot recover from an Exception
see http://stackoverflow.com/questions/29822845/custom-python-module-can-not-re-excute-when-raise-exception-in-module  ",2
"Blank Container Screen from Admin UI w/ message rates
With message rates enabled and container management enabled, if you deploy a streaming module, the container page may be blank.  Because the streaming module builds the channels outside the spring context (spark receiver is ran in the spark cluster not in xd) there is no need to setup the input and/or output channels.  When these channels aren't defined the rest call from admin UI will fail because it will not find the message rates returned in the JSON from the JMX call.  {code} Advice - Caught exception while handling a request org.codehaus.jettison.json.JSONException: JSONObject[""value""] not found.         at org.codehaus.jettison.json.JSONObject.get(JSONObject.java:360)         at org.codehaus.jettison.json.JSONObject.getJSONObject(JSONObject.java:454)         at org.springframework.xd.dirt.rest.ContainersController.getMessageRate(ContainersController.java:146)         at org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:121) {code}  As a work around, I have included the input and output channels for a spark streaming processor which is not used anywhere.  This gives a bad side affect of looking like the module isn't processing with message rates of 0, but everything else is now shown.",3
"xd-admin script fails when providing --hadoopDistro option
XD-2837 added back the --hadoopDistro option for xd-admin scripts. However, if I try to use it I get an error message saying: ""--hadoopDistro"" is not a valid option  ",3
"Update spring-data-hadoop to version 2.1.2.RELEASE
nan",2
"Experiment with re-parsing of streams when needed
As a follow up to XD-2877, experiment with the removal of the list of modules from BaseDefinition and reparse as needed.    Branch is here: https://github.com/pperalta/spring-xd/tree/deploy-refactor-2",8
"Update acceptance test to use new JMX Module name format
the update to the JMX was introduced in XD-2941.   Also noticed that we should have been checking source and not sink .  This was also resolved.",2
"Issues with custom modules when using module configuration
SpringXD seems to think that a module exists if there is a module configuration present. There is also an issue of having to restart the node when theres been a problem with uploading/removing a module.  When using SpringXD in single node on windows, i uploaded a custom module and then added a folder and property file for it in the module configuration directory as specified in the documentation. When i went to delete the module using the command in the SpringXD admin console, it would say that it was successfull, but when then listing the modules, it would still be listed. If i tried to upload a new version of that same module, i would get an error stating that module already existed with the same name. I would check the custom modules directory and my jar would not be there. I would then have to manually delete the module configuration directory and restart SpringXD before being able to upload a new module, having to replace my module configuration each time.  Seems like there are three things wrong here: * should the presence of a module configuration alone inform SpringXD of a modules existence? * should one have to delete a module configuration before uploading a new version of the module? * when getting module deletion/upload errors, should one have to restart spring xd node to get it to allow the upload again?",1
"Spike: Research the stream support for reliable HDFS writes
As a user, I'd like to have the option of reliable HDFS writes (for stream pipelines), so I can get acknowledgement of actual HDFS _commits_ as opposed to just from the message bus.",5
"Add support to override partition function
As a developer, I’d like override the partition function within my source or processor module, so I can send the data to a specific partition.",5
"Add support for multiple topics in Kafka source
As a user, I'd like to consume multiple topic-partitions, so I can have the option to consume from multiple data endpoints and still be able to serve the data via single queue.",3
"Add a new variation of DSL parser for Flo
As a Flo developer, I'd like to have a new DSL parser, so I can easily  detect incorrect module/option values when supplied from the Flo UI.    Example:  MyStream = mail | log  tap:stream:MyStream.bar > log    If parsed separately (which Flo UI does), the current parser endpoint will barf on the second stream because it doesn’t know about the first stream (MyStream). ",8
"Verify module count works on 10+ Containers
This tests should prove that Kafka can handle a module count greater than one with the proper concurrency settings.  load-generator should be used as the foundation for this test with the following settings:  module.load-generator.count=10,module.throughput.consumer.concurrency=10    An environment should be provisioned to support the containers, Zookeeper and Kafka.  ",3
"Jobs are failing to be deployed
Error Started:  Commit: 7087dc67e058edd6cbb1630ebd95b52e2c7e21e1   https://github.com/spring-projects/spring-xd/pull/1564    This can be reproduced by running the test with a admin and single container on Mac OSX.    Issue All Jobs fail to deploy with the following exception:  {noformat}  /  ___|          (-)             \ \ / /  _  \  \ `--. _ __  _ __ _ _ __   __ _   \ V /| | | |   `--. \ '_ \| '__| | '_ \ / _` |  / ^ \| | | |  /\__/ / |_) | |  | | | | | (_| | / / \ \ |/ /  \____/| .__/|_|  |_|_| |_|\__, | \/   \/___/        | |                  __/ |        |_|                 |___/  1.2.0.BUILD-SNAPSHOT             eXtreme Data      Started : AdminServerApplication  Documentation: https://github.com/spring-projects/spring-xd/wiki    2015-04-27 09:08:51,082 1.2.0.SNAP  WARN main config.IntegrationRegistrar - The '#jsonPath' SpEL function cannot be registered. The version of json-path found on the classpath is not supported. Supported json-path version is '0.9.1'. Upgrade to Spring Integration 4.2 or later to use json-path 1.0 or later.  2015-04-27 09:09:02,767 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD Home: /Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd  2015-04-27 09:09:02,768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Transport: redis  2015-04-27 09:09:02,768 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop Distro: hadoop26  2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Hadoop version detected from classpath 2.6.0  2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//  2015-04-27 09:09:02,771 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD config names: servers,application  2015-04-27 09:09:02,772 1.2.0.SNAP  INFO LeaderSelector-0 zk.DeploymentSupervisor - Leader Admin 172.31.99.83:9393 is watching for stream/job deployment requests.  2015-04-27 09:09:02,773 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config location: file:/Users/glennrenfro/project/spring-xd/build/dist/spring-xd/xd/config//modules/  2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - XD module config name: modules  2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Admin web UI: http://Glenns-MacBook-Pro.local:9393/admin-ui  2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper at: localhost:2181  2015-04-27 09:09:02,775 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Zookeeper namespace: xd  2015-04-27 09:09:02,776 1.2.0.SNAP  INFO main util.XdConfigLoggingInitializer - Analytics: redis  2015-04-27 09:09:02,813 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: type=INITIALIZED  2015-04-27 09:09:02,845 1.2.0.SNAP  INFO main admin.AdminServerApplication - Started AdminServerApplication in 6.777 seconds (JVM running for 14.213)  2015-04-27 09:09:04,010 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Path cache event: path=/containers/dc7692b1-979b-4fa3-a11a-3f35cdedc319, type=CHILD_ADDED  2015-04-27 09:09:04,017 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Container arrived: Container{name='dc7692b1-979b-4fa3-a11a-3f35cdedc319', attributes={groups=, host=Glenns-MacBook-Pro.local, id=dc7692b1-979b-4fa3-a11a-3f35cdedc319, managementPort=9395, ip=172.31.99.83, pid=99669}}  2015-04-27 09:09:04,018 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ContainerListener - Scheduling deployments to new container(s) in 15000 ms  2015-04-27 09:10:35,003 1.2.0.SNAP  INFO DeploymentSupervisor-0 zk.ZKJobDeploymentHandler - Deployment status for job 'tfphj4ffb45d5-0d6c-4f22-b407-c313ce82b449': DeploymentStatus{state=failed,error(s)=org.springframework.beans.factory.BeanDefinitionStoreException: Invalid bean definition with name 'objectNameProperties' defined in null: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""; nested exception is java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""    org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:211)    org.springframework.context.support.PropertySourcesPlaceholderConfigurer.processProperties(PropertySourcesPlaceholderConfigurer.java:180)    org.springframework.context.support.PropertySourcesPlaceholderConfigurer.postProcessBeanFactory(PropertySourcesPlaceholderConfigurer.java:155)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:265)    org.springframework.context.support.PostProcessorRegistrationDelegate.invokeBeanFactoryPostProcessors(PostProcessorRegistrationDelegate.java:162)    org.springframework.context.support.AbstractApplicationContext.invokeBeanFactoryPostProcessors(AbstractApplicationContext.java:606)    org.springframework.context.support.AbstractApplicationContext.refresh(AbstractApplicationContext.java:462)    org.springframework.boot.SpringApplication.refresh(SpringApplication.java:691)    org.springframework.boot.SpringApplication.run(SpringApplication.java:321)    org.springframework.boot.builder.SpringApplicationBuilder.run(SpringApplicationBuilder.java:139)    org.springframework.xd.module.core.SimpleModule.initialize(SimpleModule.java:214)    org.springframework.xd.dirt.module.ModuleDeployer.doDeploy(ModuleDeployer.java:217)    org.springframework.xd.dirt.module.ModuleDeployer.deploy(ModuleDeployer.java:200)    org.springframework.xd.dirt.server.container.DeploymentListener.deployModule(DeploymentListener.java:365)    org.springframework.xd.dirt.server.container.DeploymentListener.deployJobModule(DeploymentListener.java:291)    org.springframework.xd.dirt.server.container.DeploymentListener.onChildAdded(DeploymentListener.java:181)    org.springframework.xd.dirt.server.container.DeploymentListener.childEvent(DeploymentListener.java:149)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:509)    org.apache.curator.framework.recipes.cache.PathChildrenCache$5.apply(PathChildrenCache.java:503)    org.apache.curator.framework.listen.ListenerContainer$1.run(ListenerContainer.java:92)    com.google.common.util.concurrent.MoreExecutors$SameThreadExecutorService.execute(MoreExecutors.java:297)    org.apache.curator.framework.listen.ListenerContainer.forEach(ListenerContainer.java:83)    org.apache.curator.framework.recipes.cache.PathChildrenCache.callListeners(PathChildrenCache.java:500)    org.apache.curator.framework.recipes.cache.EventOperation.invoke(EventOperation.java:35)    org.apache.curator.framework.recipes.cache.PathChildrenCache$10.run(PathChildrenCache.java:762)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)    java.util.concurrent.FutureTask.run(FutureTask.java:262)    java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)    java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)    java.lang.Thread.run(Thread.java:745)  Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder 'xd.stream.name' in string value ""${xd.stream.name}""    org.springframework.util.PropertyPlaceholderHelper.parseStringValue(PropertyPlaceholderHelper.java:174)    org.springframework.util.PropertyPlaceholderHelper.replacePlaceholders(PropertyPlaceholderHelper.java:126)    org.springframework.core.env.AbstractPropertyResolver.doResolvePlaceholders(AbstractPropertyResolver.java:204)    org.springframework.core.env.AbstractPropertyResolver.resolveRequiredPlaceholders(AbstractPropertyResolver.java:178)    org.springframework.context.support.PropertySourcesPlaceholderConfigurer$2.resolveStringValue(PropertySourcesPlaceholderConfigurer.java:175)    org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveStringValue(BeanDefinitionVisitor.java:282)    org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:204)    org.springframework.beans.factory.config.BeanDefinitionVisitor.visitMap(BeanDefinitionVisitor.java:262)    org.springframework.beans.factory.config.BeanDefinitionVisitor.resolveValue(BeanDefinitionVisitor.java:198)    org.springframework.beans.factory.config.BeanDefinitionVisitor.visitPropertyValues(BeanDefinitionVisitor.java:141)    org.springframework.beans.factory.config.BeanDefinitionVisitor.visitBeanDefinition(BeanDefinitionVisitor.java:82)    org.springframework.beans.factory.config.PlaceholderConfigurerSupport.doProcessProperties(PlaceholderConfigurerSupport.java:208)  	... 31 more  }  {noformat}",1
"Align Spring XD partitioning with Kafka partitioning for the Kafka message bus
As a developer, I want that the Spring XD partitioning process targets Kafka bus partitions directly, so that the design of my stream processing application is easier to understand and the order of messages is not altered    Current situation  - Spring XD partitioning logic that builds on top of Kafka partitioning;  - The number of Spring XD partitions is not explicitly configured (it's inferred from the number of consumer modules)  - If the concurrency of the consumer modules is 1, then Spring XD partitions are matched 1:1 with Kafka partitions;  -  If the concurrency of the consumer modules is n, then a Spring XD partition uses n Kafka partitions, and the message bus distributes messages across the Kafka partitions that correspond to the Spring XD partitions;  - this could be confusing to the end user, especially if they are used to the Kafka partitioning process;  - this can also lead to changes of ordering between messages, as messages within the same Spring XD partitions will be sent to different Kafka partitions (this only happens if the concurrency of the receiving module is higher than 1)    Improvement:  - *For the Kafka message bus* the number of Spring XD partitions does not need to be equal to the number of modules (must be higher or equal, though, so that consumers can be created), and should be configured explicitly - using the `partitionCount` property - (as an option, the module count * concurrency can be used as a default)   - as a result, in the case of Kafka there will always be a 1:1 match between Kafka partitions and Spring XD partitions, optionally processed by fewer modules than the partition count;",5
"Deploy stream in a single xd-container
As a developer, I'd like to design and document the approach towards deploying stream in a single container, so I can have all modules within a stream colocated.   ",5
"TupleCode should retain custom formatting settings
As a developer, I'd like to handle the non-default {{ConfigurableConversionService}} tuples in an uniform manner, so they're not reset after deserialization. ",5
"Benchmark with and without JMX activated
As a developer, I'd like to benchmark a stream with and without {{JMX}} enabled, so I can test in isolation, and document the differences in performance.",3
"Enhance TupleCodec performance
Profile TupleCodec and implement performance optimizations",5
"Unable to call Sqoop Job commands other than --create from within Spring-Xd Job
Running a (SQOOP Job --create) from within (Spring-XD JOB create) statement runs successfully.Unable to run the (Sqoop Job --exec) from within (Spring-XD Job)    CREATE DEFINITION:  job create sqoop_lookup_d_job_v1 --definition ""sqoop --command=job  --args='--create lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx\"" -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query \""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), ''-'')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), ''-'')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), ''-'')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), ''-'')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND $CONDITIONS\"" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by \""|\"" --append'""    Validated job definition details stored in PostgreSQL repository    Trying to run EXECUTE In Same fashion.    EXECUTION DEFINITION:  job create sqoop_lookup_d_exec_v1 --definition ""sqoop --command=job --args='--exec lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxx\""'""      Stack Trace:  batch.stepType	org.springframework.batch.core.step.tasklet.TaskletStep  batch.taskletType	org.springframework.xd.sqoop.SqoopTasklet  sqoop.command	job --exec lookupd_job --meta-connect ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxx&password=xxxxxxx"" -- exec  sqoop.errors	No job operation specified  Try --help for usage instructions.  Exception in thread ""main"" java.lang.RuntimeException: Sqoop failed - return code 1  at org.springframework.xd.sqoop.SqoopRunner.main(SqoopRunner.java:81)  sqoop.log	16:01:45,668 INFO main sqoop.SqoopRunner - Sqoop command: job  16:01:45,668 INFO main sqoop.SqoopRunner - Using args: [--exec, lookupd_job, --meta-connect, ""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxxxx&password=xxxxx""]  16:01:45,668 INFO main sqoop.SqoopRunner - Mapreduce home: /opt/pivotal/spring-xd-1.1.1.RELEASE/xd/lib/phd21  16:01:45,679 INFO main sqoop.SqoopRunner - Setting configuration property: fs.defaultFS=hdfs://xxxxxxxxxxxxx.com:8020  16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.resourcemanager.address=xxxxxxxxxxxx.com:8032  16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: yarn.application.classpath=$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*,$USS_HOME/*,$USS_CONF  16:01:45,759 INFO main sqoop.SqoopRunner - Setting configuration property: mapreduce.framework.name=yarn  16:01:45,817 WARN main tool.SqoopTool - $SQOOP_CONF_DIR has not been set in the environment. Cannot check for additional configuration.  16:01:45,863 INFO main sqoop.Sqoop - Running Sqoop version: 1.4.5    I have tested --list, --exec,--delete they are all erroring same way. Looking at SqoopRunner not sure what makes --create any different from other saved-job functionality.    Please let me know how i can call or execute save job definition's through spring-xd Sqoop tasklet  ",5
"Support Spark streaming processor/sink specific module options
Currently, the module options provided for Spark streaming processor/sink modules use the same DefaultSparkStreamingModuleOptionsMetadata. Since we start adding new module options for processor/sink specific modules, it would be better if we expose specific ModuleOption classes so that would help the implementing developers.",3
"Add support for using Sqoop metastore
As a user, I'd like to have the option to change the default Sqoop _metastore_, so I can implement a DB of my choice and not tied to default specifications.    Refer to this [thread|http://stackoverflow.com/questions/24078668/how-to-change-sqoop-metastore] for more details. ",1
"Detailed module list performance improvement
The call to /modules?detailed=true that was introduced for Flo proves to be a performance hog, most certainly because of all the metadata resolution that has to occur there (and no caching takes place)",3
"spring-xd services randomly report failure after correct shutdown
On multiple occasions we have seen that {{spring-xd-container}} and {{spring-xd-admin}} services can exit reporting {{FAILED}} state, however most of the times the Java process is correctly terminated.  {code} $ sudo service spring-xd-container stop Stopping xd-container:                                     [FAILED] $ ps uax | grep [x]d-container $ {code}  and in the container logs:  {code} [info 2015/04/28 09:42:15.167 EDT  <Distributed system shutdown hook> tid=0x88] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.168 EDT  <Distributed system shutdown hook> tid=0x88] GemFireCache[id = 2029162775; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:34 EDT 2015; se  [info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.171 EDT  <Distributed system shutdown hook> tid=0x53] GemFireCache[id = 389249684; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:14 EDT 2015; ser  [info 2015/04/28 09:42:15.177 EDT  <Distributed system shutdown hook> tid=0x77] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.179 EDT  <Distributed system shutdown hook> tid=0x77] GemFireCache[id = 1768828050; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:27 EDT 2015; se  [info 2015/04/28 09:42:15.181 EDT <Distributed system shutdown hook> tid=0x63] VM is exiting - shutting down distributed system  [info 2015/04/28 09:42:15.199 EDT <Distributed system shutdown hook> tid=0x63] GemFireCache[id = 548938309; isClosing = true; isShutDownAll = false; closingGatewayHubsByShutdownAll = false; created = Mon Apr 27 10:59:19 EDT 2015; serv 2015-04-28 09:42:15,410 1.1.1.RELEASE DEBUG xdbus.queue:radius-1 transform.RadiusMsgTransformer - Transformed message: GenericMessage [payload=FACILITY=22, SEVERITY=5, TIMESTAMP=Tue Apr 28 09:42:15 EDT 2015, HOST=hopisepsnprd01, Messa  [info 2015/04/28 09:42:15.626 EDT  <Distributed system shutdown hook> tid=0x53] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.630 EDT  <Distributed system shutdown hook> tid=0x77] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.621 EDT  <Distributed system shutdown hook> tid=0x88] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen  [info 2015/04/28 09:42:15.662 EDT <Distributed system shutdown hook> tid=0x63] Resetting original MemoryPoolMXBean heap threshold bytes 0 on pool PS Old Gen 2015-04-28 09:42:15,854 1.1.1.RELEASE  WARN Thread-4 support.DisposableBeanAdapter - Invocation of destroy method failed on bean with name 'client-pool': java.lang.IllegalStateException: Pool could not be destroyed because it is still  [config 2015/04/28 09:42:15.857 EDT <Thread-4> tid=0x12] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.897 EDT  <Thread-4> tid=0x12] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.898 EDT  <Distributed system shutdown hook> tid=0x53] Destroying connection pool client-pool  [config 2015/04/28 09:42:15.908 EDT  <Distributed system shutdown hook> tid=0x88] Destroying connection pool client-pool {code}",1
"db.password not being passed when Sqoop job --create called from Spring-XD Batch job
Created a single definition Sqoop Job --create statement. When processed through Sqoop direct (see attach image for props in repos. jobname sqoop2)   Notice: job definition set db.require.password = false and has a propname called db.password that holds the value for password.   When same definition is created as a batch job via Spring-XD (see image jobname lookupd_job), the db.require.password prop is set to ""TRUE"" and the db.password is not even created as a row.  This causes a password prompt when trying to execute the job in Sqoop direct, that was created via a spring-XD batch job.   Note the job definition for Spring-XD job contains meta-connect with username and password defined as well as import jdbc: --connect username and password. When created via Sqoop (no Spring-XD) password is stored and job is able to execute with no prompt.  Please see attachment for repository job values. Highlighted in yellow is the discrepant property and value attribution. Please reach out if there are questions or need further details.  To automate Spring-XD batch job using Sqoop via Spring we can not be prompted for password.  Spring-XD Job definition: job create sqoop_lookup_d_job_v1 --definition ""sqoop --command=job  --args='--create lookupd_job --meta-connect \""jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx\"" -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query \""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), ''-'')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), ''-'')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), ''-'')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), ''-'')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND $CONDITIONS\"" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by \""|\"" --append'""  Sqoop Direct Definition: sqoop job --create sqoop2 --meta-connect 'jdbc:postgresql://xx.xxx.xx.xx:5433/bdl?user=xxxxx&password=xxxxxx' -- import  --connect jdbc:oracle:thin:@xxxxxx.com:xxxx/GDWP --username xxxxx --password xxxxx --query ""SELECT ROW_WID, LKUP_ID, TRIM(TRANSLATE(LKUP_CD, CHR(10)||CHR(13), '-')) AS LKUP_CD, TRIM(TRANSLATE(LKUP_DESC, CHR(10)||CHR(13), '-')) AS LKUP_DESC, TRIM(TRANSLATE(LKUP_TYPE, CHR(10)||CHR(13), '-')) AS LKUP_TYPE, TRIM(TRANSLATE(LKUP_VAL, CHR(10)||CHR(13), '-')) AS LKUP_VAL, SRC_STRT_DT, SRC_END_DT, W_INSERT_DT, W_UPDATE_DT FROM MASTERDATA.W_LOOKUP_D WHERE 1=1 AND \$CONDITIONS "" --incremental append --check-column ROW_WID --last-value 10150 --target-dir /user/monasj1/bdl/data/sqoop/jobtest --num-mappers 1 --fields-terminated-by '|' --append ",5
"Message rate collection throws warning level exception
When the container doesn't have any modules deployed, the jolokia response returns stacktrace with ""NoInstanceFoundException"". This exception is thrown at the admin log as:    2015-04-28 13:09:35,952 1.2.0.SNAP  WARN qtp1648225666-27 rest.ContainersController - Error getting message rate metrics for 713255e5-49b2-4158-b69c-2d203cfe50d3  org.codehaus.jettison.json.JSONException: JSONObject[""value""] not found.    org.codehaus.jettison.json.JSONObject.get(JSONObject.java:360)    org.codehaus.jettison.json.JSONObject.getJSONObject(JSONObject.java:454)    org.springframework.xd.dirt.rest.ContainersController.setMessageRates(ContainersController.java:134)    org.springframework.xd.dirt.rest.ContainersController.list(ContainersController.java:114)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)    org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)    org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)    org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)    org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)    org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)    org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)    org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)    org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:857)    javax.servlet.http.HttpServlet.service(HttpServlet.java:735)    org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)    javax.servlet.http.HttpServlet.service(HttpServlet.java:848)    org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)    org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)    org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)    org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)    org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)    org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)    org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)    org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)    org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)    org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)    org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)    org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)    org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)    org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)    org.eclipse.jetty.server.Server.handle(Server.java:370)    org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)    org.eclipse.jetty.server.AbstractHttpConnection.headerComplete(AbstractHttpConnection.java:971)    org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.headerComplete(AbstractHttpConnection.java:1033)    org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:644)    org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:235)    org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)    org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)    org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)    org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)    org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)    java.lang.Thread.run(Thread.java:745)",1
"Version info not available when security enabled
When security is enabled, the VersionController REST endpoint isn't visible.",1
"Manual acknowledgement with Kafka bus doesn't work
When the kafka message headers are expected to be set with acknowledgement flags to manually acknowledge the messages at the consumer side, the message headers are missing.",1
"Can't compose script processor
Consider this simple stream which works out of the box because {{transform.groovy}} is shipped with Spring XD: {code} stream create --name ""stream1"" --definition ""time | script --script='transform.groovy' | log"" --deploy {code}  Composing {{time}} and {{script}} modules like that  {code} module compose --name ""cmp-time"" --definition ""time | script --script='transform.groovy'"" stream create --name ""stream2"" --definition ""cmp-time | log"" --deploy {code}  will throw following exception in xd-shell:  {code} Apr 29, 2015 11:28:57 AM org.springframework.shell.core.AbstractShell handleExecutionResult INFO: Successfully created module 'cmp-time' with type source Apr 29, 2015 11:28:57 AM org.springframework.shell.core.SimpleExecutionStrategy invoke SEVERE: Command failed org.springframework.xd.rest.client.impl.SpringXDException: Error with option(s) for module cmp-time of type source:     valid: 'script' cannot be null or empty {code}  and following exception in xd-container:  {code} 2015-04-29 11:28:57,263 1.1.1.RELEASE ERROR qtp616131272-35 rest.RestControllerAdvice - Caught exception while handling a request org.springframework.xd.dirt.plugins.ModuleConfigurationException: Error with option(s) for module cmp-time of type source:     valid: 'script' cannot be null or empty   org.springframework.xd.dirt.plugins.ModuleConfigurationException.fromBindException(ModuleConfigurationException.java:55)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:180)   org.springframework.xd.dirt.stream.AbstractDeployer.save(AbstractDeployer.java:95)   org.springframework.xd.dirt.rest.XDController.save(XDController.java:235)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:221)   org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:137)   org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:110)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandleMethod(RequestMappingHandlerAdapter.java:777)   org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:706)   org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:85)   org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:943)   org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:877)   org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:966)   org.springframework.web.servlet.FrameworkServlet.doPost(FrameworkServlet.java:868)   javax.servlet.http.HttpServlet.service(HttpServlet.java:755)   org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:842)   javax.servlet.http.HttpServlet.service(HttpServlet.java:848)   org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:684)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1496)   org.springframework.boot.actuate.autoconfigure.EndpointWebMvcAutoConfiguration$ApplicationContextHeaderFilter.doFilterInternal(EndpointWebMvcAutoConfiguration.java:291)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:77)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:87)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.boot.actuate.trace.WebRequestTraceFilter.doFilterInternal(WebRequestTraceFilter.java:100)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.security.web.FilterChainProxy.doFilterInternal(FilterChainProxy.java:186)   org.springframework.security.web.FilterChainProxy.doFilter(FilterChainProxy.java:160)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.springframework.boot.actuate.autoconfigure.MetricFilterAutoConfiguration$MetricsFilter.doFilterInternal(MetricFilterAutoConfiguration.java:90)   org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107)   org.eclipse.jetty.servlet.ServletHandler$CachedChain.doFilter(ServletHandler.java:1467)   org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:499)   org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:137)   org.eclipse.jetty.security.SecurityHandler.handle(SecurityHandler.java:557)   org.eclipse.jetty.server.session.SessionHandler.doHandle(SessionHandler.java:231)   org.eclipse.jetty.server.handler.ContextHandler.doHandle(ContextHandler.java:1086)   org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:428)   org.eclipse.jetty.server.session.SessionHandler.doScope(SessionHandler.java:193)   org.eclipse.jetty.server.handler.ContextHandler.doScope(ContextHandler.java:1020)   org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:135)   org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:116)   org.eclipse.jetty.server.Server.handle(Server.java:370)   org.eclipse.jetty.server.AbstractHttpConnection.handleRequest(AbstractHttpConnection.java:494)   org.eclipse.jetty.server.AbstractHttpConnection.content(AbstractHttpConnection.java:982)   org.eclipse.jetty.server.AbstractHttpConnection$RequestHandler.content(AbstractHttpConnection.java:1043)   org.eclipse.jetty.http.HttpParser.parseNext(HttpParser.java:865)   org.eclipse.jetty.http.HttpParser.parseAvailable(HttpParser.java:240)   org.eclipse.jetty.server.AsyncHttpConnection.handle(AsyncHttpConnection.java:82)   org.eclipse.jetty.io.nio.SelectChannelEndPoint.handle(SelectChannelEndPoint.java:667)   org.eclipse.jetty.io.nio.SelectChannelEndPoint$1.run(SelectChannelEndPoint.java:52)   org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:608)   org.eclipse.jetty.util.thread.QueuedThreadPool$3.run(QueuedThreadPool.java:543)   java.lang.Thread.run(Thread.java:745) Caused by: org.springframework.validation.BindException: org.springframework.validation.BeanPropertyBindingResult: 1 errors Field error in object 'target' on field 'valid': rejected value [false]; codes [AssertTrue.target.valid,AssertTrue.valid,AssertTrue.boolean,AssertTrue]; arguments [org.springframework.context.support.DefaultMessageSourceResolvable: codes [target.valid,valid]; arguments []; default message [valid]]; default message ['script' cannot be null or empty]   org.springframework.xd.module.options.PojoModuleOptionsMetadata.bindAndValidate(PojoModuleOptionsMetadata.java:205)   org.springframework.xd.module.options.PojoModuleOptionsMetadata.interpolate(PojoModuleOptionsMetadata.java:139)   org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)   org.springframework.xd.module.options.HierarchicalCompositeModuleOptionsMetadata.interpolate(HierarchicalCompositeModuleOptionsMetadata.java:105)   org.springframework.xd.module.options.FlattenedCompositeModuleOptionsMetadata.interpolate(FlattenedCompositeModuleOptionsMetadata.java:152)   org.springframework.xd.module.options.EnvironmentAwareModuleOptionsMetadataResolver$ModuleOptionsMetadataWithDefaults.interpolate(EnvironmentAwareModuleOptionsMetadataResolver.java:167)   org.springframework.xd.dirt.stream.XDStreamParser.parse(XDStreamParser.java:177) 	... 61 more {code}",2
"Job failed to deploy (Sporadic)
Commit: 433d18f03fd7f3bf7d9aeee80ab292f9c92af5a4 Transport: Rabbit 1 Admin 2 Containers Admin Log is attached. (Exception is at line 52) During Acceptance Tests for  testJobCreateDuplicateWithDeployFalse failed with the following error reported from the admin.  {noformat}  org.springframework.xd.rest.client.impl.SpringXDException(KeeperErrorCode = NoNode for /xd/jobs/jobFalseDeploy )   org.junit.runners.model.MultipleFailureException.assertEmpty(MultipleFailureException.java:67)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:39)   org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)   org.junit.rules.ExpectedException$ExpectedExceptionStatement.evaluate(ExpectedException.java:239)   org.junit.rules.RunRules.evaluate(RunRules.java:20)   org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)   org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)   org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)   org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)   org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)   org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)   org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)   org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)   org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)   org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)   org.junit.runners.ParentRunner.run(ParentRunner.java:363)   org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.runTestClass(JUnitTestClassExecuter.java:86)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassExecuter.execute(JUnitTestClassExecuter.java:49)   org.gradle.api.internal.tasks.testing.junit.JUnitTestClassProcessor.processTestClass(JUnitTestClassProcessor.java:69)   org.gradle.api.internal.tasks.testing.SuiteTestClassProcessor.processTestClass(SuiteTestClassProcessor.java:48)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.dispatch.ContextClassLoaderDispatch.dispatch(ContextClassLoaderDispatch.java:32)   org.gradle.messaging.dispatch.ProxyDispatchAdapter$DispatchingInvocationHandler.invoke(ProxyDispatchAdapter.java:93)   com.sun.proxy.$Proxy2.processTestClass(Unknown Source)   org.gradle.api.internal.tasks.testing.worker.TestWorker.processTestClass(TestWorker.java:105)   sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)   sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:57)   sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)   java.lang.reflect.Method.invoke(Method.java:606)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:35)   org.gradle.messaging.dispatch.ReflectionDispatch.dispatch(ReflectionDispatch.java:24)   org.gradle.messaging.remote.internal.hub.MessageHub$Handler.run(MessageHub.java:355)   org.gradle.internal.concurrent.DefaultExecutorFactory$StoppableExecutorImpl$1.run(DefaultExecutorFactory.java:64)   java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)   java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)   java.lang.Thread.run(Thread.java:745) {noformat}",3
" gemfire-json-server multiple PdxTypes Types
I am using SpringXD to ingest tweets to a gemfire-json-server sink.  I am running into an issue where the json documents get defined as a pdx type twice.  See the reweet_count field below.  This causes problems later when using OQL to access this data.  Incompatible types.  What are the recommended ways to resolve this?  The field type should account for the largest possible value, which is unknown because it is twitter.  This would likely be a int or long.  I was asked to log this as a SXD JIRA issue, but I am not sure if the problem is in SXD or GemFire.    [info 2015/04/25 06:51:28.767 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[      dsid=0typenum=1, name=__GEMFIRE_JSON, fields=[          id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1          from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1          created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2          text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3          language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4       retweet_count:short:5:4:idx0(relativeOffset)=-3:idx1(vlfOffsetIndex)=-1          retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]]    [info 2015/04/25 06:51:29.307 CST  <twitterSource-1-1> tid=0x53] Defining: PdxType[       dsid=0typenum=2, name=__GEMFIRE_JSON, fields=[        id:String:0:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=-1        from_user:String:1:1:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=1        created_at:String:2:2:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=2        text:String:3:3:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=3        language_code:String:4:4:idx0(relativeOffset)=0:idx1(vlfOffsetIndex)=4        retweet_count:byte:5:4:idx0(relativeOffset)=-2:idx1(vlfOffsetIndex)=-1        retweet:boolean:6:4:idx0(relativeOffset)=-1:idx1(vlfOffsetIndex)=-1]]",3
"Support --ref=true/false for sftp source
The file and ftp sources allow working with either the java.io.File or its contents.  For consistency, the sftp source should support the same mechanism.  ",2
"Add documentation for connecting to HDFS with HA Namenode
nan",1
"RemoteFileToHadoopTests fails on 1.1.x
This error surfaced recently as a result of a fix to a bug in HostNotWindowsRule which disabled this test in all environments. Now the test has been reactivated it is failing on the 1.1.x branch.  The test runs OK on master.  {noformat}  Encountered an error executing step step1-master in job job  org.springframework.messaging.MessageDeliveryException: failed to send Message to channel 'null'; nested exception is java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:292)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.xd.dirt.integration.bus.local.LocalMessageBus$3.handleMessage(LocalMessageBus.java:262)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutput(AbstractMessageProducingHandler.java:248)    org.springframework.integration.handler.AbstractMessageProducingHandler.produceOutput(AbstractMessageProducingHandler.java:171)    org.springframework.integration.handler.AbstractMessageProducingHandler.sendOutputs(AbstractMessageProducingHandler.java:119)    org.springframework.integration.handler.AbstractReplyProducingMessageHandler.handleMessageInternal(AbstractReplyProducingMessageHandler.java:105)    org.springframework.integration.handler.AbstractMessageHandler.handleMessage(AbstractMessageHandler.java:78)    org.springframework.integration.dispatcher.AbstractDispatcher.tryOptimizedDispatch(AbstractDispatcher.java:116)    org.springframework.integration.dispatcher.UnicastingDispatcher.doDispatch(UnicastingDispatcher.java:101)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:97)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:239)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:115)    org.springframework.messaging.core.GenericMessagingTemplate.doSend(GenericMessagingTemplate.java:45)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:95)    org.springframework.messaging.core.AbstractMessageSendingTemplate.send(AbstractMessageSendingTemplate.java:85)    org.springframework.batch.integration.partition.MessageChannelPartitionHandler.handle(MessageChannelPartitionHandler.java:224)    org.springframework.batch.core.partition.support.PartitionStep.doExecute(PartitionStep.java:106)    org.springframework.batch.core.step.AbstractStep.execute(AbstractStep.java:198)    org.springframework.batch.core.job.SimpleStepHandler.handleStep(SimpleStepHandler.java:148)    org.springframework.batch.core.job.flow.JobFlowExecutor.executeStep(JobFlowExecutor.java:64)    org.springframework.batch.core.job.flow.support.state.StepState.handle(StepState.java:67)    org.springframework.batch.core.job.flow.support.SimpleFlow.resume(SimpleFlow.java:165)    org.springframework.batch.core.job.flow.support.SimpleFlow.start(SimpleFlow.java:144)    org.springframework.batch.core.job.flow.FlowJob.doExecute(FlowJob.java:134)    org.springframework.batch.core.job.AbstractJob.execute(AbstractJob.java:304)    org.springframework.batch.core.launch.support.SimpleJobLauncher$1.run(SimpleJobLauncher.java:135)    org.springframework.core.task.SyncTaskExecutor.execute(SyncTaskExecutor.java:50)    org.springframework.batch.core.launch.support.SimpleJobLauncher.run(SimpleJobLauncher.java:128)    org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:161)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)    org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)    org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)    org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)    org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)    org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)    org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)    org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)    org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)    org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)    org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)    org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)    org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)    org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)    org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)    org.junit.rules.RunRules.evaluate(RunRules.java:20)    org.junit.runners.ParentRunner.run(ParentRunner.java:363)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)    org.junit.runner.JUnitCore.run(JUnitCore.java:137)    com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)    com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)    com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    java.lang.reflect.Method.invoke(Method.java:483)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  Caused by: java.lang.IllegalStateException: ThreadPoolTaskExecutor not initialized    org.springframework.util.Assert.state(Assert.java:385)    org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.getThreadPoolExecutor(ThreadPoolTaskExecutor.java:221)    org.springframework.scheduling.concurrent.ThreadPoolTaskExecutor.execute(ThreadPoolTaskExecutor.java:252)    org.springframework.integration.dispatcher.UnicastingDispatcher.dispatch(UnicastingDispatcher.java:89)    org.springframework.integration.channel.AbstractSubscribableChannel.doSend(AbstractSubscribableChannel.java:77)    org.springframework.integration.channel.AbstractMessageChannel.send(AbstractMessageChannel.java:277)  	... 76 more    java.lang.AssertionError:   Expected :exitCode=COMPLETED;exitDescription=  Actual   :exitCode=FAILED;exitDescription=     <Click to see difference>        org.junit.Assert.fail(Assert.java:88)    org.junit.Assert.failNotEquals(Assert.java:834)    org.junit.Assert.assertEquals(Assert.java:118)    org.junit.Assert.assertEquals(Assert.java:144)    org.springframework.batch.integration.x.RemoteFileToHadoopTests.testSimple(RemoteFileToHadoopTests.java:162)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)    org.junit.runners.model.FrameworkMethod$1.runReflectiveCall(FrameworkMethod.java:50)    org.junit.internal.runners.model.ReflectiveCallable.run(ReflectiveCallable.java:12)    org.junit.runners.model.FrameworkMethod.invokeExplosively(FrameworkMethod.java:47)    org.junit.internal.runners.statements.InvokeMethod.evaluate(InvokeMethod.java:17)    org.junit.internal.runners.statements.RunBefores.evaluate(RunBefores.java:26)    org.springframework.test.context.junit4.statements.RunBeforeTestMethodCallbacks.evaluate(RunBeforeTestMethodCallbacks.java:73)    org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:27)    org.springframework.test.context.junit4.statements.RunAfterTestMethodCallbacks.evaluate(RunAfterTestMethodCallbacks.java:82)    org.springframework.test.context.junit4.statements.SpringRepeat.evaluate(SpringRepeat.java:73)    org.junit.runners.ParentRunner.runLeaf(ParentRunner.java:325)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:217)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.runChild(SpringJUnit4ClassRunner.java:83)    org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)    org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)    org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)    org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)    org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)    org.springframework.test.context.junit4.statements.RunBeforeTestClassCallbacks.evaluate(RunBeforeTestClassCallbacks.java:61)    org.springframework.test.context.junit4.statements.RunAfterTestClassCallbacks.evaluate(RunAfterTestClassCallbacks.java:68)    org.springframework.xd.test.HostNotWindowsRule$1.evaluate(HostNotWindowsRule.java:38)    org.junit.rules.RunRules.evaluate(RunRules.java:20)    org.junit.runners.ParentRunner.run(ParentRunner.java:363)    org.springframework.test.context.junit4.SpringJUnit4ClassRunner.run(SpringJUnit4ClassRunner.java:163)    org.junit.runner.JUnitCore.run(JUnitCore.java:137)    com.intellij.junit4.JUnit4IdeaTestRunner.startRunnerWithArgs(JUnit4IdeaTestRunner.java:74)    com.intellij.rt.execution.junit.JUnitStarter.prepareStreamsAndStart(JUnitStarter.java:211)    com.intellij.rt.execution.junit.JUnitStarter.main(JUnitStarter.java:67)    sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)    sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)    com.intellij.rt.execution.application.AppMain.main(AppMain.java:134)  {noformat}",2
